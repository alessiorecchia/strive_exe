{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "    <h2 align=\"center\">Deep Learning Fundamentals</h2>\n",
    "    <h2 align=\"center\" style=\"color:#01ff84\">Multiclass Classification: MNIST</h2>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:36.081105Z",
     "start_time": "2021-05-26T22:26:35.040138Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxliary plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:37.473177Z",
     "start_time": "2021-05-26T22:26:37.465910Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/view-classify-in-module-helper/30279/6\n",
    "\n",
    "def view_classify(img, ps):\n",
    "\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST Dataset\n",
    "First up, we need to get our dataset. This is provided through the `torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us. Don't worry too much about the details here, you'll learn more about this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:38.402766Z",
     "start_time": "2021-05-26T22:26:38.298968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data (Preprocessing)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)) ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset    = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset    = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:38.632988Z",
     "start_time": "2021-05-26T22:26:38.477558Z"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the training data loaded into `trainloader` and we make that an iterator with `iter(trainloader)`. We'd use this to loop through the dataset for training, but here I'm just grabbing the first batch so we can check out the data. We can see below that `images` is just a tensor with size (64, 1, 28, 28). So, 64 images per batch, 1 color channel, and 28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:39.407000Z",
     "start_time": "2021-05-26T22:26:39.265256Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "image/png": {
       "width": 251,
       "height": 248
      },
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building networks with PyTorch\n",
    "\n",
    "Here I'll use PyTorch to build a simple feedfoward network to classify the MNIST images. That is, the network will receive a digit image as input and predict the digit in the image.\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "To build a neural network with PyTorch, you use the `torch.nn` module. The network itself is a class inheriting from `torch.nn.Module`. You define each of the operations separately, like `nn.Linear(784, 128)` for a fully connected linear layer with 784 inputs and 128 units.\n",
    "\n",
    "The class needs to include a `forward` method that implements the forward pass through the network. In this method, you pass some input tensor `x` through each of the operations you defined earlier. The `torch.nn` module also has functional equivalents for things like ReLUs in `torch.nn.functional`. This module is usually imported as `F`. Then to use a ReLU activation on some layer (which is just a tensor), you'd do `F.relu(x)`. Below are a few different commonly used activation functions.\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "So, for this network, I'll build it with three fully connected layers, then a softmax output for predicting classes. The softmax function is similar to the sigmoid in that it squashes inputs between 0 and 1, but it's also normalized so that all the values sum to one like a proper probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:39.961531Z",
     "start_time": "2021-05-26T22:26:39.946776Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    # Defining the layers, 128, 64, 10 units each\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, 10)\n",
    "        \n",
    "    # Forward pass through the network, returns the output logits\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why the input features are 784? Because the input images have size 28 pixels x 28 pixels for a total of 784 features. Since a Multilayer perceptron accepts only flatten inputs, we need to flatten a 28x28 grid into a 784 array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential API\n",
    "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, `nn.Sequential` ([documentation](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential)). Using this to build the equivalent network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:41.213448Z",
     "start_time": "2021-05-26T22:26:41.205216Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sequential(\n  (0): Linear(in_features=784, out_features=4, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=4, out_features=4, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=4, out_features=10, bias=True)\n  (5): Softmax(dim=1)\n)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size   = 784\n",
    "hidden_sizes = [4, 4]\n",
    "output_size   = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass in an `OrderedDict` to name the individual layers and operations. Note that a dictionary keys must be unique, so _each operation must have a different name_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:42.300216Z",
     "start_time": "2021-05-26T22:26:42.289009Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=4, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=4, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model = nn.Sequential(OrderedDict([\n",
    "          ('fc1',   nn.Linear(input_size, hidden_sizes[0])),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2',   nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "          ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing weights and biases\n",
    "\n",
    "The weights and such are automatically initialized for you, but it's possible to customize how they are initialized. The weights and biases are tensors attached to the layer you defined, you can get them with `model.fc1.weight` for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:42.972699Z",
     "start_time": "2021-05-26T22:26:42.963913Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([[-0.0114, -0.0202, -0.0168,  ..., -0.0110,  0.0124, -0.0217],\n        [ 0.0202,  0.0298, -0.0162,  ...,  0.0041,  0.0299, -0.0251],\n        [-0.0329, -0.0285,  0.0260,  ...,  0.0167,  0.0040, -0.0192],\n        [-0.0281,  0.0287, -0.0321,  ..., -0.0054, -0.0290, -0.0305]],\n       requires_grad=True)\nParameter containing:\ntensor([0.0293, 0.0064, 0.0017, 0.0029], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For custom initialization, we want to modify these tensors in place. These are actually autograd *Variables*, so we need to get back the actual tensors with `model.fc1.weight.data`. Once we have the tensors, we can fill them with zeros (for biases) or random normal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:43.889729Z",
     "start_time": "2021-05-26T22:26:43.883940Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Set biases to all zeros\n",
    "model.fc1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:44.084097Z",
     "start_time": "2021-05-26T22:26:44.076738Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.0039, -0.0078,  0.0157,  ...,  0.0035,  0.0040,  0.0073],\n",
       "        [ 0.0003,  0.0126,  0.0027,  ...,  0.0068,  0.0208, -0.0007],\n",
       "        [ 0.0068, -0.0080,  0.0131,  ...,  0.0054, -0.0018, -0.0042],\n",
       "        [-0.0080, -0.0017, -0.0007,  ..., -0.0011, -0.0031,  0.0186]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# sample from random normal with standard dev = 0.01\n",
    "model.fc1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Forward pass\n",
    "\n",
    "Now that we have a network, let's see what happens when we pass in an image. This is called the forward pass. We're going to convert the image data into a tensor, then pass it through the operations defined by the network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:44.506324Z",
     "start_time": "2021-05-26T22:26:44.491847Z"
    }
   },
   "outputs": [],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:44.596541Z",
     "start_time": "2021-05-26T22:26:44.594169Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 28, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:44.851894Z",
     "start_time": "2021-05-26T22:26:44.845888Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=4, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=4, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:46.121246Z",
     "start_time": "2021-05-26T22:26:46.112022Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to not automatically get batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:46.519895Z",
     "start_time": "2021-05-26T22:26:46.514137Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "img_idx = 0\n",
    "images[img_idx,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:47.945952Z",
     "start_time": "2021-05-26T22:26:47.888846Z"
    }
   },
   "outputs": [],
   "source": [
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model(images[img_idx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:50.561845Z",
     "start_time": "2021-05-26T22:26:50.411449Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x648 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "image/png": {
       "width": 349,
       "height": 195
      },
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "img = images[img_idx]\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, our network has basically no idea what this digit is. It's because we haven't trained it yet, all the weights are random!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural Networks\n",
    "\n",
    "The network we built isn't so smart, it doesn't know anything about our handwritten digits. Neural networks with non-linear activations work like universal function approximators. There is some function that maps your input to the output. For example, images of handwritten digits to class probabilities. The power of neural networks is that we can train them to approximate this function, and basically any function given enough data and compute time.\n",
    "\n",
    "<img src=\"assets/function_approx.png\" width=500px>\n",
    "\n",
    "At first the network is naive, it doesn't know the function mapping the inputs to the outputs. We train the network by showing it examples of real data, then adjusting the network parameters such that it approximates this function.\n",
    "\n",
    "To find these parameters, we need to know how poorly the network is predicting the real outputs. For this we calculate a **loss function** (also called the cost), a measure of our prediction error. For example, the mean squared loss is often used in regression and binary classification problems\n",
    "\n",
    "$$\n",
    "\\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
    "$$\n",
    "\n",
    "where $n$ is the number of training examples, $y_i$ are the true labels, and $\\hat{y}_i$ are the predicted labels.\n",
    "\n",
    "By minimizing this loss with respect to the network parameters, we can find configurations where the loss is at a minimum and the network is able to predict the correct labels with high accuracy. We find this minimum using a process called **gradient descent**. The gradient is the slope of the loss function and points in the direction of fastest change. To get to the minimum in the least amount of time, we then want to follow the gradient (downwards). You can think of this like descending a mountain by following the steepest slope to the base.\n",
    "\n",
    "<img src='assets/gradient_descent.png' width=350px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "For single layer networks, gradient descent is simple to implement. However, it's more complicated for deeper, multilayer neural networks like the one we've built. Complicated enough that it took about 30 years before researchers figured out how to train multilayer networks, although it's straightforward once you learn about it. \n",
    "\n",
    "This is done through **backpropagation** which is really just an application of the chain rule from calculus. It's easiest to understand if we convert a two layer network into a graph representation.\n",
    "\n",
    "<img src='assets/w1_backprop_graph.png' width=400px>\n",
    "\n",
    "In the forward pass through the network, our data and operations go from right to left here. To train the weights with gradient descent, we propagate the gradient of the cost backwards through the network. Mathematically, this is really just calculating the gradient of the loss with respect to the weights using the chain rule.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell}{\\partial w_1} = \\frac{\\partial l_1}{\\partial w_1} \\frac{\\partial s}{\\partial l_1} \\frac{\\partial l_2}{\\partial s} \\frac{\\partial \\ell}{\\partial l_2}\n",
    "$$\n",
    "\n",
    "We update our weights using this gradient with some learning rate $\\alpha$. \n",
    "\n",
    "$$\n",
    "w^\\prime = w - \\alpha \\frac{\\partial \\ell}{\\partial w}\n",
    "$$\n",
    "\n",
    "The learning rate is set such that the weight update steps are small enough that the iterative method settles in a minimum.\n",
    "\n",
    "The first thing we need to do for training is define our loss function. In PyTorch, you'll usually see this as `criterion`. Here we're using softmax output, so we want to use `criterion = nn.CrossEntropyLoss()` as our loss. Later when training, you use `loss = criterion(output, targets)` to calculate the actual loss.\n",
    "\n",
    "We also need to define the optimizer we're using, SGD or Adam, or something along those lines. Here I'll just use SGD with `torch.optim.SGD`, passing in the network parameters and the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "Torch provides a module, `autograd`, for automatically calculating the gradient of tensors. It does this by keeping track of operations performed on tensors. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
    "\n",
    "You can turn off gradients for a block of code with the `torch.no_grad()` content:\n",
    "```python\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n",
    "```\n",
    "\n",
    "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "The gradients are computed with respect to some variable `z` with `z.backward()`. This does a backward pass through the operations that created `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:52.867509Z",
     "start_time": "2021-05-26T22:26:52.860629Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 2.3745, -0.4129],\n        [-0.1983, -0.6832]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:53.383436Z",
     "start_time": "2021-05-26T22:26:53.375536Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[5.6380, 0.1705],\n        [0.0393, 0.4668]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see the operation that created `y`, a power operation `PowBackward0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:53.870654Z",
     "start_time": "2021-05-26T22:26:53.867424Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<PowBackward0 object at 0x7f7fe1cc13a0>\n"
     ]
    }
   ],
   "source": [
    "## grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autgrad module keeps track of these operations and knows how to calculate the gradient for each one. In this way, it's able to calculate the gradients for a chain of operations, with respect to any one tensor. Let's reduce the tensor `y` to a scalar value, the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:54.831912Z",
     "start_time": "2021-05-26T22:26:54.824631Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(1.5787, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the gradients for `x` and `y` but they are empty currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:55.546143Z",
     "start_time": "2021-05-26T22:26:55.541213Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the gradients, you need to run the `.backward` method on a Variable, `z` for example. This will calculate the gradient for `z` with respect to `x`\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:56.607560Z",
     "start_time": "2021-05-26T22:26:56.594993Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1.1872, -0.2065],\n        [-0.0992, -0.3416]])\ntensor([[ 1.1872, -0.2065],\n        [-0.0992, -0.3416]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These gradients calculations are particularly useful for neural networks. For training we need the gradients of the weights with respect to the cost. With PyTorch, we run data forward through the network to calculate the cost, then, go backwards to calculate the gradients with respect to the cost. Once we have the gradients we can make a gradient descent step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll build a network with `nn.Sequential` here. Only difference from the last part is I'm not actually using softmax on the output, but instead just using the raw output from the last layer. This is because the output from softmax is a probability distribution. Often, the output will have values really close to zero or really close to one. Due to [inaccuracies with representing numbers as floating points](https://docs.python.org/3/tutorial/floatingpoint.html), computations with a softmax output can lose accuracy and become unstable. To get around this, we'll use the raw output, called the **logits**, to calculate the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:56.944759Z",
     "start_time": "2021-05-26T22:26:56.936939Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size   = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size  = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(OrderedDict([\n",
    "          ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('logits', nn.Linear(hidden_sizes[1], output_size))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network!\n",
    "\n",
    "The first thing we need to do for training is define our loss function. In PyTorch, you'll usually see this as `criterion`. Here we're using softmax output, so we want to use `criterion = nn.CrossEntropyLoss()` as our loss. Later when training, you use `loss = criterion(output, targets)` to calculate the actual loss.\n",
    "\n",
    "We also need to define the optimizer we're using, SGD or Adam, or something along those lines. Here I'll just use SGD with `torch.optim.SGD`, passing in the network parameters and the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:57.317614Z",
     "start_time": "2021-05-26T22:26:57.313022Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's consider just one learning step before looping through all the data. The general process with PyTorch:\n",
    "\n",
    "* Make a forward pass through the network to get the logits \n",
    "* Use the logits to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "Below I'll go through one training step and print out the weights and gradients so you can see how it changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:27:07.408433Z",
     "start_time": "2021-05-26T22:27:07.373358Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initial weights -  Parameter containing:\ntensor([[-0.0343,  0.0059, -0.0057,  ..., -0.0099,  0.0186,  0.0183],\n        [ 0.0207, -0.0218,  0.0093,  ..., -0.0075,  0.0035, -0.0143],\n        [ 0.0116,  0.0060, -0.0121,  ..., -0.0199, -0.0264, -0.0135],\n        ...,\n        [-0.0151,  0.0120, -0.0035,  ..., -0.0038, -0.0102, -0.0176],\n        [ 0.0223, -0.0168, -0.0147,  ...,  0.0052,  0.0273,  0.0042],\n        [-0.0157,  0.0302, -0.0295,  ...,  0.0151,  0.0284, -0.0260]],\n       requires_grad=True)\nGradient - tensor([[ 0.0009,  0.0009,  0.0009,  ...,  0.0009,  0.0009,  0.0009],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0009,  0.0009,  0.0009,  ...,  0.0009,  0.0009,  0.0009],\n        ...,\n        [ 0.0012,  0.0012,  0.0012,  ...,  0.0012,  0.0012,  0.0012],\n        [-0.0014, -0.0014, -0.0014,  ..., -0.0014, -0.0014, -0.0014],\n        [-0.0087, -0.0087, -0.0087,  ..., -0.0087, -0.0087, -0.0087]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model.fc1.weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(trainloader.batch_size, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model.fc1.weight.grad)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:27:07.915247Z",
     "start_time": "2021-05-26T22:27:07.908155Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Updated weights -  Parameter containing:\ntensor([[-0.0343,  0.0059, -0.0057,  ..., -0.0100,  0.0186,  0.0183],\n        [ 0.0207, -0.0218,  0.0093,  ..., -0.0075,  0.0035, -0.0143],\n        [ 0.0116,  0.0060, -0.0121,  ..., -0.0200, -0.0264, -0.0136],\n        ...,\n        [-0.0151,  0.0120, -0.0036,  ..., -0.0038, -0.0102, -0.0177],\n        [ 0.0223, -0.0168, -0.0146,  ...,  0.0052,  0.0274,  0.0042],\n        [-0.0157,  0.0303, -0.0294,  ...,  0.0152,  0.0285, -0.0259]],\n       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('Updated weights - ', model.fc1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for real\n",
    "\n",
    "Now we'll put this algorithm into a loop so we can go through all the images. This is fairly straightforward. We'll loop through the mini-batches in our dataset, pass the data through the network to calculate the losses, get the gradients, then run the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:27:08.816179Z",
     "start_time": "2021-05-26T22:27:08.812807Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:27:36.083537Z",
     "start_time": "2021-05-26T22:27:09.280769Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1/3\n",
      "\tIteration: 0\t Loss: 0.0569\n",
      "\tIteration: 40\t Loss: 2.2960\n",
      "\tIteration: 80\t Loss: 2.2779\n",
      "\tIteration: 120\t Loss: 2.2552\n",
      "\tIteration: 160\t Loss: 2.2415\n",
      "\tIteration: 200\t Loss: 2.2215\n",
      "\tIteration: 240\t Loss: 2.1935\n",
      "\tIteration: 280\t Loss: 2.1661\n",
      "\tIteration: 320\t Loss: 2.1534\n",
      "\tIteration: 360\t Loss: 2.1146\n",
      "\tIteration: 400\t Loss: 2.0878\n",
      "\tIteration: 440\t Loss: 2.0512\n",
      "\tIteration: 480\t Loss: 1.9911\n",
      "\tIteration: 520\t Loss: 1.9362\n",
      "\tIteration: 560\t Loss: 1.8875\n",
      "\tIteration: 600\t Loss: 1.8478\n",
      "\tIteration: 640\t Loss: 1.7953\n",
      "\tIteration: 680\t Loss: 1.7100\n",
      "\tIteration: 720\t Loss: 1.6677\n",
      "\tIteration: 760\t Loss: 1.6005\n",
      "\tIteration: 800\t Loss: 1.5258\n",
      "\tIteration: 840\t Loss: 1.4529\n",
      "\tIteration: 880\t Loss: 1.3806\n",
      "\tIteration: 920\t Loss: 1.2959\n",
      "\tIteration: 960\t Loss: 1.3081\n",
      "\tIteration: 1000\t Loss: 1.2583\n",
      "\tIteration: 1040\t Loss: 1.1695\n",
      "\tIteration: 1080\t Loss: 1.0923\n",
      "\tIteration: 1120\t Loss: 1.1146\n",
      "\tIteration: 1160\t Loss: 1.0587\n",
      "\tIteration: 1200\t Loss: 0.9888\n",
      "\tIteration: 1240\t Loss: 0.9521\n",
      "\tIteration: 1280\t Loss: 0.9027\n",
      "\tIteration: 1320\t Loss: 0.9258\n",
      "\tIteration: 1360\t Loss: 0.9021\n",
      "\tIteration: 1400\t Loss: 0.8434\n",
      "\tIteration: 1440\t Loss: 0.8253\n",
      "\tIteration: 1480\t Loss: 0.7836\n",
      "\tIteration: 1520\t Loss: 0.7946\n",
      "\tIteration: 1560\t Loss: 0.7367\n",
      "\tIteration: 1600\t Loss: 0.7452\n",
      "\tIteration: 1640\t Loss: 0.6925\n",
      "\tIteration: 1680\t Loss: 0.6986\n",
      "\tIteration: 1720\t Loss: 0.7096\n",
      "\tIteration: 1760\t Loss: 0.6701\n",
      "\tIteration: 1800\t Loss: 0.6992\n",
      "\tIteration: 1840\t Loss: 0.6534\n",
      "\tIteration: 1880\t Loss: 0.6300\n",
      "\tIteration: 1920\t Loss: 0.6190\n",
      "\tIteration: 1960\t Loss: 0.6186\n",
      "\tIteration: 2000\t Loss: 0.6119\n",
      "\tIteration: 2040\t Loss: 0.5823\n",
      "\tIteration: 2080\t Loss: 0.5779\n",
      "\tIteration: 2120\t Loss: 0.5817\n",
      "\tIteration: 2160\t Loss: 0.5765\n",
      "\tIteration: 2200\t Loss: 0.6040\n",
      "\tIteration: 2240\t Loss: 0.5645\n",
      "\tIteration: 2280\t Loss: 0.5270\n",
      "\tIteration: 2320\t Loss: 0.5373\n",
      "\tIteration: 2360\t Loss: 0.5403\n",
      "\tIteration: 2400\t Loss: 0.5541\n",
      "\tIteration: 2440\t Loss: 0.5348\n",
      "\tIteration: 2480\t Loss: 0.4662\n",
      "\tIteration: 2520\t Loss: 0.4807\n",
      "\tIteration: 2560\t Loss: 0.5391\n",
      "\tIteration: 2600\t Loss: 0.5358\n",
      "\tIteration: 2640\t Loss: 0.4767\n",
      "\tIteration: 2680\t Loss: 0.5459\n",
      "\tIteration: 2720\t Loss: 0.4858\n",
      "\tIteration: 2760\t Loss: 0.4668\n",
      "\tIteration: 2800\t Loss: 0.4612\n",
      "\tIteration: 2840\t Loss: 0.4698\n",
      "\tIteration: 2880\t Loss: 0.4712\n",
      "\tIteration: 2920\t Loss: 0.5419\n",
      "\tIteration: 2960\t Loss: 0.4457\n",
      "\tIteration: 3000\t Loss: 0.3961\n",
      "\tIteration: 3040\t Loss: 0.5136\n",
      "\tIteration: 3080\t Loss: 0.4521\n",
      "\tIteration: 3120\t Loss: 0.3783\n",
      "\tIteration: 3160\t Loss: 0.4663\n",
      "\tIteration: 3200\t Loss: 0.4895\n",
      "\tIteration: 3240\t Loss: 0.4496\n",
      "\tIteration: 3280\t Loss: 0.4831\n",
      "\tIteration: 3320\t Loss: 0.4122\n",
      "\tIteration: 3360\t Loss: 0.5090\n",
      "\tIteration: 3400\t Loss: 0.4456\n",
      "\tIteration: 3440\t Loss: 0.4521\n",
      "\tIteration: 3480\t Loss: 0.4633\n",
      "\tIteration: 3520\t Loss: 0.4847\n",
      "\tIteration: 3560\t Loss: 0.4112\n",
      "\tIteration: 3600\t Loss: 0.4260\n",
      "\tIteration: 3640\t Loss: 0.4032\n",
      "\tIteration: 3680\t Loss: 0.4106\n",
      "\tIteration: 3720\t Loss: 0.4016\n",
      "Epoch: 2/3\n",
      "\tIteration: 0\t Loss: 0.0039\n",
      "\tIteration: 40\t Loss: 0.4050\n",
      "\tIteration: 80\t Loss: 0.4890\n",
      "\tIteration: 120\t Loss: 0.3983\n",
      "\tIteration: 160\t Loss: 0.4395\n",
      "\tIteration: 200\t Loss: 0.4549\n",
      "\tIteration: 240\t Loss: 0.3831\n",
      "\tIteration: 280\t Loss: 0.4155\n",
      "\tIteration: 320\t Loss: 0.4529\n",
      "\tIteration: 360\t Loss: 0.3587\n",
      "\tIteration: 400\t Loss: 0.3808\n",
      "\tIteration: 440\t Loss: 0.3403\n",
      "\tIteration: 480\t Loss: 0.4209\n",
      "\tIteration: 520\t Loss: 0.3828\n",
      "\tIteration: 560\t Loss: 0.4108\n",
      "\tIteration: 600\t Loss: 0.3863\n",
      "\tIteration: 640\t Loss: 0.4287\n",
      "\tIteration: 680\t Loss: 0.3377\n",
      "\tIteration: 720\t Loss: 0.3890\n",
      "\tIteration: 760\t Loss: 0.4042\n",
      "\tIteration: 800\t Loss: 0.3472\n",
      "\tIteration: 840\t Loss: 0.4135\n",
      "\tIteration: 880\t Loss: 0.3928\n",
      "\tIteration: 920\t Loss: 0.4565\n",
      "\tIteration: 960\t Loss: 0.3775\n",
      "\tIteration: 1000\t Loss: 0.3481\n",
      "\tIteration: 1040\t Loss: 0.4352\n",
      "\tIteration: 1080\t Loss: 0.4468\n",
      "\tIteration: 1120\t Loss: 0.4009\n",
      "\tIteration: 1160\t Loss: 0.3112\n",
      "\tIteration: 1200\t Loss: 0.3350\n",
      "\tIteration: 1240\t Loss: 0.4213\n",
      "\tIteration: 1280\t Loss: 0.4632\n",
      "\tIteration: 1320\t Loss: 0.3578\n",
      "\tIteration: 1360\t Loss: 0.3829\n",
      "\tIteration: 1400\t Loss: 0.3829\n",
      "\tIteration: 1440\t Loss: 0.3893\n",
      "\tIteration: 1480\t Loss: 0.3752\n",
      "\tIteration: 1520\t Loss: 0.3748\n",
      "\tIteration: 1560\t Loss: 0.3609\n",
      "\tIteration: 1600\t Loss: 0.4301\n",
      "\tIteration: 1640\t Loss: 0.4134\n",
      "\tIteration: 1680\t Loss: 0.4390\n",
      "\tIteration: 1720\t Loss: 0.3528\n",
      "\tIteration: 1760\t Loss: 0.3421\n",
      "\tIteration: 1800\t Loss: 0.3185\n",
      "\tIteration: 1840\t Loss: 0.3844\n",
      "\tIteration: 1880\t Loss: 0.3581\n",
      "\tIteration: 1920\t Loss: 0.3785\n",
      "\tIteration: 1960\t Loss: 0.3444\n",
      "\tIteration: 2000\t Loss: 0.3542\n",
      "\tIteration: 2040\t Loss: 0.3629\n",
      "\tIteration: 2080\t Loss: 0.3491\n",
      "\tIteration: 2120\t Loss: 0.3194\n",
      "\tIteration: 2160\t Loss: 0.3544\n",
      "\tIteration: 2200\t Loss: 0.3619\n",
      "\tIteration: 2240\t Loss: 0.2996\n",
      "\tIteration: 2280\t Loss: 0.3344\n",
      "\tIteration: 2320\t Loss: 0.3210\n",
      "\tIteration: 2360\t Loss: 0.3161\n",
      "\tIteration: 2400\t Loss: 0.3858\n",
      "\tIteration: 2440\t Loss: 0.3774\n",
      "\tIteration: 2480\t Loss: 0.3879\n",
      "\tIteration: 2520\t Loss: 0.3035\n",
      "\tIteration: 2560\t Loss: 0.3516\n",
      "\tIteration: 2600\t Loss: 0.3660\n",
      "\tIteration: 2640\t Loss: 0.3706\n",
      "\tIteration: 2680\t Loss: 0.3645\n",
      "\tIteration: 2720\t Loss: 0.4043\n",
      "\tIteration: 2760\t Loss: 0.4306\n",
      "\tIteration: 2800\t Loss: 0.3419\n",
      "\tIteration: 2840\t Loss: 0.3388\n",
      "\tIteration: 2880\t Loss: 0.3139\n",
      "\tIteration: 2920\t Loss: 0.3479\n",
      "\tIteration: 2960\t Loss: 0.3510\n",
      "\tIteration: 3000\t Loss: 0.3993\n",
      "\tIteration: 3040\t Loss: 0.3430\n",
      "\tIteration: 3080\t Loss: 0.4329\n",
      "\tIteration: 3120\t Loss: 0.2951\n",
      "\tIteration: 3160\t Loss: 0.3190\n",
      "\tIteration: 3200\t Loss: 0.3496\n",
      "\tIteration: 3240\t Loss: 0.3412\n",
      "\tIteration: 3280\t Loss: 0.3478\n",
      "\tIteration: 3320\t Loss: 0.3647\n",
      "\tIteration: 3360\t Loss: 0.3210\n",
      "\tIteration: 3400\t Loss: 0.2574\n",
      "\tIteration: 3440\t Loss: 0.3792\n",
      "\tIteration: 3480\t Loss: 0.3546\n",
      "\tIteration: 3520\t Loss: 0.3487\n",
      "\tIteration: 3560\t Loss: 0.3055\n",
      "\tIteration: 3600\t Loss: 0.3070\n",
      "\tIteration: 3640\t Loss: 0.3179\n",
      "\tIteration: 3680\t Loss: 0.2618\n",
      "\tIteration: 3720\t Loss: 0.3683\n",
      "Epoch: 3/3\n",
      "\tIteration: 0\t Loss: 0.0019\n",
      "\tIteration: 40\t Loss: 0.3340\n",
      "\tIteration: 80\t Loss: 0.3228\n",
      "\tIteration: 120\t Loss: 0.3324\n",
      "\tIteration: 160\t Loss: 0.3764\n",
      "\tIteration: 200\t Loss: 0.2613\n",
      "\tIteration: 240\t Loss: 0.3224\n",
      "\tIteration: 280\t Loss: 0.3422\n",
      "\tIteration: 320\t Loss: 0.2901\n",
      "\tIteration: 360\t Loss: 0.2846\n",
      "\tIteration: 400\t Loss: 0.3004\n",
      "\tIteration: 440\t Loss: 0.2985\n",
      "\tIteration: 480\t Loss: 0.3366\n",
      "\tIteration: 520\t Loss: 0.2911\n",
      "\tIteration: 560\t Loss: 0.3247\n",
      "\tIteration: 600\t Loss: 0.3292\n",
      "\tIteration: 640\t Loss: 0.3662\n",
      "\tIteration: 680\t Loss: 0.3583\n",
      "\tIteration: 720\t Loss: 0.3156\n",
      "\tIteration: 760\t Loss: 0.3060\n",
      "\tIteration: 800\t Loss: 0.2959\n",
      "\tIteration: 840\t Loss: 0.2871\n",
      "\tIteration: 880\t Loss: 0.3391\n",
      "\tIteration: 920\t Loss: 0.2927\n",
      "\tIteration: 960\t Loss: 0.3670\n",
      "\tIteration: 1000\t Loss: 0.3901\n",
      "\tIteration: 1040\t Loss: 0.2993\n",
      "\tIteration: 1080\t Loss: 0.3280\n",
      "\tIteration: 1120\t Loss: 0.3131\n",
      "\tIteration: 1160\t Loss: 0.3420\n",
      "\tIteration: 1200\t Loss: 0.3047\n",
      "\tIteration: 1240\t Loss: 0.2808\n",
      "\tIteration: 1280\t Loss: 0.3207\n",
      "\tIteration: 1320\t Loss: 0.3568\n",
      "\tIteration: 1360\t Loss: 0.3081\n",
      "\tIteration: 1400\t Loss: 0.3496\n",
      "\tIteration: 1440\t Loss: 0.2994\n",
      "\tIteration: 1480\t Loss: 0.2711\n",
      "\tIteration: 1520\t Loss: 0.2892\n",
      "\tIteration: 1560\t Loss: 0.3562\n",
      "\tIteration: 1600\t Loss: 0.3376\n",
      "\tIteration: 1640\t Loss: 0.3107\n",
      "\tIteration: 1680\t Loss: 0.3281\n",
      "\tIteration: 1720\t Loss: 0.2700\n",
      "\tIteration: 1760\t Loss: 0.3036\n",
      "\tIteration: 1800\t Loss: 0.2795\n",
      "\tIteration: 1840\t Loss: 0.2811\n",
      "\tIteration: 1880\t Loss: 0.3232\n",
      "\tIteration: 1920\t Loss: 0.2837\n",
      "\tIteration: 1960\t Loss: 0.3221\n",
      "\tIteration: 2000\t Loss: 0.3145\n",
      "\tIteration: 2040\t Loss: 0.3358\n",
      "\tIteration: 2080\t Loss: 0.3016\n",
      "\tIteration: 2120\t Loss: 0.4205\n",
      "\tIteration: 2160\t Loss: 0.3273\n",
      "\tIteration: 2200\t Loss: 0.2875\n",
      "\tIteration: 2240\t Loss: 0.3052\n",
      "\tIteration: 2280\t Loss: 0.3265\n",
      "\tIteration: 2320\t Loss: 0.2971\n",
      "\tIteration: 2360\t Loss: 0.3109\n",
      "\tIteration: 2400\t Loss: 0.2868\n",
      "\tIteration: 2440\t Loss: 0.2745\n",
      "\tIteration: 2480\t Loss: 0.2944\n",
      "\tIteration: 2520\t Loss: 0.3115\n",
      "\tIteration: 2560\t Loss: 0.3386\n",
      "\tIteration: 2600\t Loss: 0.2954\n",
      "\tIteration: 2640\t Loss: 0.3036\n",
      "\tIteration: 2680\t Loss: 0.3423\n",
      "\tIteration: 2720\t Loss: 0.3127\n",
      "\tIteration: 2760\t Loss: 0.3163\n",
      "\tIteration: 2800\t Loss: 0.3295\n",
      "\tIteration: 2840\t Loss: 0.2733\n",
      "\tIteration: 2880\t Loss: 0.2752\n",
      "\tIteration: 2920\t Loss: 0.2956\n",
      "\tIteration: 2960\t Loss: 0.3060\n",
      "\tIteration: 3000\t Loss: 0.3238\n",
      "\tIteration: 3040\t Loss: 0.3011\n",
      "\tIteration: 3080\t Loss: 0.2961\n",
      "\tIteration: 3120\t Loss: 0.3503\n",
      "\tIteration: 3160\t Loss: 0.3371\n",
      "\tIteration: 3200\t Loss: 0.2666\n",
      "\tIteration: 3240\t Loss: 0.2882\n",
      "\tIteration: 3280\t Loss: 0.2567\n",
      "\tIteration: 3320\t Loss: 0.3060\n",
      "\tIteration: 3360\t Loss: 0.2760\n",
      "\tIteration: 3400\t Loss: 0.2334\n",
      "\tIteration: 3440\t Loss: 0.3369\n",
      "\tIteration: 3480\t Loss: 0.2529\n",
      "\tIteration: 3520\t Loss: 0.2800\n",
      "\tIteration: 3560\t Loss: 0.3060\n",
      "\tIteration: 3600\t Loss: 0.3204\n",
      "\tIteration: 3640\t Loss: 0.2894\n",
      "\tIteration: 3680\t Loss: 0.3466\n",
      "\tIteration: 3720\t Loss: 0.3115\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "print_every = 40\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    print(f\"Epoch: {e+1}/{epochs}\")\n",
    "\n",
    "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
    "\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)   # 1) Forward pass\n",
    "        loss = criterion(output, labels) # 2) Compute loss\n",
    "        loss.backward()                  # 3) Backward pass\n",
    "        optimizer.step()                 # 4) Update model\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the network trained, we can check out it's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:30:00.206666Z",
     "start_time": "2021-05-26T22:29:59.954325Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x648 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "image/png": {
       "width": 349,
       "height": 195
      },
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "\n",
    "# Output of the network are logits, need to take softmax for probabilities\n",
    "ps = F.softmax(logits, dim=1)\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our network is brilliant. It can accurately predict the digits in our images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "    <h2 align=\"center\" style=\"color:#01ff84\">EMNIST Classification: Exercise</h2>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 1:</h3>\n",
    "  <p>Now it's your turn to build a simple network, use any method I've covered so far. In the next notebook, you'll learn how to train a network so it can make good predictions.</p>\n",
    "  <p>Build a network to classify the MNIST images with 3 hidden layers. Use 16 units in the first hidden layer, 32 units in the second layer, and 8 units in the third layer. Each hidden layer should have a ReLU activation function, and use softmax on the output layer.</p>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Exercise_net(\n",
       "  (fc1): Linear(in_features=784, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=8, bias=True)\n",
       "  (fc4): Linear(in_features=8, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "## TODO: Your network here\n",
    "\n",
    "class Exercise_net(nn.Module):\n",
    "    \n",
    "    # Defining the layers, 128, 64, 10 units each\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # input layer\n",
    "        self.fc1 = nn.Linear(784, 16)\n",
    "        # first hidden layer, size = 16\n",
    "        self.fc2 = nn.Linear(16, 32)\n",
    "        #  # second hidden layer, size = 32\n",
    "        self.fc3 = nn.Linear(32, 8)\n",
    "        # third hidden layer, size = 8\n",
    "        self.fc4 = nn.Linear(8, 10)\n",
    "        \n",
    "    # Forward pass through the network, returns the output logits\n",
    "    def forward(self, x):\n",
    "\n",
    "        #  input layer\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        # first hidden layer and activation\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        # second hidden layer and activation\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        # third hidden layer and output layer\n",
    "        x = self.fc4(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = Exercise_net()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/alessio/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x648 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "image/png": {
       "width": 349,
       "height": 195
      },
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Run this cell with your model to make sure it works\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 2:</h3>\n",
    "  <p>Train your network implementing the Pytorch training loop and <strong style=\"color:#01ff84\">after each epoch, use the model for predicting the test (validation) MNIST data.</strong></p>\n",
    "  <p>Note: If your model does not fit with the final softmax layer, you can remove this layer.</p>\n",
    "  <p>Hint: <a href=\"https://discuss.pytorch.org/t/training-loop-checking-validation-accuracy/78399\">Training loop checking validation accuracy\n",
    "</a></p>\n",
    "  <p>Research about <code>model.train()</code>, <code>model.eval()</code> and <code>with torch.no_grad()</code> in Pytorch.\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initial weights -  Parameter containing:\ntensor([[ 2.7822e-02,  3.4200e-02, -1.0357e-02,  ..., -1.5592e-02,\n         -8.8897e-03,  2.5820e-02],\n        [-2.9294e-02,  2.7647e-02, -2.3993e-02,  ...,  7.0154e-03,\n         -2.9234e-02,  1.7053e-03],\n        [ 3.7106e-03, -1.6514e-02,  3.1374e-02,  ..., -2.6961e-02,\n          2.6428e-02,  1.1115e-02],\n        ...,\n        [ 6.0822e-05,  3.0935e-02,  3.4669e-02,  ..., -1.2886e-02,\n          1.7104e-03, -2.7726e-02],\n        [ 2.7828e-02,  9.4873e-04, -3.4017e-02,  ..., -1.4618e-02,\n         -1.9509e-02, -1.5909e-02],\n        [-2.0589e-02,  3.2132e-02,  6.2521e-03,  ..., -3.3073e-02,\n          6.0551e-03, -3.0039e-02]], requires_grad=True)\nGradient - tensor([[ 2.8068e-05,  2.8068e-05,  2.8068e-05,  ...,  2.8068e-05,\n          2.8068e-05,  2.8068e-05],\n        [-2.5165e-05, -2.5165e-05, -2.5165e-05,  ..., -2.5165e-05,\n         -2.5165e-05, -2.5165e-05],\n        [ 5.8629e-07,  5.8629e-07,  5.8629e-07,  ...,  5.8629e-07,\n          5.8629e-07,  5.8629e-07],\n        ...,\n        [ 2.0469e-05,  2.0469e-05,  2.0469e-05,  ...,  2.0469e-05,\n          2.0469e-05,  2.0469e-05],\n        [ 1.6237e-05,  1.6237e-05,  1.6237e-05,  ...,  1.6237e-05,\n          1.6237e-05,  1.6237e-05],\n        [-1.9223e-05, -1.9223e-05, -1.9223e-05,  ..., -1.9223e-05,\n         -1.9223e-05, -1.9223e-05]])\n"
     ]
    }
   ],
   "source": [
    "# First step: defining criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "\n",
    "# first step for testing pourposes\n",
    "\n",
    "print('Initial weights - ', model.fc1.weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(trainloader.batch_size, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model.fc1.weight.grad)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(test_loader, model):\n",
    "    acc_list = []\n",
    "    y_preds_list = []\n",
    "    y_true_list = []\n",
    "    for i, (images_test, y_true) in enumerate(iter(test_loader)):\n",
    "        y_preds = []\n",
    "\n",
    "        # Flatten EMNIST images into a 784 long vector\n",
    "        images_test.resize_(images_test.size()[0], 784)\n",
    "        logits = model.forward(images_test)\n",
    "        output_preds = F.softmax(logits, dim=1)\n",
    "        for p in output_preds:\n",
    "            y_preds.append(p.argmax())\n",
    "        \n",
    "        y_preds = np.array(y_preds)\n",
    "        y_preds = torch.tensor(y_preds)\n",
    "\n",
    "        for i in range(y_preds.size(0)):\n",
    "            y_preds_list.append(y_preds[i].item())\n",
    "            y_true_list.append(y_true[i].item())\n",
    "\n",
    "    accuracy = (np.array(y_preds_list) == np.array(y_true_list)).sum()/len(y_preds_list)\n",
    "    print(accuracy)\n",
    "\n",
    "    return accuracy, y_preds_list, y_true_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1/7\n",
      "\tIteration: 0\t Loss: 0.0578\n",
      "\tIteration: 40\t Loss: 2.3024\n",
      "\tIteration: 80\t Loss: 2.3042\n",
      "\tIteration: 120\t Loss: 2.3025\n",
      "\tIteration: 160\t Loss: 2.3018\n",
      "\tIteration: 200\t Loss: 2.3037\n",
      "\tIteration: 240\t Loss: 2.3035\n",
      "\tIteration: 280\t Loss: 2.3031\n",
      "\tIteration: 320\t Loss: 2.3031\n",
      "\tIteration: 360\t Loss: 2.3050\n",
      "\tIteration: 400\t Loss: 2.3027\n",
      "\tIteration: 440\t Loss: 2.3031\n",
      "\tIteration: 480\t Loss: 2.3031\n",
      "\tIteration: 520\t Loss: 2.3015\n",
      "\tIteration: 560\t Loss: 2.2999\n",
      "\tIteration: 600\t Loss: 2.3026\n",
      "\tIteration: 640\t Loss: 2.2996\n",
      "\tIteration: 680\t Loss: 2.3016\n",
      "\tIteration: 720\t Loss: 2.3034\n",
      "\tIteration: 760\t Loss: 2.3033\n",
      "\tIteration: 800\t Loss: 2.3024\n",
      "\tIteration: 840\t Loss: 2.3014\n",
      "\tIteration: 880\t Loss: 2.3026\n",
      "\tIteration: 920\t Loss: 2.3036\n",
      "\tIteration: 960\t Loss: 2.3018\n",
      "\tIteration: 1000\t Loss: 2.3018\n",
      "\tIteration: 1040\t Loss: 2.3028\n",
      "\tIteration: 1080\t Loss: 2.3020\n",
      "\tIteration: 1120\t Loss: 2.3025\n",
      "\tIteration: 1160\t Loss: 2.3016\n",
      "\tIteration: 1200\t Loss: 2.3000\n",
      "\tIteration: 1240\t Loss: 2.3006\n",
      "\tIteration: 1280\t Loss: 2.3022\n",
      "\tIteration: 1320\t Loss: 2.3016\n",
      "\tIteration: 1360\t Loss: 2.3042\n",
      "\tIteration: 1400\t Loss: 2.3052\n",
      "\tIteration: 1440\t Loss: 2.3045\n",
      "\tIteration: 1480\t Loss: 2.3033\n",
      "\tIteration: 1520\t Loss: 2.3017\n",
      "\tIteration: 1560\t Loss: 2.3031\n",
      "\tIteration: 1600\t Loss: 2.3018\n",
      "\tIteration: 1640\t Loss: 2.3029\n",
      "\tIteration: 1680\t Loss: 2.3032\n",
      "\tIteration: 1720\t Loss: 2.3036\n",
      "\tIteration: 1760\t Loss: 2.3031\n",
      "\tIteration: 1800\t Loss: 2.3031\n",
      "\tIteration: 1840\t Loss: 2.3006\n",
      "\tIteration: 1880\t Loss: 2.3007\n",
      "\tIteration: 1920\t Loss: 2.3011\n",
      "\tIteration: 1960\t Loss: 2.3005\n",
      "\tIteration: 2000\t Loss: 2.3014\n",
      "\tIteration: 2040\t Loss: 2.3029\n",
      "\tIteration: 2080\t Loss: 2.3032\n",
      "\tIteration: 2120\t Loss: 2.3020\n",
      "\tIteration: 2160\t Loss: 2.3032\n",
      "\tIteration: 2200\t Loss: 2.3023\n",
      "\tIteration: 2240\t Loss: 2.3046\n",
      "\tIteration: 2280\t Loss: 2.3026\n",
      "\tIteration: 2320\t Loss: 2.3042\n",
      "\tIteration: 2360\t Loss: 2.3023\n",
      "\tIteration: 2400\t Loss: 2.3041\n",
      "\tIteration: 2440\t Loss: 2.3023\n",
      "\tIteration: 2480\t Loss: 2.3024\n",
      "\tIteration: 2520\t Loss: 2.3011\n",
      "\tIteration: 2560\t Loss: 2.3056\n",
      "\tIteration: 2600\t Loss: 2.3008\n",
      "\tIteration: 2640\t Loss: 2.3006\n",
      "\tIteration: 2680\t Loss: 2.3009\n",
      "\tIteration: 2720\t Loss: 2.3007\n",
      "\tIteration: 2760\t Loss: 2.3019\n",
      "\tIteration: 2800\t Loss: 2.3020\n",
      "\tIteration: 2840\t Loss: 2.3020\n",
      "\tIteration: 2880\t Loss: 2.3031\n",
      "\tIteration: 2920\t Loss: 2.3016\n",
      "\tIteration: 2960\t Loss: 2.3036\n",
      "\tIteration: 3000\t Loss: 2.3015\n",
      "\tIteration: 3040\t Loss: 2.3013\n",
      "\tIteration: 3080\t Loss: 2.3051\n",
      "\tIteration: 3120\t Loss: 2.3013\n",
      "\tIteration: 3160\t Loss: 2.3045\n",
      "\tIteration: 3200\t Loss: 2.3034\n",
      "\tIteration: 3240\t Loss: 2.3042\n",
      "\tIteration: 3280\t Loss: 2.3016\n",
      "\tIteration: 3320\t Loss: 2.3018\n",
      "\tIteration: 3360\t Loss: 2.3017\n",
      "\tIteration: 3400\t Loss: 2.3003\n",
      "\tIteration: 3440\t Loss: 2.3028\n",
      "\tIteration: 3480\t Loss: 2.3006\n",
      "\tIteration: 3520\t Loss: 2.3025\n",
      "\tIteration: 3560\t Loss: 2.3034\n",
      "\tIteration: 3600\t Loss: 2.3030\n",
      "\tIteration: 3640\t Loss: 2.3034\n",
      "\tIteration: 3680\t Loss: 2.3042\n",
      "\tIteration: 3720\t Loss: 2.3047\n",
      "0.1135\n",
      "Epoch: 2/7\n",
      "\tIteration: 0\t Loss: 0.0577\n",
      "\tIteration: 40\t Loss: 2.3011\n",
      "\tIteration: 80\t Loss: 2.3008\n",
      "\tIteration: 120\t Loss: 2.3045\n",
      "\tIteration: 160\t Loss: 2.3030\n",
      "\tIteration: 200\t Loss: 2.3026\n",
      "\tIteration: 240\t Loss: 2.3028\n",
      "\tIteration: 280\t Loss: 2.3006\n",
      "\tIteration: 320\t Loss: 2.3008\n",
      "\tIteration: 360\t Loss: 2.3025\n",
      "\tIteration: 400\t Loss: 2.3030\n",
      "\tIteration: 440\t Loss: 2.2995\n",
      "\tIteration: 480\t Loss: 2.3022\n",
      "\tIteration: 520\t Loss: 2.3016\n",
      "\tIteration: 560\t Loss: 2.3022\n",
      "\tIteration: 600\t Loss: 2.3012\n",
      "\tIteration: 640\t Loss: 2.3025\n",
      "\tIteration: 680\t Loss: 2.3031\n",
      "\tIteration: 720\t Loss: 2.3015\n",
      "\tIteration: 760\t Loss: 2.3021\n",
      "\tIteration: 800\t Loss: 2.3025\n",
      "\tIteration: 840\t Loss: 2.3028\n",
      "\tIteration: 880\t Loss: 2.3036\n",
      "\tIteration: 920\t Loss: 2.3019\n",
      "\tIteration: 960\t Loss: 2.3036\n",
      "\tIteration: 1000\t Loss: 2.3034\n",
      "\tIteration: 1040\t Loss: 2.3019\n",
      "\tIteration: 1080\t Loss: 2.3042\n",
      "\tIteration: 1120\t Loss: 2.3013\n",
      "\tIteration: 1160\t Loss: 2.3030\n",
      "\tIteration: 1200\t Loss: 2.3025\n",
      "\tIteration: 1240\t Loss: 2.3060\n",
      "\tIteration: 1280\t Loss: 2.3029\n",
      "\tIteration: 1320\t Loss: 2.3030\n",
      "\tIteration: 1360\t Loss: 2.3024\n",
      "\tIteration: 1400\t Loss: 2.3032\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-7e646ab59b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {e+1}/{epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Flatten EMNIST images into a 784 long vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \"\"\"\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;31m# PIL image mode: L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'YCbCr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## TODO: Your training loop here\n",
    "\n",
    "'''\n",
    "# Define a transform to normalize the data (Preprocessing)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)) ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset    = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset    = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True)\n",
    "'''\n",
    "\n",
    "epochs = 7\n",
    "print_every = 40\n",
    "accs_test = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    print(f\"Epoch: {e+1}/{epochs}\")\n",
    "\n",
    "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
    "\n",
    "        # Flatten EMNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)   # 1) Forward pass\n",
    "        loss = criterion(output, labels) # 2) Compute loss\n",
    "        loss.backward()                  # 3) Backward pass\n",
    "        optimizer.step()                 # 4) Update model\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
    "            running_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        acc, y_pred, y_true = check_accuracy(testloader, model)\n",
    "        accs_test.append(acc)\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.0983, 0.0986, 0.1511, 0.2129, 0.3128, 0.4973, 0.539]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "accs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x648 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAroAAAGHCAYAAABf8fH3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAABYlAAAWJQFJUiTwAAApyklEQVR4nO3deZgdZZn38e8d1gAhgChxD4uaACokDggosiijoggijq8DirsjI4oyigojuMzAjI7gMqICouAMIg46Igg4gCCoOGFxgCiyBEFZZAsBwpbc7x9VbQ6HczrVndNdpyrfz3XVVX2qnqq6T/VJ9y9PP1UVmYkkSZLUNlPqLkCSJEmaCAZdSZIktZJBV5IkSa1k0JUkSVIrGXQlSZLUSgZdSZIktZJBV5IkSa1k0JUkSVIrGXQlSZLUSgZdSZIktZJBV5IkSa1k0JUkSVIrGXQlSZLUSgZdSZKAiMhymll3LSuDiFhQnu+dmnLciDi83PbEqvuNiJ3K5QvGV7FWhEFXktQqEbFWRPxdRPwoIv4QEQ9GxAMRcWNEnBYR+0bE1LrrnCwdAaxzWhIRd0XERRFxUESsVXedK6OI2LMMzzvVXUtbrVp3AZIkDUpEvBb4OjCjY/EDwFJgZjntDRwVEftl5nmTXWONHgDuL79eHdgAeEk5vTMids7MO+oqriHuBH4H3DqGbR4st/ljj3V7Am8tv75gRQpTb/boSpJaISL2B35AEXJ/B+wHbJiZ62TmusB6wBsoAsXTgB3rqLNGn8vMGeW0AbAh8Fkggc0p/oOgUWTmlzNzVmZ+bAzbXFpus+tE1qbeDLqSpMaLiBcAx1L8XjsT2DozT87Mu0baZObCzPx+Zu4M/A2wqJ5qh0Nm3pWZhwLfLBe9LiKeVmdN0qAZdCVJbfBZYA2KPw+/OTMXj9Y4M08F/q3KjiNilYjYOSKOiYh5EXF7RDwSEX+KiNMjYpdRtp0SEftHxPnlmNhHI+LPEXF1RJwQEa/ssc3GEfHViLg2IhaXY4xviogLIuJjEbFhlbrH4D87vp7TUcdfLs6LiNkR8a2IuLl8Dz/oqnnriDi5XP9wRNwZEWdHxN5VCoiIZ0XEceX2D5XjqT8XEdP7tF89InaPiG9ExJXl8R4qz9N3ImLuBB2378VooxzjCRejjSxj2bCFT3aPoy7b/WP5+n+Xc4y3le1ujgizXQfH6EqSGi0ing7sXr78YmYurLJdZmbFQ8wGOsfyPgw8AjyVYozlnhHxicz8px7bngS8ueP1QmBdimEDm5fTT0ZWRsQciqEV08pFj1KMrX1WOb0MuLxzmwHoHDu6bo/1L6XoLV+Lohf8sc6VEfFu4Kss6zy7l2KYyG7AbhFxMrB/Zi7pc/zNgFOBJ1OMIU6KsdQfpuhl3jEzu8fE7gb8qOP1g+V2z6I432+MiLdn5kl9jjne4w7KI8DtwHRgTR4/frrTCcAngbkR8fzM/L8++3t7Of9WZi4ddLFNZuqXJDXdTkCUX//3BOz/EeB7wGspxv9Ozcx1gI2Aw4AlwGciYtvOjSJiR4rQtRQ4CFg3M9ejCDZPA/YHft51rM9RhNxfAXMyc/XMXB9YG/gr4GiKsDxIz+r4+t4e6/8d+DXw/HKs81oUYZCI2J5lIfc04JllvesBn6AIj/sCo41p/RzFe3ppZk6jeK97Ulz4tRnwrR7b3E8x5GJXinHYa2fmVODZFOdoVeDrEfGsHtuuyHEHIjMvycwZwHdHaukYPz2jXEdm3gKcXbZ5W699RcRmFBcUJsuGoahk0JUkNd3scv4wxUVoA5WZ12bmGzPzjMy8faQnODPvyMzPAEdQBO33dm364nJ+TmYenZmLyu0yM2/NzG9l5sF9tvlAZl7eUcODmfm/mXlQZv5iwG/xXSOHoQi03e4AXpWZV3XUf3257tMUWeJi4E1lMCMz7y97uI8s2300Inr1FkMx5ORVmfnzctulmflD4I3l+ldExEs6N8jMCzLz7Zl5Xtc47D9k5kEUPaFr0iccjve4NflGOd83IlbrsX6kN/fCju+LSgZdSVLTPamc3zOG4QiDNPIn9B26lt9Xzp8yhnGTI9s8dYWrGkU5xnXziDiO4nZrAKdk5p97NP9yrzHPEbEBsHP58p/7DE04CngIWAd4dZ9yTs3M67oXZub5wCXlyzf0fzc99fueTPRxJ8KPKIY5PBl4TeeK8nP1lvLlCZNcVyMYdCVJWo6ImBrFgxUuiIg7yguyRi4aGul57b5jwU8phj3MAS6I4kEVy7urwZnl/NsRcWREvLhPL954fLKj5oeBq4F3lOt+Cbyvz3b9epC3pujJTuBnvRqU46XnlS/n9GrD6PePHdnvE7aNiA0i4rCIuKS80O+xjvd3etlstPM9ruNOtsx8jGXDKLp7qP8aeDrFf5BOm8y6msKL0SRJTTfyp+v1IyIG3asbEU+lCEXP7Vj8AHAPxfjbVSguLlu7c7vMvC4i/g74MsUFXS8t97eA4mKyr3cOTyj9A/A8YHvgo+X0UET8gmKc8InLu6PEKDoveFpCMT51PkUoPKUMVL306uWFoocRYGFm9rqQasQtXe279XqQQve6x20bEZtTXCC4UcfiRcBiiuC9OjAytnl5+6583BodB3wEeFVEbJSZt5fLR4YtnJKZD9ZT2nCzR1eS1HTzy/kaFCFx0I6mCLk3UPyZf4PyIRRPKS8aenG/DTPzBGBj4IPADylC+UyK8bzzIuLjXe3voriw6BXAFyl6i1enGCLw78BVEfGMcb6Pzguenp6Zm2fm3uX9hvuFXChC8WjWGGc9VUSf5d+kCLmXAa8EpmXmupm5Ufk92Wc524/3uLXIzN9T9DKvSvEglJGhI3uUTRy20IdBV5LUdD+j6MWDZb/4ByIiVgdeV77828z8r8y8p6vZRoyivIDtmMzck6KHcBuKXtQAPh3Fwy4622dm/jQzP5CZcyh6i98D3A1sAnxhRd/XgIz09E6NiNF6PkeCeb+e4dGGF4yMVf7LtuWdFLahCOB7ZObZPXqUR/2ejOe4Q+C4cj4yfGFfiv8EXZOZv6qnpOFn0JUkNVp5pf/I2Nb3j3J1/+NERJVeuw1Z1mPZPcxgxMurHA/+EmJ/TdHjeAvF7+FRr+zPzHsy8+vASO/vy6oeb4JdzrL/YOzcq0H54IWRhzdc1mc/o72fkXWd2/4lOGdmv+EHVb4nYz3uRBi5522Vz+JpFLd/27y8ld1I4LU3dxQGXUlSGxxKcYHVM4D/iIg1R2scEW8EPlRhv/exLMw9v8d+ngq8v88xVu+30/IOBY+WL9co20+JiNGunVnc2b5umXk3cH758qN97izxUYrbfN3Psv+MdPubiNike2F5H+KRuyZ8r2PVyH2EN4qIp/TY7vk8/iEd/Yz1uBNh5C4b6y2vYWY+BJxcvvw8sBXFZ2i0h2Ks9Ay6kqTGy8wrgAMoQunuwOXlXQ42GGkTEdMj4vURcT7Fjfqn9dzZ4/d7P8UdCQBOiIityn1NiYhdKYZN9OuN+6eIOC0i9uyqY6OI+CLF2N0Ezi1XrQtcFxGfiIjnR8QqXcf6bNnubIbHYRS9knOAU0bGD0fEOuX440PKdkdm5n199vEIcFb58ImR9/talt1F4NzMvLij/XyK3vAAvls+MIGIWC0iXk9xPke7OG68x50IV5fzV5b/aVqekXvqjgTxMzLzjsGX1SKZ6eTk5OTk1IqJ4slWt1MEyJFpEct6ZkemBcCOXduOrJvZtXxblj1iNilC1MjruyjG8CblU4U7tju665gLe9Tx8Y7263Wte6Tc/2Mdy64HnjHGc7Kg3PbwMW7X83z0aPceivGySRF67+6q+WRglVHqeifFQylGvled5/r3wFN7bLtXxzGzPK8Pl1/fRDF+NYEFAz7u4eX6E0fZ705dy3capZYNy+9xlu/n1nI/T2jbsc2vO+p8Td3/5oZ9skdXktQamfkDigu2DqD4U/ktFFeqr0oRIE6j+LP28zLzwor7/BWwHfADiluKrUYRkL5G8efjK/ts+gXgQIq7LVxL0QO5BnAzRY/yjlk8PWzEfRQPBDgauJTiQqhpFLcF+zXFI3W3yvLpY8MiM79G8Xji/6AIautQhPpzgX0yc9/s/TCJEdcBL6IYa7qQ4nZtCyj+PP+izLy1xzFPB3Ypj7GI4ntyE8Vjfbdm2S3NRjPm4w5aZt5JMb75vyi+30+meIzxs0fZ7L/K+a3AWRNaYAtE+b8DSZIkDbmIOJfiYrujMvOQ5bVf2Rl0JUmSGqAcj3xt+fK52eMRxno8hy5IkiQNuYhYB/gSxRCYMwy51dijK0mSNKQi4oMUT9abQTHG+yFgbmZeU2NZjWGPriRJ0vBaj+LitCXAJcBuhtzq7NGVJElSK9mjK0mSpFYy6EqSJKmVDLqSJElqpVXHu+Erpuzj4F5JjXXu0u9F3TVIkiaWPbqSJElqpXH36EqSmiMibgTWBRbUXIokjdVM4L7M3HisGxp0JWnlsO7UqVM3mD179gZ1FyJJYzF//nwWL148rm0NupK0clgwe/bsDebNm1d3HZI0JnPnzuWyyy5bMJ5tHaMrSZKkVjLoSpIkqZUMupIkSWolg64kSZJayaArSZKkVjLoSpIkqZUMupIkSWolg64kSZJayaArSZKkVjLoSpIkqZUMupIkSWolg64kSZJaadW6C5AkTY6r/riQmYf8eEzbLDhy9wmqRpImnj26kiRJaiWDriRJklrJoCtJkqRWMuhKkiSplQy6kjQEovD2iPhlRCyKiAcj4vKIODAiVqm7PklqIoOuJA2HbwHHAxsD3wW+AawOHAN8NyKixtokqZG8vZgk1Swi9gT2A24EtsnMO8vlqwGnAnsDbwVOrKlESWoke3QlqX6vL+efHwm5AJn5KHBY+fL9k16VJDWcQVeS6jejnN/QY93IsjkRsd7klCNJ7eDQBUmq30gv7sY91m3S8fUs4Jej7Sgi5vVZNWscdUlSo9mjK0n1O6OcfygiNhhZGBGrAkd0tFt/UquSpIazR1eS6ncKsC/wKuCaiPhv4EHg5cCmwO+B5wBLlrejzJzba3nZ0ztnUAVLUhPYoytJNcvMpcAewMHAbRR3YHg7cAvwEuCusukdtRQoSQ1lj64kDYHMfAz4fDn9RURMBbYCFgNXT35lktRc9uhK0nDbD1gTOLW83ZgkqSKDriQNgYhYt8eyvwKOBO4HPjXpRUlSwzl0QZKGw7kRsRi4ClgEbAG8GngYeH1m9rrHriRpFAZdSRoOpwFvorj7wlTgT8BxwJGZuaDGuiSpsQy6kjQEMvNfgX+tuw5JahPH6EqSJKmVDLqSJElqJYcuSNJKYsunT2fekbvXXYYkTRp7dCVJktRKBl1JkiS1kkFXkiRJrWTQlSRJUisZdCVJktRKBl1JkiS1kkFXkiRJrWTQlSRJUisZdCVJktRKBl1JGhIRsXtEnBMRt0TE4oi4ISK+FxHb1V2bJDWRQVeShkBEHAWcAcwBfgIcA1wGvA64OCL2rbE8SWqkVesuQJJWdhExAzgYuB14QWbe0bFuZ+A84FPAyfVUKEnNZI+uJNXv2RQ/j3/VGXIBMvN8YBHw5DoKk6QmM+hKUv1+DzwCbBMRG3auiIgdgWnAT+soTJKazKELUh83H7p95baPbP5g5babvvmKcVSjNsvMuyPio8C/AddExA+Au4BNgT2Ac4H31FehJDWTQVeShkBmHh0RC4ATgHd1rLoOOLF7SEM/ETGvz6pZK1ahJDWPQxckaQhExEeA04ATKXpy1wbmAjcA34mIf6mvOklqJnt0JalmEbETcBRwemZ+qGPVZRGxF3At8OGIODYzbxhtX5k5t88x5lHcukySVhr26EpS/V5Tzs/vXpGZDwKXUvy83noyi5KkpjPoSlL91ijn/W4hNrL8kUmoRZJaw6ArSfW7qJy/OyKe3rkiIl4F7AA8BFwy2YVJUpM5RleS6ncaxX1yXw7Mj4jTgduA2RTDGgI4JDPvqq9ESWoeg64k1Swzl0bEq4EDgDcBewFrAXcDZwJfzMxzaixRkhrJoCtJQyAzHwWOLidJ0gA4RleSJEmtZI/uELr9wOqPnr1v06WV28761LWV2y656+7KbdvqkelZue38lx1fue32Z/y/ym03eE3175kkSXo8e3QlSZLUSgZdSZIktZJBV5IkSa1k0JUkSVIrGXQlSZLUSgZdSZIktZJBV5IkSa1k0JUkSVIrGXQlSZLUSgZdSZIktZKPAJ4kD+y9beW2P/vI5yu3XStWr9x2p4sPqNx2nVN/WbltW63y8MTs9+nTFlZuu3hiSpAkaaVgj64kDYGI2D8icjnTkrrrlKQmsUdXkobDFcARfda9FNgFOGvSqpGkFjDoStIQyMwrKMLuE0TEL8ovvz5Z9UhSGzh0QZKGWERsCbwY+CPw45rLkaRGMehK0nB7Tzk/PjMdoytJY+DQBUkaUhExFdgXWAocV3GbeX1WzRpUXZLUFPboStLweiOwHnBWZt5ccy2S1Dj26ErS8Hp3Of9a1Q0yc26v5WVP75xBFCVJTWGPriQNoYjYHNgeuAU4s+ZyJKmRDLqSNJy8CE2SVpBDF1bAlBdUv7bjiH+pdB0JMLbH+kpqn4hYE9iP4iK042suR5Iayx5dSRo++wDrA2d6EZokjZ9BV5KGz8hFaD4JTZJWgEFXkoZIRMwGXoIXoUnSCnOMriQNkcycD0TddUhSG9ijK0mSpFYy6EqSJKmVDLqSJElqJYOuJEmSWsmgK0mSpFYy6EqSJKmVvL1YlylrrVW57dxvX1257a5Tqz+q/vpHF1duu+dXPlK57dNOvaRyW8Fb9zivctspY7gb1JRYOp5yJEnSGNmjK0mSpFYy6EqSJKmVDLqSJElqJYOuJEmSWsmgK0mSpFYy6EqSJKmVDLqSNEQi4qUR8f2IuDUiHi7n50TEq+uuTZKaxvvoStKQiIhDgU8DdwJnALcCGwJbAzsBZ9ZWnCQ1kEFXkoZAROxDEXJ/Crw+Mxd1rV+tlsIkqcEcuiBJNYuIKcBRwIPAm7tDLkBmPjrphUlSw9mj2+WevV5Que0nn/yVym3H8ljft/zDwZXb+ljfibN0DI/1XUpWbrvdBjdUbnvetKdVr2HRE7KRmmN7YGPgNOCeiNgd2BJ4CLg0M39RZ3GS1FQGXUmq31+V89uBy4Dnd66MiAuBN2Tmn5e3o4iY12fVrBWqUJIayKELklS/p5Tz9wJTgZcD0yh6dc8GdgS+V09pktRc9uhKUv1WKedB0XN7Zfn66ojYC7gWeFlEbLe8YQyZObfX8rKnd86gCpakJrBHV5Lqd085v6Ej5AKQmYspenUBtpnUqiSp4Qy6klS/35Xze/usHwnCUye+FElqD4OuJNXvQuAx4DkRsXqP9VuW8wWTVpEktYBBV5Jqlpl3At8FpgP/2LkuIl4B/DWwEPjJ5FcnSc3lxWiSNBw+BGwLfCIidgQuBZ4N7AUsAd6VmffWV54kNY9BV5KGQGbeERHbAodShNsXA4uAHwP/nJm/rLM+SWoig64kDYnMvJuiZ/dDddciSW1g0O1yz+zqj30diw8v2Lty23VOteNmosTcLSq3fcd6XxvDnqtfDH/xXZtVbrt00e1jqEGSJHXyYjRJkiS1kkFXkiRJrWTQlSRJUisZdCVJktRKBl1JkiS1kkFXkiRJrWTQlSRJUisZdCVJktRKBl1JkiS1kkFXkiRJreQjgLVSWbLW6pXbbrhK9cf6SpKk4WOPriQNgYhYEBHZZ7qt7vokqYns0ZWk4bEQOLrH8vsnuQ5JagWDriQNj3sz8/C6i5CktnDogiRJklrJHl1JGh5rRMS+wLOAB4DfABdm5pJ6y5KkZjLoStLwmAGc1LXsxoh4W2b+rI6CJKnJDLqSNBy+CVwEXA0sAjYB/h54N3BWRGyXmVcubycRMa/PqlmDKlSSmsKgK0lDIDOP6Fp0FfDeiLgf+DBwOLDXZNclSU1m0JWk4XYsRdDdsUrjzJzba3nZ0ztngHVJ0tDzrguSNNzuKOdr11qFJDWQPbpd1rotKredwhjaxtLxlKMKcoetKre97s2rVW47lu/vWDz8/vXH0Pr2CalBjbJdOb+h1iokqYHs0ZWkmkXEFhGxQY/lzwa+XL48eXKrkqTms0dXkuq3D3BIRJwP3Ehx14VNgd2BNYEzgc/VV54kNZNBV5Lqdz7wPGBriqEKawP3Aj+nuK/uSZmZtVUnSQ1l0JWkmpUPg/CBEJI0YI7RlSRJUisZdCVJktRKBl1JkiS1kkFXkiRJrWTQlSRJUit514UuTz356sptD9p/28pt3zTj0spt//l9f1u57YyT/q9y26WLFlVuOxZTpk2r3PaxrTar1O7ezdasvM+/Pfisym0PWO/6ym3H8iy7Q++YW32/v/ntGPYsSZLGyx5dSZIktZJBV5IkSa3k0AVJWklc9ceFzDzkx3WXIWnILDhy97pLmDD26EqSJKmVDLqSJElqJYOuJEmSWsmgK0mSpFYy6ErSkIqI/SIiy+mdddcjSU1j0JWkIRQRzwS+BNxfdy2S1FQGXUkaMhERwDeBu4Bjay5HkhrL++h2WXLvwsptL/nadpXbfuyw8yu33esTX6rc9vi/f1bltnc+Vv1RvVPIym03XO2Oym3ftu4FldtWNYWo3HYsj/UdizNu2KJy22dQ/THTWmkdCOwC7FTOJUnjYI+uJA2RiJgNHAkck5kX1l2PJDWZPbqSNCQiYlXgJOAPwMfHuY95fVbNGm9dktRUBl1JGh7/CGwNvCQzF9ddjCQ1nUFXkoZARGxD0Yv7+cz8xXj3k5lz++x/HjBnvPuVpCZyjK4k1axjyMK1wGE1lyNJrWHQlaT6rQM8F5gNPNTxkIgEPlm2+Ua57Oi6ipSkpnHogiTV72Hg+D7r5lCM2/058Dtg3MMaJGllY9CVpJqVF571fMRvRBxOEXS/lZnHTWZdktR0Dl2QJElSKxl0JUmS1EoOXVgBT/pG9aFyb736gMpt7/3Eg5XbXrzVKZXbjsXYHqtb/XHBVc2+oOdfcXva6IdrVG77laOOqdx2i9X956H6ZebhwOE1lyFJjWSPriRJklrJoCtJkqRW8m+zkrSS2PLp05l35O51lyFJk8YeXUmSJLWSQVeSJEmtZNCVJElSKxl0JUmS1EoGXUmSJLWSQVeSJEmtZNCVJElSK3kf3UkSl1xZue36Y7jN5WuYO45qht+mXD4h+73vyOqPC57C0spt49fTx1OOJEmaQPboSpIkqZUMupIkSWolg64kDYGIOCoi/icibo6IxRFxd0RcHhGfjIgn1V2fJDWRQVeShsNBwNrAucAxwHeAx4DDgd9ExDPrK02SmsmL0SRpOKybmQ91L4yIzwIfBz4GvG/Sq5KkBrNHV5KGQK+QWzq1nD9nsmqRpLYw6ErScHttOf9NrVVIUgM5dEGShkhEHAysA0wHXgS8hCLkHllx+3l9Vs0aSIGS1CAGXUkaLgcDG3W8/gmwf2b+uaZ6JKmxDLqSNEQycwZARGwEbE/Rk3t5RLwmMy+rsH3PxyWWPb1zBlmrJA07g65WKkuz+rD0pSyp3Hb6DdUfFyxVkZm3A6dHxGXAtcC3gS3rrUqSmsWL0SRpiGXmTcA1wBYRsWHd9UhSkxh0JWn4Pa2cV/8zgyTJoCtJdYuIWRExo8fyKeUDI54CXJKZ90x+dZLUXI7RlaT6vRL414i4ELgeuIvizgsvAzYBbgPeVV95ktRMBl1Jqt9Pga8DOwAvBNYDHqC4CO0k4IuZeXdt1UlSQxl0JalmmXkVcEDddUhS2zhGV5IkSa1k0JUkSVIrGXQlSZLUSgZdSZIktZIXo6nxHttlbuW2W65+8Rj2vObYi5EkSUPDHl1JkiS1kkFXkiRJrWTQlSRJUisZdCVJktRKBl1JkiS1kkFXkiRJrWTQlSRJUisZdCWpZhHxpIh4Z0ScHhHXRcTiiFgYET+PiHdEhD+rJWkcfGCEJNVvH+CrwK3A+cAfgI2A1wPHAa+KiH0yM+srUZKax6ArSfW7FtgD+HFmLh1ZGBEfBy4F9qYIvd+vpzxJaiaDrhpv1fPmVW571SPTKrfdYc1Hx1OONGaZeV6f5bdFxLHAZ4GdMOhK0pg47kuShtvI/7geq7UKSWogg64kDamIWBV4S/nyJ3XWIklN5NAFSRpeRwJbAmdm5tlVNoiIfmN5Zg2sKklqCHt0JWkIRcSBwIeB3wL71VyOJDWSPbqSNGQi4gDgGOAaYNfMvLvqtpk5t88+5wFzBlOhJDWDPbqSNEQi4oPAl4GrgJ0z87Z6K5Kk5jLoStKQiIiPAl8ArqAIuXfUW5EkNZtBV5KGQEQcRnHx2TyK4Qp31lySJDWeY3QlqWYR8VbgU8AS4CLgwIjobrYgM0+c5NIkqdEMupJUv43L+SrAB/u0+Rlw4mQUI0ltYdDVSmVKLK3elif0qEkTIjMPBw6vuQxJah3H6EqSJKmVDLqSJElqJYOuJEmSWsmgK0mSpFYy6EqSJKmVDLqSJElqJYOuJEmSWsmgK0mSpFYy6EqSJKmVDLqSJElqJR8BrMa76VPbVW77otUvrdz2+scerdx2+lV3V267pHJLSZK0IuzRlSRJUisZdCVJktRKBl1JGgIR8YaI+FJEXBQR90VERsTJddclSU3mGF1JGg6HAi8E7gduAWbVW44kNZ89upI0HA4CngusC/xdzbVIUivYoytJQyAzzx/5OiLqLEWSWsMeXUmSJLWSPbqS1CIRMa/PKsf8Slrp2KMrSZKkVrJHV5JaJDPn9lpe9vTOmeRyJKlWBl013qpb3le57WqxSuW2h978qsptl1xzbeW2kiRpcjh0QZIkSa1k0JUkSVIrGXQlSZLUSo7RlaQhEBF7AnuWL2eU8+0i4sTy6zsz8+BJLkuSGs2gK0nDYSvgrV3LNikngJsAg64kjYFDFyRpCGTm4ZkZo0wz665RkprGoCtJkqRWMuhKkiSplQy6kiRJaiUvRlPjLb5pWuW2h27c8+moPd35qY0rt12Nuyq3lSRJk8MeXUmSJLWSQVeSJEmtZNCVJElSKxl0JUmS1EoGXUmSJLWSQVeSJEmtZNCVJElSKxl0JUmS1EoGXUmSJLWSQVeShkREPCMiToiIP0XEwxGxICKOjoj1665NkprIRwCr8TY76JeV214xhv2uxv+OuRZpvCJiU+AS4CnAD4HfAtsAHwBeGRE7ZKbPmpakMbBHV5KGw79ThNwDM3PPzDwkM3cBvgA8D/hsrdVJUgMZdCWpZhGxCbAbsAD4StfqTwIPAPtFxNqTXJokNZpBV5Lqt0s5Pyczl3auyMxFwMXAWsCLJ7swSWoyx+hKUv2eV86v7bP+9xQ9vs8F/me0HUXEvD6rZo2vNElqLnt0Jal+08v5wj7rR5avN/GlSFJ72KMrScMvynkur2Fmzu25g6Knd84gi5KkYWePriTVb6THdnqf9et2tZMkVWDQlaT6/a6cP7fP+ueU835jeCVJPRh0Jal+55fz3SLicT+XI2IasAOwGKj+dBRJkkFXkuqWmdcD5wAzgQO6Vh8BrA18OzMfmOTSJKnRvBhNkobD+ygeAfzFiNgVmA9sC+xMMWThEzXWJkmNZI+uJA2Bslf3RcCJFAH3w8CmwBeB7TLzrvqqk6RmskdXkoZEZt4MvK3uOiSpLezRlSRJUisZdCVJktRKBl1JkiS1kkFXkiRJrWTQlSRJUisZdCVJktRKBl1JkiS1kkFXkiRJrWTQlSRJUisZdCVJktRKBl1JkiS1kkFXkiRJrWTQlSRJUisZdCVJktRKBl1JkiS10qp1FyBJmhQz58+fz9y5c+uuQ5LGZP78+QAzx7OtQVeSVg7rLF68eMlll112Zd2FDJFZ5fy3tVYxXDwnT+Q5eaLJPiczgfvGs6FBV5JWDlcBZKZduqWImAeek06ekyfynDxRk86JY3QlSZLUSuPu0T136fdikIVIkiRJg2SPriRJklrJoCtJkqRWMuhKkiSplSIz665BkiRJGjh7dCVJktRKBl1JkiS1kkFXkiRJrWTQlSRJUisZdCVJktRKBl1JkiS1kkFXkiRJrWTQlaQhFhHPiIgTIuJPEfFwRCyIiKMjYv2J3k9EbB8RZ0bE3RHxYET8JiI+GBGrrPg7G78VPScR8aSIeGdEnB4R10XE4ohYGBE/j4h3RMQTfjdGxMyIyFGmUwb/TqsbxOek3Kbf+7ttlO3a+jnZfznf84yIJV3bDO3nJCLeEBFfioiLIuK+sp6Tx7mvxvw88YERkjSkImJT4BLgKcAPgd8C2wA7A78DdsjMuyZiPxHxOuD7wEPAd4G7gdcCzwNOy8x9BvAWx2wQ5yQi3gt8FbgVOB/4A7AR8HpgOsX73ic7fkFGxEzgRuBK4Ac9dntVZp62Am9t3Ab4OVkArAcc3WP1/Zn5uR7btPlzshWwZ5/VLwV2AX6cma/p2GYmw/s5uQJ4IXA/cAswC/hOZu47xv006+dJZjo5OTk5DeEEnA0k8P6u5f9WLj92IvYDrAvcATwMvKhj+ZoUv+ASeFNTzwlFQHktMKVr+QyK0JvA3l3rZpbLT6z7czGBn5MFwIIxHLfVn5Pl7P8X5X72aNDnZGfgOUAAO5V1njzR57buz0ntJ97JycnJ6YkTsEn5C+DGHoFsGkWvzAPA2oPeD/D2cptv9djfLuW6nzX1nCznGB8vj/GlruVDGWAGeU7GEXRXys8JsGW5/1uAVZrwOenxHsYVdJv488QxupI0nHYp5+dk5tLOFZm5CLgYWAt48QTsZ2Sbn/TY34XAg8D2EbHG8t7EgA3qnIzm0XL+WJ/1T4uI90TEx8v5C1bgWIMw6HOyRkTsW76/D0TEzqOMoVxZPyfvKefHZ+aSPm2G7XMyKI37eWLQlaTh9Lxyfm2f9b8v58+dgP303SYzH6PozVmVondnMg3qnPQUEasCbylf9vqlDPAK4Fjgs+X8yog4PyKeNZ5jDsCgz8kM4CSK93c0cB7w+4h42ViO3dbPSURMBfYFlgLHjdJ02D4ng9K4nycGXUkaTtPL+cI+60eWrzcB+xnUsQdtous6kuLP0mdm5tld6x4EPg3MBdYvp5dRXMy2E/A/EbH2OI+7IgZ5Tr4J7EoRdtcGng98jeLP8WdFxAsn8NiDNJF1vbHc7qzMvLnH+mH9nAxK436eGHQlqZminK/orXPGs59BHXvQxl1XRBwIfJjiCvL9utdn5h2Z+Y+ZeVlm3ltOFwK7Ab8CNgPeOf7SJ0zlc5KZR2TmeZl5e2Y+mJlXZeZ7KS4ymgocPlHHnmQrUte7y/nXeq1s8OdkUIbu54lBV5KG00gvx/Q+69ftajfI/Qzq2IM2IXVFxAHAMcA1wM6ZeXfVbcs/vY78CXvHsRx3QCbje3VsOe9+fyvb52RzYHuKi9DOHMu2Q/A5GZTG/Twx6ErScPpdOe83jvA55bzfWLkV2U/fbcpxrBtTXKx1w3KOPWiDOid/EREfBL4MXEURcvs+GGEUfy7ndfxJeuDnpIc7ynn3+1tpPielKhehjabOz8mgNO7niUFXkobT+eV8t+h6UldETAN2ABYDv5yA/ZxXzl/ZY387UlxVfUlmPry8NzFggzonI9t8FPgCcAVFyL1j9C36GrnCfLIDHQz4nPSxXTnvfn8rxeek3G5NiiEtS4Hjx1lXnZ+TQWnczxODriQNocy8HjiH4kKgA7pWH0HRK/TtzHwAICJWi4hZ5VOLxr2f0mnAncCbIuJFIwvLX/afKV9+ddxvbpwGdU7KdYdRXHw2D9g1M+8c7dgRsW1ErN5j+S7AQeXLcT1OdUUM6pxExBYRsUH3/iPi2RQ93vDE99f6z0mHfSguLDuzz0VolPsays/JWLXp54mPAJakIdXjUZvzgW0pnnB0LbB9lo/a7Hj06E2ZOXO8++nYZk+KX1APAadQPLJzD8pHdgJvzBp+gQzinETEW4ETgSXAl+g9NnBBZp7Ysc0FwBbABRRjNAFewLJ7hB6WmZ+hBgM6J4cDh1D02N0ILAI2BXaneILVmcBemflI17H3pKWfk679XQS8hOJJaD8a5bgXMLyfkz1Z9kjjGcBfU/QuX1QuuzMzDy7bzqQtP08m6kkUTk5OTk4rPgHPpLjt063AI8BNFBdObdDVbibFVcsLVmQ/XdvsQBFw7qH4c+T/UfRKrTKo91fHOaG4e0AuZ7qga5t3AGdQPD3sforHmf4B+C7w0qZ/TihugfWfFHeduJfiwRl/Bs6luLdwrGyfk471s8v1Ny/vPQ3z56TC535BR9vW/DyxR1eSJEmt5BhdSZIktZJBV5IkSa1k0JUkSVIrGXQlSZLUSgZdSZIktZJBV5IkSa1k0JUkSVIrGXQlSZLUSgZdSZIktZJBV5IkSa1k0JUkSVIrGXQlSZLUSgZdSZIktZJBV5IkSa1k0JUkSVIrGXQlSZLUSgZdSZIktdL/B529L7XM53T1AAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "image/png": {
       "width": 349,
       "height": 195
      },
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Run this cell with your model to make sure it works and predicts well for the validation data\n",
    "images, labels = next(iter(testloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 3:</h3>\n",
    "  <p>Write the code for adding <strong style=\"color:#01ff84\">Early Stopping with patience = 2</strong> to the training loop from scratch.</p>\n",
    "  <p><strong style=\"color:#01ff84\">Hint:</strong> Monitor the Validation loss every epoch, and if in 2 epochs, the validation loss does not improve, stop the training loop with <code>break</code>.</p>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1/10\n",
      "\tIteration: 0\t Loss: 0.0465\n",
      "\tIteration: 40\t Loss: 1.8477\n",
      "\tIteration: 80\t Loss: 1.8434\n",
      "\tIteration: 120\t Loss: 1.8484\n",
      "\tIteration: 160\t Loss: 1.8456\n",
      "\tIteration: 200\t Loss: 1.8425\n",
      "\tIteration: 240\t Loss: 1.8776\n",
      "\tIteration: 280\t Loss: 1.8377\n",
      "\tIteration: 320\t Loss: 1.8706\n",
      "\tIteration: 360\t Loss: 1.8384\n",
      "\tIteration: 400\t Loss: 1.8666\n",
      "\tIteration: 440\t Loss: 1.8600\n",
      "\tIteration: 480\t Loss: 1.8413\n",
      "\tIteration: 520\t Loss: 1.8664\n",
      "\tIteration: 560\t Loss: 1.8021\n",
      "\tIteration: 600\t Loss: 1.8967\n",
      "\tIteration: 640\t Loss: 1.8264\n",
      "\tIteration: 680\t Loss: 1.8441\n",
      "\tIteration: 720\t Loss: 1.8423\n",
      "\tIteration: 760\t Loss: 1.8205\n",
      "\tIteration: 800\t Loss: 1.8438\n",
      "\tIteration: 840\t Loss: 1.8642\n",
      "\tIteration: 880\t Loss: 1.8592\n",
      "\tIteration: 920\t Loss: 1.8753\n",
      "\tIteration: 960\t Loss: 1.8392\n",
      "\tIteration: 1000\t Loss: 1.8540\n",
      "\tIteration: 1040\t Loss: 1.8587\n",
      "\tIteration: 1080\t Loss: 1.8459\n",
      "\tIteration: 1120\t Loss: 1.8607\n",
      "\tIteration: 1160\t Loss: 1.8611\n",
      "\tIteration: 1200\t Loss: 1.8532\n",
      "\tIteration: 1240\t Loss: 1.8677\n",
      "\tIteration: 1280\t Loss: 1.8642\n",
      "\tIteration: 1320\t Loss: 1.8360\n",
      "\tIteration: 1360\t Loss: 1.8745\n",
      "\tIteration: 1400\t Loss: 1.8609\n",
      "\tIteration: 1440\t Loss: 1.8586\n",
      "\tIteration: 1480\t Loss: 1.8675\n",
      "\tIteration: 1520\t Loss: 1.8583\n",
      "\tIteration: 1560\t Loss: 1.8524\n",
      "\tIteration: 1600\t Loss: 1.8587\n",
      "\tIteration: 1640\t Loss: 1.8636\n",
      "\tIteration: 1680\t Loss: 1.8538\n",
      "\tIteration: 1720\t Loss: 1.8536\n",
      "\tIteration: 1760\t Loss: 1.8539\n",
      "\tIteration: 1800\t Loss: 1.8471\n",
      "\tIteration: 1840\t Loss: 1.8703\n",
      "\tIteration: 1880\t Loss: 1.8500\n",
      "\tIteration: 1920\t Loss: 1.8427\n",
      "\tIteration: 1960\t Loss: 1.8508\n",
      "\tIteration: 2000\t Loss: 1.8652\n",
      "\tIteration: 2040\t Loss: 1.8790\n",
      "\tIteration: 2080\t Loss: 1.8660\n",
      "\tIteration: 2120\t Loss: 1.8489\n",
      "\tIteration: 2160\t Loss: 1.8400\n",
      "\tIteration: 2200\t Loss: 1.8367\n",
      "\tIteration: 2240\t Loss: 1.8327\n",
      "\tIteration: 2280\t Loss: 1.8412\n",
      "\tIteration: 2320\t Loss: 1.8362\n",
      "\tIteration: 2360\t Loss: 1.8479\n",
      "\tIteration: 2400\t Loss: 1.8465\n",
      "\tIteration: 2440\t Loss: 1.8391\n",
      "\tIteration: 2480\t Loss: 1.8546\n",
      "\tIteration: 2520\t Loss: 1.8098\n",
      "\tIteration: 2560\t Loss: 1.8637\n",
      "\tIteration: 2600\t Loss: 1.8535\n",
      "\tIteration: 2640\t Loss: 1.8686\n",
      "\tIteration: 2680\t Loss: 1.8481\n",
      "\tIteration: 2720\t Loss: 1.8582\n",
      "\tIteration: 2760\t Loss: 1.8453\n",
      "\tIteration: 2800\t Loss: 1.8623\n",
      "\tIteration: 2840\t Loss: 1.8835\n",
      "\tIteration: 2880\t Loss: 1.8677\n",
      "\tIteration: 2920\t Loss: 1.8559\n",
      "\tIteration: 2960\t Loss: 1.8581\n",
      "\tIteration: 3000\t Loss: 1.8448\n",
      "\tIteration: 3040\t Loss: 1.8386\n",
      "\tIteration: 3080\t Loss: 1.8407\n",
      "\tIteration: 3120\t Loss: 1.8295\n",
      "\tIteration: 3160\t Loss: 1.8278\n",
      "\tIteration: 3200\t Loss: 1.8529\n",
      "\tIteration: 3240\t Loss: 1.8729\n",
      "\tIteration: 3280\t Loss: 1.8438\n",
      "\tIteration: 3320\t Loss: 1.8292\n",
      "\tIteration: 3360\t Loss: 1.8405\n",
      "\tIteration: 3400\t Loss: 1.8362\n",
      "\tIteration: 3440\t Loss: 1.8471\n",
      "\tIteration: 3480\t Loss: 1.8569\n",
      "\tIteration: 3520\t Loss: 1.8602\n",
      "\tIteration: 3560\t Loss: 1.8328\n",
      "\tIteration: 3600\t Loss: 1.8607\n",
      "\tIteration: 3640\t Loss: 1.8282\n",
      "\tIteration: 3680\t Loss: 1.8715\n",
      "\tIteration: 3720\t Loss: 1.8586\n",
      "0.6178\n",
      "Epoch: 2/10\n",
      "\tIteration: 0\t Loss: 0.0442\n",
      "\tIteration: 40\t Loss: 1.8471\n",
      "\tIteration: 80\t Loss: 1.8521\n",
      "\tIteration: 120\t Loss: 1.8575\n",
      "\tIteration: 160\t Loss: 1.8491\n",
      "\tIteration: 200\t Loss: 1.8403\n",
      "\tIteration: 240\t Loss: 1.8081\n",
      "\tIteration: 280\t Loss: 1.8504\n",
      "\tIteration: 320\t Loss: 1.8582\n",
      "\tIteration: 360\t Loss: 1.8297\n",
      "\tIteration: 400\t Loss: 1.8129\n",
      "\tIteration: 440\t Loss: 1.8424\n",
      "\tIteration: 480\t Loss: 1.8421\n",
      "\tIteration: 520\t Loss: 1.8321\n",
      "\tIteration: 560\t Loss: 1.8528\n",
      "\tIteration: 600\t Loss: 1.8513\n",
      "\tIteration: 640\t Loss: 1.8566\n",
      "\tIteration: 680\t Loss: 1.8326\n",
      "\tIteration: 720\t Loss: 1.8452\n",
      "\tIteration: 760\t Loss: 1.8404\n",
      "\tIteration: 800\t Loss: 1.8322\n",
      "\tIteration: 840\t Loss: 1.8467\n",
      "\tIteration: 880\t Loss: 1.8825\n",
      "\tIteration: 920\t Loss: 1.8266\n",
      "\tIteration: 960\t Loss: 1.8273\n",
      "\tIteration: 1000\t Loss: 1.8948\n",
      "\tIteration: 1040\t Loss: 1.8453\n",
      "\tIteration: 1080\t Loss: 1.8233\n",
      "\tIteration: 1120\t Loss: 1.8636\n",
      "\tIteration: 1160\t Loss: 1.8374\n",
      "\tIteration: 1200\t Loss: 1.8541\n",
      "\tIteration: 1240\t Loss: 1.8963\n",
      "\tIteration: 1280\t Loss: 1.8747\n",
      "\tIteration: 1320\t Loss: 1.8695\n",
      "\tIteration: 1360\t Loss: 1.8018\n",
      "\tIteration: 1400\t Loss: 1.8787\n",
      "\tIteration: 1440\t Loss: 1.8245\n",
      "\tIteration: 1480\t Loss: 1.8636\n",
      "\tIteration: 1520\t Loss: 1.8765\n",
      "\tIteration: 1560\t Loss: 1.8363\n",
      "\tIteration: 1600\t Loss: 1.8492\n",
      "\tIteration: 1640\t Loss: 1.8653\n",
      "\tIteration: 1680\t Loss: 1.8497\n",
      "\tIteration: 1720\t Loss: 1.8428\n",
      "\tIteration: 1760\t Loss: 1.8666\n",
      "\tIteration: 1800\t Loss: 1.8384\n",
      "\tIteration: 1840\t Loss: 1.8301\n",
      "\tIteration: 1880\t Loss: 1.8535\n",
      "\tIteration: 1920\t Loss: 1.8666\n",
      "\tIteration: 1960\t Loss: 1.8660\n",
      "\tIteration: 2000\t Loss: 1.8680\n",
      "\tIteration: 2040\t Loss: 1.8461\n",
      "\tIteration: 2080\t Loss: 1.8815\n",
      "\tIteration: 2120\t Loss: 1.8746\n",
      "\tIteration: 2160\t Loss: 1.8444\n",
      "\tIteration: 2200\t Loss: 1.8375\n",
      "\tIteration: 2240\t Loss: 1.8318\n",
      "\tIteration: 2280\t Loss: 1.8500\n",
      "\tIteration: 2320\t Loss: 1.8282\n",
      "\tIteration: 2360\t Loss: 1.8906\n",
      "\tIteration: 2400\t Loss: 1.8741\n",
      "\tIteration: 2440\t Loss: 1.8752\n",
      "\tIteration: 2480\t Loss: 1.8326\n",
      "\tIteration: 2520\t Loss: 1.8445\n",
      "\tIteration: 2560\t Loss: 1.8261\n",
      "\tIteration: 2600\t Loss: 1.8394\n",
      "\tIteration: 2640\t Loss: 1.8590\n",
      "\tIteration: 2680\t Loss: 1.8264\n",
      "\tIteration: 2720\t Loss: 1.8179\n",
      "\tIteration: 2760\t Loss: 1.8229\n",
      "\tIteration: 2800\t Loss: 1.7967\n",
      "\tIteration: 2840\t Loss: 1.8724\n",
      "\tIteration: 2880\t Loss: 1.8300\n",
      "\tIteration: 2920\t Loss: 1.8161\n",
      "\tIteration: 2960\t Loss: 1.8557\n",
      "\tIteration: 3000\t Loss: 1.8528\n",
      "\tIteration: 3040\t Loss: 1.8360\n",
      "\tIteration: 3080\t Loss: 1.8304\n",
      "\tIteration: 3120\t Loss: 1.8429\n",
      "\tIteration: 3160\t Loss: 1.8559\n",
      "\tIteration: 3200\t Loss: 1.8234\n",
      "\tIteration: 3240\t Loss: 1.8426\n",
      "\tIteration: 3280\t Loss: 1.8589\n",
      "\tIteration: 3320\t Loss: 1.8377\n",
      "\tIteration: 3360\t Loss: 1.8470\n",
      "\tIteration: 3400\t Loss: 1.8638\n",
      "\tIteration: 3440\t Loss: 1.8393\n",
      "\tIteration: 3480\t Loss: 1.8451\n",
      "\tIteration: 3520\t Loss: 1.8428\n",
      "\tIteration: 3560\t Loss: 1.8506\n",
      "\tIteration: 3600\t Loss: 1.8461\n",
      "\tIteration: 3640\t Loss: 1.7994\n",
      "\tIteration: 3680\t Loss: 1.8389\n",
      "\tIteration: 3720\t Loss: 1.8613\n",
      "0.6259\n",
      "Epoch: 3/10\n",
      "\tIteration: 0\t Loss: 0.0475\n",
      "\tIteration: 40\t Loss: 1.8492\n",
      "\tIteration: 80\t Loss: 1.8177\n",
      "\tIteration: 120\t Loss: 1.8213\n",
      "\tIteration: 160\t Loss: 1.8349\n",
      "\tIteration: 200\t Loss: 1.8226\n",
      "\tIteration: 240\t Loss: 1.8737\n",
      "\tIteration: 280\t Loss: 1.8130\n",
      "\tIteration: 320\t Loss: 1.8554\n",
      "\tIteration: 360\t Loss: 1.8585\n",
      "\tIteration: 400\t Loss: 1.8482\n",
      "\tIteration: 440\t Loss: 1.8630\n",
      "\tIteration: 480\t Loss: 1.8525\n",
      "\tIteration: 520\t Loss: 1.8427\n",
      "\tIteration: 560\t Loss: 1.8592\n",
      "\tIteration: 600\t Loss: 1.8411\n",
      "\tIteration: 640\t Loss: 1.8757\n",
      "\tIteration: 680\t Loss: 1.8578\n",
      "\tIteration: 720\t Loss: 1.8654\n",
      "\tIteration: 760\t Loss: 1.8024\n",
      "\tIteration: 800\t Loss: 1.8225\n",
      "\tIteration: 840\t Loss: 1.8232\n",
      "\tIteration: 880\t Loss: 1.8366\n",
      "\tIteration: 920\t Loss: 1.8176\n",
      "\tIteration: 960\t Loss: 1.8800\n",
      "\tIteration: 1000\t Loss: 1.8564\n",
      "\tIteration: 1040\t Loss: 1.8443\n",
      "\tIteration: 1080\t Loss: 1.8245\n",
      "\tIteration: 1120\t Loss: 1.8136\n",
      "\tIteration: 1160\t Loss: 1.8624\n",
      "\tIteration: 1200\t Loss: 1.8559\n",
      "\tIteration: 1240\t Loss: 1.8321\n",
      "\tIteration: 1280\t Loss: 1.8251\n",
      "\tIteration: 1320\t Loss: 1.8410\n",
      "\tIteration: 1360\t Loss: 1.8698\n",
      "\tIteration: 1400\t Loss: 1.8329\n",
      "\tIteration: 1440\t Loss: 1.8529\n",
      "\tIteration: 1480\t Loss: 1.8446\n",
      "\tIteration: 1520\t Loss: 1.8219\n",
      "\tIteration: 1560\t Loss: 1.8355\n",
      "\tIteration: 1600\t Loss: 1.8135\n",
      "\tIteration: 1640\t Loss: 1.8448\n",
      "\tIteration: 1680\t Loss: 1.8562\n",
      "\tIteration: 1720\t Loss: 1.8101\n",
      "\tIteration: 1760\t Loss: 1.8741\n",
      "\tIteration: 1800\t Loss: 1.8055\n",
      "\tIteration: 1840\t Loss: 1.8568\n",
      "\tIteration: 1880\t Loss: 1.8780\n",
      "\tIteration: 1920\t Loss: 1.8229\n",
      "\tIteration: 1960\t Loss: 1.8482\n",
      "\tIteration: 2000\t Loss: 1.8673\n",
      "\tIteration: 2040\t Loss: 1.8412\n",
      "\tIteration: 2080\t Loss: 1.8475\n",
      "\tIteration: 2120\t Loss: 1.8266\n",
      "\tIteration: 2160\t Loss: 1.8438\n",
      "\tIteration: 2200\t Loss: 1.8435\n",
      "\tIteration: 2240\t Loss: 1.8420\n",
      "\tIteration: 2280\t Loss: 1.8773\n",
      "\tIteration: 2320\t Loss: 1.8286\n",
      "\tIteration: 2360\t Loss: 1.8442\n",
      "\tIteration: 2400\t Loss: 1.8290\n",
      "\tIteration: 2440\t Loss: 1.8114\n",
      "\tIteration: 2480\t Loss: 1.8174\n",
      "\tIteration: 2520\t Loss: 1.8581\n",
      "\tIteration: 2560\t Loss: 1.8316\n",
      "\tIteration: 2600\t Loss: 1.8333\n",
      "\tIteration: 2640\t Loss: 1.8723\n",
      "\tIteration: 2680\t Loss: 1.8641\n",
      "\tIteration: 2720\t Loss: 1.8280\n",
      "\tIteration: 2760\t Loss: 1.8411\n",
      "\tIteration: 2800\t Loss: 1.8309\n",
      "\tIteration: 2840\t Loss: 1.8229\n",
      "\tIteration: 2880\t Loss: 1.8174\n",
      "\tIteration: 2920\t Loss: 1.8875\n",
      "\tIteration: 2960\t Loss: 1.8769\n",
      "\tIteration: 3000\t Loss: 1.8089\n",
      "\tIteration: 3040\t Loss: 1.8471\n",
      "\tIteration: 3080\t Loss: 1.8204\n",
      "\tIteration: 3120\t Loss: 1.8476\n",
      "\tIteration: 3160\t Loss: 1.8655\n",
      "\tIteration: 3200\t Loss: 1.8564\n",
      "\tIteration: 3240\t Loss: 1.8173\n",
      "\tIteration: 3280\t Loss: 1.8794\n",
      "\tIteration: 3320\t Loss: 1.8538\n",
      "\tIteration: 3360\t Loss: 1.8405\n",
      "\tIteration: 3400\t Loss: 1.8148\n",
      "\tIteration: 3440\t Loss: 1.8631\n",
      "\tIteration: 3480\t Loss: 1.8415\n",
      "\tIteration: 3520\t Loss: 1.8534\n",
      "\tIteration: 3560\t Loss: 1.8659\n",
      "\tIteration: 3600\t Loss: 1.8700\n",
      "\tIteration: 3640\t Loss: 1.8315\n",
      "\tIteration: 3680\t Loss: 1.8310\n",
      "\tIteration: 3720\t Loss: 1.8540\n",
      "0.6285\n"
     ]
    }
   ],
   "source": [
    "## TODO: Your training loop here\n",
    "\n",
    "epochs = 10\n",
    "print_every = 40\n",
    "accs_test = []\n",
    "patience = 2\n",
    "epsilon = 0.005\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    print(f\"Epoch: {e+1}/{epochs}\")\n",
    "\n",
    "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
    "\n",
    "        # Flatten EMNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)   # 1) Forward pass\n",
    "        loss = criterion(output, labels) # 2) Compute loss\n",
    "        loss.backward()                  # 3) Backward pass\n",
    "        optimizer.step()                 # 4) Update model\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
    "            running_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        acc, y_pred, y_true = check_accuracy(testloader, model)\n",
    "        accs_test.append(acc)\n",
    "    model.train()\n",
    "    if len(accs_test) > (patience - 1):\n",
    "        if accs_test[-1] - accs_test[-patience] < epsilon:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Optional:</h3>\n",
    "  <p>Don't you want to use MNIST? Try EMNIST instead! Maybe using the first 10 letters of the alphabet!</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:35:26.981584Z",
     "start_time": "2021-05-26T22:35:26.954522Z"
    }
   },
   "outputs": [],
   "source": [
    "# we will need a custom visualization function\n",
    "def view_classify_emnist(img, ps):\n",
    "\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(list(\"abcdefghij\"), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:50:57.571260Z",
     "start_time": "2021-05-26T22:50:57.322172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data (Preprocessing)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5)) ])\n",
    "def my_collate(batch):\n",
    "    modified_batch = []\n",
    "    for item in batch:\n",
    "        image, label = item\n",
    "        if label < 10: # only the first ten letters\n",
    "            modified_batch.append(item)\n",
    "    return torch.utils.data._utils.collate.default_collate(modified_batch)\n",
    "\n",
    "\n",
    "# Download and load the training data\n",
    "trainset    = datasets.EMNIST('EMNIST_data/', split=\"letters\", download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "# Download and load the test data\n",
    "testset    = datasets.EMNIST('EMNIST_data/', split=\"letters\", download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:51:02.493175Z",
     "start_time": "2021-05-26T22:51:02.464301Z"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:51:03.118421Z",
     "start_time": "2021-05-26T22:51:02.978678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[5].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:51:06.653639Z",
     "start_time": "2021-05-26T22:51:06.647991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 9, 6, 7, 5, 1, 9, 3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python395jvsc74a57bd05d8eb55396b26e444e25830983e23d02f9d742a022e83389ffb69c4e4a8d7f54",
   "display_name": "Python 3.9.5 64-bit ('deep_learning': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "metadata": {
   "interpreter": {
    "hash": "5d8eb55396b26e444e25830983e23d02f9d742a022e83389ffb69c4e4a8d7f54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}