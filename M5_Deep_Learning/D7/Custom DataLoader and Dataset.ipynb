{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "threaded-court",
   "metadata": {},
   "source": [
    "Training a neural network, data is often processed in batches. For this reason, it is convenient to load the data in a\n",
    "\n",
    "```\n",
    "for epoch in range(epochs):\n",
    "    for x_batch, y_batch in data:\n",
    "        train\n",
    "```\n",
    "fashion, where `x_batch, y_batch` contain respectively a batch of samples features and labels.\n",
    "\n",
    "If we have something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "verified-joshua",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:01:00.351865Z",
     "start_time": "2021-06-02T05:01:00.348363Z"
    }
   },
   "outputs": [],
   "source": [
    "X = [1,2,3,4]\n",
    "\n",
    "y = [0,0,1,1]\n",
    "\n",
    "data = X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-treat",
   "metadata": {},
   "source": [
    "we don't get the desired behaviour. In fact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thick-stomach",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:01:01.078882Z",
     "start_time": "2021-06-02T05:01:01.068175Z"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1e8dd179592f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for x, y in data:\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-immunology",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:01:21.510046Z",
     "start_time": "2021-06-02T05:01:21.501972Z"
    }
   },
   "source": [
    "A way to achieve it is by using the `zip` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "altered-final",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:01:38.334914Z",
     "start_time": "2021-06-02T05:01:38.330524Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<zip at 0x7face81459c0>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data = zip(X,y)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tutorial-episode",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:01:48.885847Z",
     "start_time": "2021-06-02T05:01:48.881626Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 0\n2 0\n3 1\n4 1\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(X, y):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-warrior",
   "metadata": {},
   "source": [
    "Now it's much better! But what if we want to adjust everything in batches? What if we have data that are indexed in a csv file?\n",
    "What if we have images and we want to apply transformation to the data in the exact moment when we load them to process them? (The alternative is to preprocess all of them before loading it: it may cause a lot of storage usage! In fact, if you want to perform data augmentation for images for example, you will create a lot of copies - with slight changes - of the data!)\n",
    "\n",
    "When you have used Pytorch so far you have loaded standard datasets (MNIST, FashionMNIST...) and you have taken advantage of the Pytorch Dataloader already. Let's do the same for a custom dataset, but for that we need to override some of the method given by that class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-metabolism",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:08:37.583072Z",
     "start_time": "2021-06-02T05:08:37.570456Z"
    }
   },
   "source": [
    "As usual, we import the needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cleared-aaron",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:09:06.744694Z",
     "start_time": "2021-06-02T05:09:03.737995Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-electron",
   "metadata": {},
   "source": [
    "We need to inherit from the Dataset class (that we have imported from torch.utils.data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "expired-clerk",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:10:12.012741Z",
     "start_time": "2021-06-02T05:10:12.005962Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-peace",
   "metadata": {},
   "source": [
    "Awesome! Now we need to override our constructor and the `__getitem__` method. What is this about? It is the method that allows your CustomDataset to be *indexed* in a `dataset[i]` fashion.\n",
    "\n",
    "In addition, we want to override the `__len__` method as well, that is the method that returns the amount of data samples in the dataset that we are processing.\n",
    "\n",
    "Ok but the shuffling?! *I want to shuffle the data!* Don't worry, the rest of the methods from the `Dataset`class will still be working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incorporate-offense",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:30:20.755968Z",
     "start_time": "2021-06-02T05:30:20.736754Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        pass\n",
    "    def __getitem__(self, index):\n",
    "        # we want to be index like dataset[index]\n",
    "        # to get the index-th batch\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        # to retrieve the total samples by doing len(dataset)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-radical",
   "metadata": {},
   "source": [
    "As you can see, in the constructor I added `csv_file` as argument. The reason is that I want to create a dataloader for a dataset containing houses information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mental-skirt",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:35:21.999615Z",
     "start_time": "2021-06-02T05:35:21.995141Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = \"https://people.sc.fsu.edu/~jburkardt/data/csv/homes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "choice-method",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:35:23.163211Z",
     "start_time": "2021-06-02T05:35:22.683242Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "narrative-locator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:35:23.508847Z",
     "start_time": "2021-06-02T05:35:23.476008Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Sell   \"List\"   \"Living\"   \"Rooms\"   \"Beds\"   \"Baths\"   \"Age\"   \"Acres\"  \\\n",
       "0    142      160         28        10        5         3      60      0.28   \n",
       "1    175      180         18         8        4         1      12      0.43   \n",
       "2    129      132         13         6        3         1      41      0.33   \n",
       "3    138      140         17         7        3         1      22      0.46   \n",
       "4    232      240         25         8        4         3       5      2.05   \n",
       "5    135      140         18         7        4         3       9      0.57   \n",
       "6    150      160         20         8        4         3      18      4.00   \n",
       "7    207      225         22         8        4         2      16      2.22   \n",
       "8    271      285         30        10        5         2      30      0.53   \n",
       "9     89       90         10         5        3         1      43      0.30   \n",
       "10   153      157         22         8        3         3      18      0.38   \n",
       "11    87       90         16         7        3         1      50      0.65   \n",
       "12   234      238         25         8        4         2       2      1.61   \n",
       "13   106      116         20         8        4         1      13      0.22   \n",
       "14   175      180         22         8        4         2      15      2.06   \n",
       "15   165      170         17         8        4         2      33      0.46   \n",
       "16   166      170         23         9        4         2      37      0.27   \n",
       "17   136      140         19         7        3         1      22      0.63   \n",
       "18   148      160         17         7        3         2      13      0.36   \n",
       "19   151      153         19         8        4         2      24      0.34   \n",
       "20   180      190         24         9        4         2      10      1.55   \n",
       "21   293      305         26         8        4         3       6      0.46   \n",
       "22   167      170         20         9        4         2      46      0.46   \n",
       "23   190      193         22         9        5         2      37      0.48   \n",
       "24   184      190         21         9        5         2      27      1.30   \n",
       "25   157      165         20         8        4         2       7      0.30   \n",
       "26   110      115         16         8        4         1      26      0.29   \n",
       "27   135      145         18         7        4         1      35      0.43   \n",
       "28   567      625         64        11        4         4       4      0.85   \n",
       "29   180      185         20         8        4         2      11      1.00   \n",
       "30   183      188         17         7        3         2      16      3.00   \n",
       "31   185      193         20         9        3         2      56      6.49   \n",
       "32   152      155         17         8        4         1      33      0.70   \n",
       "33   148      153         13         6        3         2      22      0.39   \n",
       "34   152      159         15         7        3         1      25      0.59   \n",
       "35   146      150         16         7        3         1      31      0.36   \n",
       "36   170      190         24        10        3         2      33      0.57   \n",
       "37   127      130         20         8        4         1      65      0.40   \n",
       "38   265      270         36        10        6         3      33      1.20   \n",
       "39   157      163         18         8        4         2      12      1.13   \n",
       "40   128      135         17         9        4         1      25      0.52   \n",
       "41   110      120         15         8        4         2      11      0.59   \n",
       "42   123      130         18         8        4         2      43      0.39   \n",
       "43   212      230         39        12        5         3     202      4.29   \n",
       "44   145      145         18         8        4         2      44      0.22   \n",
       "45   129      135         10         6        3         1      15      1.00   \n",
       "46   143      145         21         7        4         2      10      1.20   \n",
       "47   247      252         29         9        4         2       4      1.25   \n",
       "48   111      120         15         8        3         1      97      1.11   \n",
       "49   133      145         26         7        3         1      42      0.36   \n",
       "\n",
       "     \"Taxes\"  \n",
       "0       3167  \n",
       "1       4033  \n",
       "2       1471  \n",
       "3       3204  \n",
       "4       3613  \n",
       "5       3028  \n",
       "6       3131  \n",
       "7       5158  \n",
       "8       5702  \n",
       "9       2054  \n",
       "10      4127  \n",
       "11      1445  \n",
       "12      2087  \n",
       "13      2818  \n",
       "14      3917  \n",
       "15      2220  \n",
       "16      3498  \n",
       "17      3607  \n",
       "18      3648  \n",
       "19      3561  \n",
       "20      4681  \n",
       "21      7088  \n",
       "22      3482  \n",
       "23      3920  \n",
       "24      4162  \n",
       "25      3785  \n",
       "26      3103  \n",
       "27      3363  \n",
       "28     12192  \n",
       "29      3831  \n",
       "30      3564  \n",
       "31      3765  \n",
       "32      3361  \n",
       "33      3950  \n",
       "34      3055  \n",
       "35      2950  \n",
       "36      3346  \n",
       "37      3334  \n",
       "38      5853  \n",
       "39      3982  \n",
       "40      3374  \n",
       "41      3119  \n",
       "42      3268  \n",
       "43      3648  \n",
       "44      2783  \n",
       "45      2438  \n",
       "46      3529  \n",
       "47      4626  \n",
       "48      3205  \n",
       "49      3059  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sell</th>\n      <th>\"List\"</th>\n      <th>\"Living\"</th>\n      <th>\"Rooms\"</th>\n      <th>\"Beds\"</th>\n      <th>\"Baths\"</th>\n      <th>\"Age\"</th>\n      <th>\"Acres\"</th>\n      <th>\"Taxes\"</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>142</td>\n      <td>160</td>\n      <td>28</td>\n      <td>10</td>\n      <td>5</td>\n      <td>3</td>\n      <td>60</td>\n      <td>0.28</td>\n      <td>3167</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>175</td>\n      <td>180</td>\n      <td>18</td>\n      <td>8</td>\n      <td>4</td>\n      <td>1</td>\n      <td>12</td>\n      <td>0.43</td>\n      <td>4033</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>129</td>\n      <td>132</td>\n      <td>13</td>\n      <td>6</td>\n      <td>3</td>\n      <td>1</td>\n      <td>41</td>\n      <td>0.33</td>\n      <td>1471</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>138</td>\n      <td>140</td>\n      <td>17</td>\n      <td>7</td>\n      <td>3</td>\n      <td>1</td>\n      <td>22</td>\n      <td>0.46</td>\n      <td>3204</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>232</td>\n      <td>240</td>\n      <td>25</td>\n      <td>8</td>\n      <td>4</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2.05</td>\n      <td>3613</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>135</td>\n      <td>140</td>\n      <td>18</td>\n      <td>7</td>\n      <td>4</td>\n      <td>3</td>\n      <td>9</td>\n      <td>0.57</td>\n      <td>3028</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>150</td>\n      <td>160</td>\n      <td>20</td>\n      <td>8</td>\n      <td>4</td>\n      <td>3</td>\n      <td>18</td>\n      <td>4.00</td>\n      <td>3131</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>207</td>\n      <td>225</td>\n      <td>22</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>16</td>\n      <td>2.22</td>\n      <td>5158</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>271</td>\n      <td>285</td>\n      <td>30</td>\n      <td>10</td>\n      <td>5</td>\n      <td>2</td>\n      <td>30</td>\n      <td>0.53</td>\n      <td>5702</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>89</td>\n      <td>90</td>\n      <td>10</td>\n      <td>5</td>\n      <td>3</td>\n      <td>1</td>\n      <td>43</td>\n      <td>0.30</td>\n      <td>2054</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>153</td>\n      <td>157</td>\n      <td>22</td>\n      <td>8</td>\n      <td>3</td>\n      <td>3</td>\n      <td>18</td>\n      <td>0.38</td>\n      <td>4127</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>87</td>\n      <td>90</td>\n      <td>16</td>\n      <td>7</td>\n      <td>3</td>\n      <td>1</td>\n      <td>50</td>\n      <td>0.65</td>\n      <td>1445</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>234</td>\n      <td>238</td>\n      <td>25</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.61</td>\n      <td>2087</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>106</td>\n      <td>116</td>\n      <td>20</td>\n      <td>8</td>\n      <td>4</td>\n      <td>1</td>\n      <td>13</td>\n      <td>0.22</td>\n      <td>2818</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>175</td>\n      <td>180</td>\n      <td>22</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>15</td>\n      <td>2.06</td>\n      <td>3917</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>165</td>\n      <td>170</td>\n      <td>17</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>33</td>\n      <td>0.46</td>\n      <td>2220</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>166</td>\n      <td>170</td>\n      <td>23</td>\n      <td>9</td>\n      <td>4</td>\n      <td>2</td>\n      <td>37</td>\n      <td>0.27</td>\n      <td>3498</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>136</td>\n      <td>140</td>\n      <td>19</td>\n      <td>7</td>\n      <td>3</td>\n      <td>1</td>\n      <td>22</td>\n      <td>0.63</td>\n      <td>3607</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>148</td>\n      <td>160</td>\n      <td>17</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2</td>\n      <td>13</td>\n      <td>0.36</td>\n      <td>3648</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>151</td>\n      <td>153</td>\n      <td>19</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>24</td>\n      <td>0.34</td>\n      <td>3561</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>180</td>\n      <td>190</td>\n      <td>24</td>\n      <td>9</td>\n      <td>4</td>\n      <td>2</td>\n      <td>10</td>\n      <td>1.55</td>\n      <td>4681</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>293</td>\n      <td>305</td>\n      <td>26</td>\n      <td>8</td>\n      <td>4</td>\n      <td>3</td>\n      <td>6</td>\n      <td>0.46</td>\n      <td>7088</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>167</td>\n      <td>170</td>\n      <td>20</td>\n      <td>9</td>\n      <td>4</td>\n      <td>2</td>\n      <td>46</td>\n      <td>0.46</td>\n      <td>3482</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>190</td>\n      <td>193</td>\n      <td>22</td>\n      <td>9</td>\n      <td>5</td>\n      <td>2</td>\n      <td>37</td>\n      <td>0.48</td>\n      <td>3920</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>184</td>\n      <td>190</td>\n      <td>21</td>\n      <td>9</td>\n      <td>5</td>\n      <td>2</td>\n      <td>27</td>\n      <td>1.30</td>\n      <td>4162</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>157</td>\n      <td>165</td>\n      <td>20</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0.30</td>\n      <td>3785</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>110</td>\n      <td>115</td>\n      <td>16</td>\n      <td>8</td>\n      <td>4</td>\n      <td>1</td>\n      <td>26</td>\n      <td>0.29</td>\n      <td>3103</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>135</td>\n      <td>145</td>\n      <td>18</td>\n      <td>7</td>\n      <td>4</td>\n      <td>1</td>\n      <td>35</td>\n      <td>0.43</td>\n      <td>3363</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>567</td>\n      <td>625</td>\n      <td>64</td>\n      <td>11</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0.85</td>\n      <td>12192</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>180</td>\n      <td>185</td>\n      <td>20</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>11</td>\n      <td>1.00</td>\n      <td>3831</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>183</td>\n      <td>188</td>\n      <td>17</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2</td>\n      <td>16</td>\n      <td>3.00</td>\n      <td>3564</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>185</td>\n      <td>193</td>\n      <td>20</td>\n      <td>9</td>\n      <td>3</td>\n      <td>2</td>\n      <td>56</td>\n      <td>6.49</td>\n      <td>3765</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>152</td>\n      <td>155</td>\n      <td>17</td>\n      <td>8</td>\n      <td>4</td>\n      <td>1</td>\n      <td>33</td>\n      <td>0.70</td>\n      <td>3361</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>148</td>\n      <td>153</td>\n      <td>13</td>\n      <td>6</td>\n      <td>3</td>\n      <td>2</td>\n      <td>22</td>\n      <td>0.39</td>\n      <td>3950</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>152</td>\n      <td>159</td>\n      <td>15</td>\n      <td>7</td>\n      <td>3</td>\n      <td>1</td>\n      <td>25</td>\n      <td>0.59</td>\n      <td>3055</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>146</td>\n      <td>150</td>\n      <td>16</td>\n      <td>7</td>\n      <td>3</td>\n      <td>1</td>\n      <td>31</td>\n      <td>0.36</td>\n      <td>2950</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>170</td>\n      <td>190</td>\n      <td>24</td>\n      <td>10</td>\n      <td>3</td>\n      <td>2</td>\n      <td>33</td>\n      <td>0.57</td>\n      <td>3346</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>127</td>\n      <td>130</td>\n      <td>20</td>\n      <td>8</td>\n      <td>4</td>\n      <td>1</td>\n      <td>65</td>\n      <td>0.40</td>\n      <td>3334</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>265</td>\n      <td>270</td>\n      <td>36</td>\n      <td>10</td>\n      <td>6</td>\n      <td>3</td>\n      <td>33</td>\n      <td>1.20</td>\n      <td>5853</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>157</td>\n      <td>163</td>\n      <td>18</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>12</td>\n      <td>1.13</td>\n      <td>3982</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>128</td>\n      <td>135</td>\n      <td>17</td>\n      <td>9</td>\n      <td>4</td>\n      <td>1</td>\n      <td>25</td>\n      <td>0.52</td>\n      <td>3374</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>110</td>\n      <td>120</td>\n      <td>15</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>11</td>\n      <td>0.59</td>\n      <td>3119</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>123</td>\n      <td>130</td>\n      <td>18</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>43</td>\n      <td>0.39</td>\n      <td>3268</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>212</td>\n      <td>230</td>\n      <td>39</td>\n      <td>12</td>\n      <td>5</td>\n      <td>3</td>\n      <td>202</td>\n      <td>4.29</td>\n      <td>3648</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>145</td>\n      <td>145</td>\n      <td>18</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>44</td>\n      <td>0.22</td>\n      <td>2783</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>129</td>\n      <td>135</td>\n      <td>10</td>\n      <td>6</td>\n      <td>3</td>\n      <td>1</td>\n      <td>15</td>\n      <td>1.00</td>\n      <td>2438</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>143</td>\n      <td>145</td>\n      <td>21</td>\n      <td>7</td>\n      <td>4</td>\n      <td>2</td>\n      <td>10</td>\n      <td>1.20</td>\n      <td>3529</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>247</td>\n      <td>252</td>\n      <td>29</td>\n      <td>9</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1.25</td>\n      <td>4626</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>111</td>\n      <td>120</td>\n      <td>15</td>\n      <td>8</td>\n      <td>3</td>\n      <td>1</td>\n      <td>97</td>\n      <td>1.11</td>\n      <td>3205</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>133</td>\n      <td>145</td>\n      <td>26</td>\n      <td>7</td>\n      <td>3</td>\n      <td>1</td>\n      <td>42</td>\n      <td>0.36</td>\n      <td>3059</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-salmon",
   "metadata": {},
   "source": [
    "Let's say that our task is to use the  columns `\"Living\", \"Rooms\", \"Beds\", \"Baths\", \"Age\", \"Acres\",\"Taxes\"` to predict if the `Sell` price is over or under our budget that is, for this example, 152k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "norwegian-delhi",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:46:57.397089Z",
     "start_time": "2021-06-02T05:46:57.374577Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Houses that were sold for more than 152k: 24\nHouses that were sold for less than 152k: 26\n"
     ]
    }
   ],
   "source": [
    "print(\"Houses that were sold for more than 152k:\", (df.Sell > 152).sum())\n",
    "print(\"Houses that were sold for less than 152k:\", (df.Sell <= 152).sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-appearance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:40:36.989297Z",
     "start_time": "2021-06-02T05:40:36.981228Z"
    }
   },
   "source": [
    "So we have a balanced dataset for this example. Instead of preprocessing our dataset *before* feeding the dataloader, let's do it inside!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "challenging-emphasis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:52:36.675390Z",
     "start_time": "2021-06-02T05:52:36.667671Z"
    }
   },
   "outputs": [],
   "source": [
    "class HouseDataset(Dataset):\n",
    "    def __init__(self, csv_file, budget=152):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df.columns = [x.replace('\"', '').replace(' ', '') for x in df.columns]\n",
    "        columns = [\"Living\", \"Rooms\", \"Beds\", \"Baths\", \"Age\", \"Acres\",\"Taxes\"]\n",
    "        self.X = df[columns].values # the .values takes the numpy array\n",
    "        self.y = (df.Sell.values <= budget).astype(\"int\")\n",
    "        self.n_samples = len(self.X)\n",
    "    def __getitem__(self, index):\n",
    "        # we want to be index like dataset[index]\n",
    "        # to get the index-th batch\n",
    "        return self.X[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        # to retrieve the total samples by doing len(dataset)\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-jordan",
   "metadata": {},
   "source": [
    "Now we are ready to instantiate an object of the dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "worse-guyana",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:52:38.078094Z",
     "start_time": "2021-06-02T05:52:37.567704Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = HouseDataset(dataset_path, budget=152)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "raising-tunisia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:52:51.042524Z",
     "start_time": "2021-06-02T05:52:50.954338Z"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader)\n",
    "data = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "moderate-investment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T05:52:53.705994Z",
     "start_time": "2021-06-02T05:52:53.698666Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[tensor([[2.3000e+01, 9.0000e+00, 4.0000e+00, 2.0000e+00, 3.7000e+01, 2.7000e-01,\n",
       "          3.4980e+03],\n",
       "         [1.0000e+01, 5.0000e+00, 3.0000e+00, 1.0000e+00, 4.3000e+01, 3.0000e-01,\n",
       "          2.0540e+03],\n",
       "         [1.6000e+01, 7.0000e+00, 3.0000e+00, 1.0000e+00, 3.1000e+01, 3.6000e-01,\n",
       "          2.9500e+03],\n",
       "         [2.1000e+01, 7.0000e+00, 4.0000e+00, 2.0000e+00, 1.0000e+01, 1.2000e+00,\n",
       "          3.5290e+03]], dtype=torch.float64),\n",
       " tensor([0, 1, 1, 1])]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-focus",
   "metadata": {},
   "source": [
    "Here we go! We have the batches, the shuffles and all we want in a similar manner of before!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-sharp",
   "metadata": {},
   "source": [
    "### ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-switzerland",
   "metadata": {},
   "source": [
    "If you need to load an image dataset, it's more convenient to use the `ImageFolder` class from the `torchvision.datasets` module.\n",
    "\n",
    "To do so, you need to structure your data as follows:\n",
    "\n",
    "```\n",
    "root\n",
    "|_class1\n",
    "    |_xxx.png\n",
    "|_class2\n",
    "    |_xxx.png\n",
    "```\n",
    "\n",
    "that means that each class has its own directory.\n",
    "\n",
    "By giving this structure, the name of the class will be taken by the name of the folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cat_vs_dog  readme.md  Tabular\tzalando\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../../../Datasets/cat_vs_dog/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fixed-promotion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T06:18:18.117252Z",
     "start_time": "2021-06-02T06:18:18.087515Z"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-78ea1b1f653e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Pass transforms in here, then run the next cell to see how the transforms look\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "root_dir = '../../../../../Datasets/cat_vs_dog/'\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                       transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                                                            [0.5, 0.5, 0.5])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                                                           [0.5, 0.5, 0.5])])\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(root_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-complex",
   "metadata": {},
   "source": [
    "And then you just need to create the data loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-freeware",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T06:35:56.085748Z",
     "start_time": "2021-06-02T06:35:56.018127Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-ghost",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Create a dataset with three classes of images (choose the classes and download your own images. You don't need to train, so around 10 images per class will be enough).\n",
    "\n",
    "Then visualize the images with the help of the `imshow` helper function provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None, normalize=False):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "# Run this to test your data loaders\n",
    "images, labels = next(iter(trainloader))\n",
    "imshow(images[0], normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-metropolitan",
   "metadata": {},
   "source": [
    "### Image Dataset from paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-chester",
   "metadata": {},
   "source": [
    "Sometimes, you have given a bunch of paths and labels for your dataset, because it can be not convenient to move images around. \n",
    "\n",
    "For this reason, you can create something similar to what we have done at the beginning.\n",
    "\n",
    "Let's say we have a file called `train.csv` containing the columns `path` and `label`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "convertible-western",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T06:45:25.609577Z",
     "start_time": "2021-06-02T06:45:25.548882Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame({\"path\": [\"my_dataset/image1.png\", \"my_dataset/image2.png\"], \"label\": [0, 1] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "efficient-criminal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T06:45:29.569167Z",
     "start_time": "2021-06-02T06:45:29.550927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my_dataset/image1.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my_dataset/image2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    path  label\n",
       "0  my_dataset/image1.png      0\n",
       "1  my_dataset/image2.png      1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "joint-raleigh",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T06:46:11.305110Z",
     "start_time": "2021-06-02T06:46:11.217543Z"
    }
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-color",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T06:46:05.323220Z",
     "start_time": "2021-06-02T06:46:04.582143Z"
    }
   },
   "source": [
    "We can create a custom dataloader as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "velvet-shuttle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T06:51:27.202301Z",
     "start_time": "2021-06-02T06:51:27.195260Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        self.paths = df.path.values\n",
    "        self.labels = df.label.values\n",
    "    def __getitem__(self, index):\n",
    "        # we want to be index like dataset[index]\n",
    "        # to get the index-th batch\n",
    "        img = Image.open(self.paths[index]).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # to retrieve the total samples by doing len(dataset)\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-gibraltar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T06:53:50.432448Z",
     "start_time": "2021-06-02T06:53:50.415545Z"
    }
   },
   "source": [
    "### Optional/AdvancedÂ Exercise\n",
    "\n",
    "Create the csv file of the style defined above to load the dataset that you have created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-montgomery",
   "metadata": {},
   "source": [
    "You can customize even more! A nice article for it is:\n",
    "   https://www.scottcondron.com/jupyter/visualisation/audio/2020/12/02/dataloaders-samplers-collate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-burner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python395jvsc74a57bd05d8eb55396b26e444e25830983e23d02f9d742a022e83389ffb69c4e4a8d7f54",
   "display_name": "Python 3.9.5 64-bit ('deep_learning': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "metadata": {
   "interpreter": {
    "hash": "5d8eb55396b26e444e25830983e23d02f9d742a022e83389ffb69c4e4a8d7f54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}