{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Intro"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import spacy\n",
    "\n",
    "%load_ext nb_black\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"import spacy\\n\\n%load_ext nb_black\\n\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\";\n                var nbb_formatted_code = \"import spacy\\n\\n%load_ext nb_black\\n\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Process sentences 'Hello, world. Antonio is learning Python.' using spaCy\n",
    "doc = nlp(u\"Hello, world. Antonio is learning Python.\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"# Process sentences 'Hello, world. Antonio is learning Python.' using spaCy\\ndoc = nlp(u\\\"Hello, world. Antonio is learning Python.\\\")\";\n                var nbb_formatted_code = \"# Process sentences 'Hello, world. Antonio is learning Python.' using spaCy\\ndoc = nlp(u\\\"Hello, world. Antonio is learning Python.\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get tokens and sentences\n",
    "\n",
    "#### What is a Token?\n",
    "A token is a single chopped up element of the sentence, which could be a word or a group of words to analyse. The task of chopping the sentence up is called \"tokenisation\".\n",
    "\n",
    "Example: The following sentence can be tokenised by splitting up the sentence into individual words.\n",
    "\n",
    "\t\"Antonio is learning Python!\"\n",
    "\t[\"Antonio\",\"is\",\"learning\",\"Python!\"]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Get first token of the processed document\n",
    "token = doc[0]\n",
    "print(token)\n",
    "\n",
    "# Print sentences (one sentence per line)\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello\n",
      "Hello, world.\n",
      "Antonio is learning Python.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"# Get first token of the processed document\\ntoken = doc[0]\\nprint(token)\\n\\n# Print sentences (one sentence per line)\\nfor sent in doc.sents:\\n    print(sent)\";\n                var nbb_formatted_code = \"# Get first token of the processed document\\ntoken = doc[0]\\nprint(token)\\n\\n# Print sentences (one sentence per line)\\nfor sent in doc.sents:\\n    print(sent)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part of speech tags\n",
    "\n",
    "#### What is a Speech Tag?\n",
    "A speech tag is a context sensitive description of what a word means in the context of the whole sentence.\n",
    "More information about the kinds of speech tags which are used in NLP can be [found here](http://www.winwaed.com/blog/2011/11/08/part-of-speech-tags/).\n",
    "\n",
    "Examples:\n",
    "\n",
    "1. CARDINAL, Cardinal Number - 1,2,3\n",
    "2. PROPN, Proper Noun, Singular - \"Jan\", \"Javier\", \"Antonio\", \"Italy\"\n",
    "3. INTJ, Interjection - \"Ohhhhhhhhhhh\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# For each token, print corresponding part of speech tag\n",
    "\n",
    "for token in doc:\n",
    "    print(token, '\\t\\t', token.pos_)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello \t\t INTJ\n",
      ", \t\t PUNCT\n",
      "world \t\t NOUN\n",
      ". \t\t PUNCT\n",
      "Antonio \t\t PROPN\n",
      "is \t\t AUX\n",
      "learning \t\t VERB\n",
      "Python \t\t PROPN\n",
      ". \t\t PUNCT\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"# For each token, print corresponding part of speech tag\\n\\nfor token in doc:\\n    print(token, '\\\\t\\\\t', token.pos_)\";\n                var nbb_formatted_code = \"# For each token, print corresponding part of speech tag\\n\\nfor token in doc:\\n    print(token, \\\"\\\\t\\\\t\\\", token.pos_)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from spacy import displacy"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"from spacy import displacy\";\n                var nbb_formatted_code = \"from spacy import displacy\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "displacy.serve(doc, style='dep')\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/alessio/anaconda3/envs/deep_learning/lib/python3.9/site-packages/spacy/displacy/__init__.py:97: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a0cca352e77843ae88293ec42f2c0622-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Hello,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">INTJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">world.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Antonio</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">learning</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Python.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a0cca352e77843ae88293ec42f2c0622-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a0cca352e77843ae88293ec42f2c0622-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M220.0,179.0 L228.0,167.0 212.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a0cca352e77843ae88293ec42f2c0622-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a0cca352e77843ae88293ec42f2c0622-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a0cca352e77843ae88293ec42f2c0622-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a0cca352e77843ae88293ec42f2c0622-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a0cca352e77843ae88293ec42f2c0622-0-3\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a0cca352e77843ae88293ec42f2c0622-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"displacy.serve(doc, style='dep')\";\n                var nbb_formatted_code = \"displacy.serve(doc, style=\\\"dep\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "displacy.render(doc, style = \"ent\",jupyter = True)\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hello, world. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Antonio\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is learning Python.</div></span>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"displacy.render(doc, style = \\\"ent\\\",jupyter = True)\";\n                var nbb_formatted_code = \"displacy.render(doc, style=\\\"ent\\\", jupyter=True)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have said that dependency structures are represented by directed graphs that satisfy the following constraints:\n",
    "\n",
    "1. There is a single designated root node that has no incoming arcs.\n",
    "\n",
    "2. With the exception of the root node, each vertex has exactly one incoming arc.\n",
    "\n",
    "3. There is a unique path from the root node to each vertex in V.\n",
    "\n",
    "You can inspect the head of each token by invoking the `.head` attribute of a spaCy token:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "doc[2]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "world"
      ]
     },
     "metadata": {},
     "execution_count": 8
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"doc[2]\";\n                var nbb_formatted_code = \"doc[2]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "doc[2].head"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Hello"
      ]
     },
     "metadata": {},
     "execution_count": 9
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"doc[2].head\";\n                var nbb_formatted_code = \"doc[2].head\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So how would you search for the root?\n",
    "\n",
    "Since there is a unique path from the root node to each vertex in V, there's only one root node that has no incoming arcs, we can search for the token which have as head itself!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "for token in doc:\n",
    "    if token.head == token:\n",
    "        print(token)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello\n",
      "learning\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"for token in doc:\\n    if token.head == token:\\n        print(token)\";\n                var nbb_formatted_code = \"for token in doc:\\n    if token.head == token:\\n        print(token)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As expected, since there were two sentences in the doc, we got two roots.\n",
    "\n",
    "We can also build a function that, given a spaCy token, gives the path till the root:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Define a function to find the path to the root of each word in a sentence\n",
    "def path_to_the_root(token):\n",
    "    if token.head == token:\n",
    "        return token\n",
    "    else:\n",
    "        print(f'{token}->{token.head}')\n",
    "        path_to_the_root(token.head)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"# Define a function to find the path to the root of each word in a sentence\\ndef path_to_the_root(token):\\n    if token.head == token:\\n        return token\\n    else:\\n        print(f'{token}->{token.head}')\\n        path_to_the_root(token.head)\";\n                var nbb_formatted_code = \"# Define a function to find the path to the root of each word in a sentence\\ndef path_to_the_root(token):\\n    if token.head == token:\\n        return token\\n    else:\\n        print(f\\\"{token}->{token.head}\\\")\\n        path_to_the_root(token.head)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "head = path_to_the_root(doc[4])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Antonio->learning\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"head = path_to_the_root(doc[4])\";\n                var nbb_formatted_code = \"head = path_to_the_root(doc[4])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(head)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"print(head)\";\n                var nbb_formatted_code = \"print(head)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Embeddings \n",
    "\n",
    "An embedding is a fixed sizes numerical vector that attempts to encode some semantic meaning of the word or sentence it is encoding. The distributional hypothesis is usually the concept behind most embeddings. This hypothesis states that words which often have the same neighboring words tend to be semantically similar. For example if 'football' and 'basketball' usually appear close the word 'play' we assume that they will be semantically similar. An algorithm that is based on this concept is Word2Vec. A common way of obtaining sentence embeddings is to average the word embeddings inside the sentence and use that average as the representation of the whole sentence. \n",
    "\n",
    "- In spacy every token has its embedding.\n",
    "- It is under the attribute 'vector'.\n",
    "- In spacy embeddings are of size 96 or 128.\n",
    "\n",
    "\n",
    "Obtain the embeddings of all the tokens."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "for token in doc:\n",
    "    print(token.vector)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.44524243 -0.00310461  0.5343243  -0.17235672 -0.6761433  -0.38657025\n",
      " -0.3381957  -0.02988945 -0.00555246 -0.84159493  0.16327694 -0.57697415\n",
      " -0.68480617  0.00622424  0.07834896 -0.30333096  1.5165389  -0.59602\n",
      "  0.03028199 -0.43093356  0.03739309 -0.8697863  -0.8442886   0.0344111\n",
      "  0.25991035 -0.22334436  0.09180419 -0.40757135 -0.36183017 -0.38972035\n",
      "  0.46326637 -0.54095584  0.25360817 -0.6503706  -0.23880535  0.45702097\n",
      "  0.7022171   0.42939293  0.7362815   0.30060843 -0.6067468  -0.40308905\n",
      "  0.24224597  1.1391797  -0.31396425 -0.52889717  0.06228442  1.250154\n",
      " -0.5838891   0.99806213 -0.65224385 -0.04109746  0.94972086 -0.5786103\n",
      " -0.95549035 -0.96690434  0.44947106  0.59939575 -0.04105932 -0.14472458\n",
      "  0.146662   -0.524665    1.1935519   0.18990526  0.19144967 -0.3871125\n",
      " -0.6585389  -0.3067224   0.68035066 -0.5279468   1.1744324   0.18890297\n",
      " -0.17509712 -0.12649429  0.2876051   0.47623295 -0.9217448  -0.12227535\n",
      " -0.7543309  -0.08898088 -0.55470145 -0.36096507 -0.32111156  0.05345896\n",
      "  0.38026658 -0.59420073 -0.44060737  1.7940004   1.7069807  -0.3829298\n",
      "  0.35176247 -0.07131749  0.18959686 -0.0345682   0.348513    0.11872116]\n",
      "[-0.32204735  0.03663994  0.18097472 -1.1901772  -0.00226393  0.49048445\n",
      " -0.80663276 -0.01517391 -0.4642836   0.6381493  -1.1013291   0.6910715\n",
      " -0.7109645   1.2356547  -0.7022837  -1.1748002  -0.2919885  -0.4422551\n",
      " -0.3191613  -0.23612101 -0.08072302  0.44913334 -0.45818076  0.49690196\n",
      " -0.6441289   0.14809316 -0.7548033   0.5271868  -0.3413394   0.04523216\n",
      "  0.03355569 -0.14403784 -1.0574659   0.45357925  1.2294765   0.6850211\n",
      " -0.3797481  -0.55575365  0.3396731   1.164652   -0.6485292  -0.8135272\n",
      "  1.2966031   0.87939805 -0.2660023  -0.06440268  0.63454676  1.0548234\n",
      " -0.7081971  -0.4179017  -0.3286246   0.82533216 -1.2605715  -0.3964756\n",
      " -0.2992939  -0.21678233 -0.14554007  1.4417236  -0.6621266  -0.0957793\n",
      "  0.47021344 -0.04204563  0.0704391  -0.7243011  -0.7541456  -0.06740114\n",
      " -0.2995544   0.19806008 -0.17865473  0.3702188  -0.25564528  0.70679355\n",
      "  0.08201796 -0.10583138  0.6048512   0.00902063  0.41945684  0.16461413\n",
      " -0.03603783  0.00396159  0.12779379  0.20001245  0.00816697 -0.8489127\n",
      " -0.30882195  0.8915397   1.1930835   0.4772539   0.21229783 -0.33342928\n",
      "  0.3937195   0.28106052  0.3270102   0.01530986  0.4538088   0.04788824]\n",
      "[ 0.06320907 -0.5009434   0.86384654  0.10108373 -0.06021598  0.47098747\n",
      " -0.46805865 -0.09299639 -0.4383958  -0.69945276  0.22281924 -0.93805456\n",
      " -0.3054635   0.46136677 -0.43903488  0.5956425  -0.02855387 -0.5031806\n",
      " -1.2466627  -0.45793614  0.72314084 -0.5899781  -0.6805903   0.42095622\n",
      " -0.7466032   0.0371931   0.7218974  -0.05155295  0.5582514   0.18432853\n",
      "  0.22397496 -0.31886664  0.16095704 -0.23519711  0.28828022 -0.65099335\n",
      " -0.46452338  0.6657122   0.3907298   0.45908147  0.10716589  0.33936688\n",
      " -0.6315656   0.6070595  -0.05351951 -1.0381616  -0.1728094   0.6235651\n",
      " -0.61602813 -0.36253354  0.11410612  0.7843306   0.42521673 -1.2657908\n",
      "  0.2654117  -0.13313079  0.04513031  0.10365227  0.44497156 -0.22857243\n",
      "  0.16105436 -0.40375242 -0.08225073 -0.39306122 -0.6709495  -0.87536997\n",
      "  0.41666815 -0.08336677  0.09285473  0.30933386  0.6323401  -0.37775934\n",
      " -0.09722337 -0.29724342 -0.05252057  0.22228429  0.08438161 -0.20059851\n",
      " -0.38750666  0.61701155  1.0640423  -0.10950336 -0.87727225  1.205445\n",
      " -0.63986695 -0.35104138 -0.35305107 -0.5888745   0.27181283 -0.4520226\n",
      "  0.6830285   0.34170228  0.74705946  0.09091692  0.5486316  -0.3055024 ]\n",
      "[-1.77840665e-01  1.09162077e-01  2.78199971e-01  1.31071210e+00\n",
      " -7.43639529e-01 -5.10973573e-01 -3.52138996e-01 -6.21238589e-01\n",
      " -7.77072668e-01  1.46237254e-01  2.01043308e-01  1.05467856e-01\n",
      " -5.67220926e-01 -8.78118515e-01 -2.04027876e-01 -5.04861057e-01\n",
      " -7.81300068e-01 -1.27795374e+00 -5.15869260e-01  1.74798071e-03\n",
      "  7.95131207e-01  2.87669897e-01 -3.94226611e-02 -7.91583538e-01\n",
      " -3.70800555e-01  1.57561052e+00 -2.38581911e-01  7.31593609e-01\n",
      " -2.70266354e-01 -4.01748180e-01 -3.21774960e-01 -3.66726398e-01\n",
      " -6.32144570e-01 -8.41045380e-02 -3.63639981e-01  1.58041549e+00\n",
      " -2.54706621e-01  1.87366158e-02 -3.74841779e-01 -1.91044092e-01\n",
      " -6.00473166e-01 -7.79879451e-01 -4.12861168e-01  2.18135023e+00\n",
      " -4.93127942e-01  1.06456086e-01  2.13782668e-01 -8.35812926e-01\n",
      " -7.90369093e-01 -3.43703210e-01  1.34199113e-01  3.50110352e-01\n",
      "  2.47936994e-02  3.11360568e-01 -8.30468386e-02  1.11565399e+00\n",
      " -2.81579524e-01  1.03939509e+00 -5.26451886e-01  5.95015168e-01\n",
      "  1.22815144e+00  1.49147058e+00  3.67031932e-01 -2.47585893e-01\n",
      " -4.56922293e-01  2.88151574e+00 -5.50072134e-01 -6.25027567e-02\n",
      "  1.57607067e+00 -4.42162156e-02 -8.10343564e-01 -1.39788970e-01\n",
      "  2.46576995e-01 -7.38895059e-01 -2.23600373e-01 -8.77300262e-01\n",
      "  2.32856727e+00 -8.84448886e-01 -4.21840787e-01  2.11732328e-01\n",
      "  2.20732927e+00  5.77551901e-01 -3.06891888e-01 -5.88901281e-01\n",
      " -7.21895635e-01 -2.35240534e-01 -4.01304901e-01  6.60482764e-01\n",
      " -6.15533233e-01 -2.61346459e-01 -4.87690389e-01  1.04513025e+00\n",
      " -5.92110038e-01  6.76717043e-01 -3.33274066e-01 -4.09137070e-01]\n",
      "[-0.20376076 -0.42983872  0.40873387  0.56626046  1.2091668   1.0163388\n",
      " -0.59769535 -0.38143146 -0.55030996 -0.8260666   0.07059689  0.08846276\n",
      " -0.97877127  0.18266468 -0.35365343  0.3607986   1.5435582  -0.18464278\n",
      "  0.11480963  0.4044978  -0.7749927  -0.69505215 -0.7008359  -0.85458565\n",
      "  1.3017144   0.7879386   0.74405026 -0.02128324  0.4671727  -0.0343692\n",
      " -0.37903154 -0.6587335  -0.3246674  -0.37788087 -0.49731952  1.1950597\n",
      " -0.88102984  0.70607626  0.50026554  0.1527083   0.17975082  0.295151\n",
      " -0.6043421  -0.536279   -0.2966615  -0.61461246  0.54431766  0.68037635\n",
      " -0.21235576  1.2436391   0.00536904 -0.03184021 -0.19333081 -0.67160356\n",
      " -0.30273992 -0.5337873  -0.3144433   0.80551666  0.38812685 -0.40014333\n",
      "  0.04600576 -0.3825953   1.0103257  -0.40432072 -0.5122776  -0.8507765\n",
      " -1.2457893  -0.18267922  1.1921753  -0.35031462 -0.2808469  -0.05602881\n",
      " -0.6059692  -1.1447207  -0.24422173  1.2505902   0.41417152 -0.30875397\n",
      " -0.6476067  -0.59559906  0.00161457 -0.60551476  0.26884472  0.21764298\n",
      " -0.09702884 -0.30570322  0.4189191  -0.5358885   0.26160315  0.3541317\n",
      " -0.12196639 -0.5922862  -1.0702152   0.90602934  0.51740503  0.20244057]\n",
      "[-0.6037847   0.06373208 -0.18066418  0.5672739  -0.497268   -0.06382122\n",
      "  0.5886206   0.06462477  0.28575706 -0.27961522 -0.10444458 -0.28911334\n",
      "  2.0222673  -1.40048    -0.57651556 -0.8543886  -0.37617108  0.37148362\n",
      "  0.51932615 -0.8990616  -0.9845594   0.4784702  -0.36981282  0.62931806\n",
      "  0.3699538  -0.8750952   0.79041016 -0.9184152   0.09924194 -0.09600623\n",
      " -0.937899   -0.2490315   0.03302726  0.08641036  0.04922277  1.3302209\n",
      "  0.13913825 -0.6605381  -0.23692605  0.9347159  -0.3197      0.65074277\n",
      "  0.7566767   0.26207516 -0.134725   -0.23180738  0.22304444  0.12824145\n",
      " -0.76458484 -0.5725802  -0.22037931  0.40380198 -0.22991312  1.0835195\n",
      " -0.45038703  1.7753186   0.56878746 -1.0424192   1.7832736   0.31018603\n",
      "  0.44270048  0.2357749   0.945374    0.1687673  -0.94660944  0.8272689\n",
      " -0.53348684 -0.03033757 -0.6133828  -0.2546643   0.7783972   2.5457969\n",
      " -0.67241454  0.25322527 -1.2209773  -0.17440715 -0.45347264 -0.2988694\n",
      "  0.10963535 -0.29336363 -0.7365368  -0.28387725 -0.12846482  0.89175504\n",
      "  0.8104731  -1.0748651  -0.41011584  0.41881266  0.46967226 -0.02826391\n",
      " -0.36020598  0.41616833 -0.9383143  -0.8583299   1.1350003  -0.15894839]\n",
      "[ 0.8212875  -0.69699234 -0.46039075  1.1225996  -0.03244513  1.3819139\n",
      "  0.639964   -0.6251255  -0.23833281  0.44634116 -0.77610517  0.26869768\n",
      "  0.47901693  0.26430914 -0.79035795  0.03892782 -0.1661766  -0.39829972\n",
      " -1.2033311  -0.51193607 -0.2893587   1.5779464  -0.32499728  0.10597746\n",
      " -0.04135105 -0.6478571  -0.51640606 -0.77092695 -0.5654391  -0.12466709\n",
      " -0.72540784  0.89157283  1.3001677   0.19135553 -0.95809186 -0.46567395\n",
      "  1.1560979  -0.34568462 -1.1519672  -1.4183264  -0.90516746  0.16495717\n",
      " -0.5407548   1.0434948  -0.45691013  1.4174117   0.33535922  0.80860126\n",
      "  0.19728628  0.07804866 -0.10254569 -0.44708824  1.2995222   0.89012057\n",
      "  0.77081513 -0.09925419 -0.09902808  0.29131866 -0.03636584  0.5076143\n",
      "  0.75808847  0.93800455 -0.31762668 -0.20969714  0.11496724 -1.2265419\n",
      "  0.18646333  0.43583956 -0.4529585   0.00939101 -0.13112281  0.13707267\n",
      "  0.20791599 -1.4019482  -0.41096205  0.77296835 -1.0033873  -0.572447\n",
      "  0.2636075   1.5710418  -0.59470344 -0.03214283  0.96139956  1.2894773\n",
      "  0.17555055 -0.60163796 -0.861341    0.6567781  -0.4169795   0.4544\n",
      " -0.2993067   0.5368557  -0.19625431  0.72946465 -1.195924   -0.8954758 ]\n",
      "[ 0.42751005 -0.09090367 -0.31401244 -0.22992787  0.55514127  0.08970934\n",
      " -0.43069446 -0.7428979  -0.58972126  0.22873053  1.7982652  -0.31355226\n",
      " -0.4263302   1.258636    0.57117355 -0.5375973   1.0485418  -0.22758707\n",
      " -0.42937666 -0.33781952  0.37922233 -1.3377713  -0.49850726  1.7693201\n",
      "  0.61943984  0.51844776  0.06328502 -0.96103454  0.15132183  0.33229083\n",
      "  0.24138355  1.3706825   0.39201236 -0.29883868  0.02338687 -0.37199205\n",
      " -0.8896278   0.1069351   1.1019316  -0.8026301  -0.68776834  0.66562045\n",
      " -0.2395963  -0.00900343  0.07398666  0.46315375 -0.07391278 -0.49918258\n",
      " -0.6972741  -0.84011126  0.45217866 -0.23813078  1.1564921   0.45005384\n",
      " -0.57017845 -0.69700766 -0.36616892  0.66754687 -0.16879055 -0.10274175\n",
      "  0.939834   -0.06896077 -0.5583156   0.30445504 -0.46514434 -0.7694664\n",
      " -0.488914   -0.9104614   0.78272986 -0.35563242 -0.42818815 -0.06318784\n",
      " -1.0641304  -2.310371   -0.6646585  -0.80116946  0.7234086   1.0501022\n",
      " -0.32046103 -0.12989897 -0.11088237  0.06970665  1.0849186   0.59517455\n",
      " -0.36260778  0.17318854  1.6423578  -0.37601656  1.058382   -0.40570825\n",
      " -0.8073583  -0.01465864  0.66981244  0.33225897  0.39345944 -0.13243526]\n",
      "[-0.08329424 -0.10957453 -0.36388937  1.499863   -1.1708754  -1.0331739\n",
      " -0.42601007 -0.27624446 -0.8615279   0.44288835  0.48469967  0.4390149\n",
      " -0.6065781  -0.9688202   0.1279425  -0.08086982 -0.6086686  -1.1223334\n",
      " -0.16825113 -0.39816263  0.27962324  0.11024284 -0.3086336  -0.40363282\n",
      " -0.36326224  0.59032565 -0.60933936  0.45695716 -0.33305898 -0.20294355\n",
      " -0.47247562 -0.361113    0.10677208 -0.06952664  0.02186635  2.1560638\n",
      "  0.10122487 -0.3062065  -0.19022408 -0.2695951  -0.52086127 -0.5355679\n",
      " -0.12930578  2.9256666  -0.33172607 -0.04153463  0.31934634 -1.7059472\n",
      " -0.6498908  -0.23707436 -0.07985459  0.19411065 -0.38430035  0.32206434\n",
      " -0.52770364  0.95956564 -0.71143     2.4266276  -0.4524954   0.28633675\n",
      "  0.9541229   1.6827183   0.2866657  -0.34054294 -0.31250307  3.0420876\n",
      " -0.55007124 -0.15962985  1.2558463   0.17514639 -0.44722104 -0.5642736\n",
      "  0.18657717 -0.5580041   0.18181922 -0.6962546   1.531491   -0.37454617\n",
      " -0.1429446  -0.21747993  2.5594876   0.25173602 -0.5586404  -0.49390784\n",
      " -0.90452474 -0.38011992  0.5016295   1.2186399   0.4195039  -0.5412754\n",
      " -0.40306696  0.98058707 -0.49836916  0.27614895 -0.90403116 -0.25493824]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"for token in doc:\\n    print(token.vector)\";\n                var nbb_formatted_code = \"for token in doc:\\n    print(token.vector)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Semantic similarity \n",
    "\n",
    "To compute the semantic similarity between two sentences, $u$ and $v$, we measure the cossine similarity between the two sentence embeddings. The formula is as follows:\n",
    "\n",
    "$sim(u, v) = \\frac{u \\cdot v}{||u|| ||v||} $\n",
    "\n",
    "\n",
    "Use the following formula to get the semantic similarity betwen the words in doc.\n",
    "Feel free to test it between differente words too"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import numpy as np"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 15;\n                var nbb_unformatted_code = \"import numpy as np\";\n                var nbb_formatted_code = \"import numpy as np\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def semantic_sim(u,v):\n",
    "    return (u @ v) / (np.sqrt(sum(u**2)) * np.sqrt(sum(v**2)))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 16;\n                var nbb_unformatted_code = \"def semantic_sim(u,v):\\n    return (u @ v) / (np.sqrt(sum(u**2)) * np.sqrt(sum(v**2)))\";\n                var nbb_formatted_code = \"def semantic_sim(u, v):\\n    return (u @ v) / (np.sqrt(sum(u ** 2)) * np.sqrt(sum(v ** 2)))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print(semantic_sim(doc[1].vector, doc[3].vector))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.17669735320098082\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 17;\n                var nbb_unformatted_code = \"print(semantic_sim(doc[1].vector, doc[3].vector))\";\n                var nbb_formatted_code = \"print(semantic_sim(doc[1].vector, doc[3].vector))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pride and Prejudice analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We would like to:\n",
    "\n",
    "- Extract the names of all the characters from the book (e.g. Elizabeth, Darcy, Bingley)\n",
    "- Visualize characters' occurences with regards to relative position in the book\n",
    "- Authomatically describe any character from the book\n",
    "- Find out which characters have been mentioned in a context of marriage\n",
    "- Build keywords extraction that could be used to display a word cloud (example)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To load the text file, it is convinient to decode using the utf-8 standard:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def read_file(file_name):\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        return file.read()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 18;\n                var nbb_unformatted_code = \"def read_file(file_name):\\n    with open(file_name, \\\"r\\\", encoding=\\\"utf-8\\\") as file:\\n        return file.read()\";\n                var nbb_formatted_code = \"def read_file(file_name):\\n    with open(file_name, \\\"r\\\", encoding=\\\"utf-8\\\") as file:\\n        return file.read()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process full text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "text = read_file(\"data/pride_and_prejudice.txt\")\n",
    "# Process the text\n",
    "\n",
    "doc = nlp(text)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 32;\n                var nbb_unformatted_code = \"text = read_file(\\\"data/pride_and_prejudice.txt\\\")\\n# Process the text\\n\\ndoc = nlp(text)\";\n                var nbb_formatted_code = \"text = read_file(\\\"data/pride_and_prejudice.txt\\\")\\n# Process the text\\n\\ndoc = nlp(text)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "dir(doc.sents)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__next__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'close',\n",
       " 'gi_code',\n",
       " 'gi_running',\n",
       " 'gi_yieldfrom',\n",
       " 'send',\n",
       " 'throw']"
      ]
     },
     "metadata": {},
     "execution_count": 34
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 34;\n                var nbb_unformatted_code = \"dir(doc.sents)\";\n                var nbb_formatted_code = \"dir(doc.sents)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "print(doc.sents)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<built-in method __sizeof__ of generator object at 0x7f8fadcf8ca0>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 35;\n                var nbb_unformatted_code = \"print(doc.sents.__sizeof__)\";\n                var nbb_formatted_code = \"print(doc.sents.__sizeof__)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# How many sentences are in the book (Pride & Prejudice)?\n",
    "\n",
    "count = 0\n",
    "for sent in sents:\n",
    "    count +=1\n",
    "\n",
    "print(count)\n",
    "\n",
    "# Print sentences from index 10 to index 15, to make sure that we have parsed the correct book\n",
    "\n",
    "sents\n",
    "    \n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<generator at 0x7f8fb07fa700>"
      ]
     },
     "metadata": {},
     "execution_count": 31
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 31;\n                var nbb_unformatted_code = \"# How many sentences are in the book (Pride & Prejudice)?\\n\\ncount = 0\\nfor sent in sents:\\n    count +=1\\n\\nprint(count)\\n\\n# Print sentences from index 10 to index 15, to make sure that we have parsed the correct book\\n\\nsents\\n    \";\n                var nbb_formatted_code = \"# How many sentences are in the book (Pride & Prejudice)?\\n\\ncount = 0\\nfor sent in sents:\\n    count += 1\\n\\nprint(count)\\n\\n# Print sentences from index 10 to index 15, to make sure that we have parsed the correct book\\n\\nsents\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find all the personal names\n",
    "\n",
    "[Hint](# \"List doc.ents and check ent.label_\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Extract all the personal names from Pride & Prejudice and count their occurrences.\n",
    "# Expected output is a list in the following form: [('elizabeth', 622), ('darcy', 312), ('jane', 286), ('bennet', 266) ...].\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "def find_character_occurences(doc):\n",
    "    \"\"\"\n",
    "    Return a list of actors from `doc` with corresponding occurences.\n",
    "\n",
    "    :param doc: Spacy NLP parsed document\n",
    "    :return: list of tuples in form\n",
    "        [('elizabeth', 622), ('darcy', 312), ('jane', 286), ('bennet', 266)]\n",
    "    \"\"\"\n",
    "\n",
    "    characters = Counter()\n",
    "    # your code here\n",
    "\n",
    "\n",
    "print(find_character_occurences(processed_text)[:20])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot characters personal names as a time series "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Matplotlib Jupyter HACK\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can investigate where a particular entity occurs in the text. We can do it just accessing the `.start` attribute of an entity:\n",
    "\n",
    "[Hint](# \"ent.start\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# List all the start positions of person entities"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So we can create a function that stores all the offsets of every character:\n",
    "   \n",
    "   \n",
    "[Hint](# \"Create a dictionary with the lowered lemmas [ent.lemma_.lower()] and associate a list of all the ent.starts\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot characters' mentions as a time series relative to the position of the actor's occurrence in a book.\n",
    "\n",
    "def get_character_offsets(doc):\n",
    "    \"\"\"\n",
    "    For every character in a `doc` collect all the occurences offsets and store them into a list. \n",
    "    The function returns a dictionary that has actor lemma as a key and list of occurences as a value for every character.\n",
    "    \n",
    "    :param doc: Spacy NLP parsed document\n",
    "    :return: dict object in form\n",
    "        {'elizabeth': [123, 543, 4534], 'darcy': [205, 2111]}\n",
    "    \"\"\"\n",
    "            \n",
    "    return dict(character_offsets)\n",
    "\n",
    "character_occurences = get_character_offsets(processed_text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "character_occurences"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Hint](# \"Use the character offsets for each character as x\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T17:01:35.087781Z",
     "start_time": "2021-03-28T17:01:35.071546Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the histogram of the character occurrences in the whole text\n",
    "NUM_BINS = 20\n",
    "\n",
    "def plot_character_hist(character_offsets, character_label, cumulative=False):\n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_character_hist(character_occurences, \"elizabeth\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_character_hist(character_occurences, \"darcy\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cumulative occurrences"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_character_hist(character_occurences, \"elizabeth\", cumulative=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_character_hist(character_occurences, \"darcy\", cumulative=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Spacy parse tree in action\n",
    "\n",
    "[Hint](# \"ent.subtree, token.pos_ == 'ADJ'\") "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Find words (adjectives) that describe Mr. Darcy.\n",
    "\n",
    "def get_character_adjectives(doc, character_lemma):\n",
    "    \"\"\"\n",
    "    Find all the adjectives related to `character_lemma` in `doc`\n",
    "    \n",
    "    :param doc: Spacy NLP parsed document\n",
    "    :param character_lemma: string object\n",
    "    :return: list of adjectives related to `character_lemma`\n",
    "    \"\"\"\n",
    "    \n",
    "    adjectives = []\n",
    "    for ent in processed_text.ents:\n",
    "        # your code here\n",
    "        pass\n",
    "    \n",
    "     for ent in processed_text.ents:\n",
    "        if ent.lemma_.lower() == character_lemma:\n",
    "            if ent.root.dep_ == 'nsubj':\n",
    "                for child in ent.root.head.children:\n",
    "                    if child.dep_ == 'acomp':\n",
    "                        adjectives.append(child.lemma_)\n",
    "                        \n",
    "    return adjectives\n",
    "\n",
    "print(get_character_adjectives(processed_text, 'darcy'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Find words (adjectives) that describe Elizabeth.\n",
    "\n",
    "\n",
    "print(get_character_adjectives(processed_text, 'elizabeth'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For all the dependencies manual: https://nlp.stanford.edu/software/dependencies_manual.pdf\n",
    "\n",
    "`acomp`: adjectival complement\n",
    "*i.e.* an adjectival phrase which functions as the complement (like an object of the verb) e.g. \"She looks very beautiful\": *beautiful* is an adjectival complement of *looks*\n",
    "\n",
    "`nsubj`: nominal subject\n",
    "*i.e.* a noun phrase which is the syntactic subject of a clause. The head of this relation\n",
    "might not always be a verb: when the verb is a copular verb, the root of the clause is the complement of\n",
    "the copular verb, which can be an adjective or noun.\n",
    "*e.g.* \"Clinton defeated Dole\". The relationship is *nsubj(defeated, Clinton)*\n",
    "\n",
    "\"The baby is cute\". The relationship is *nsubj(cute, baby)*.\n",
    "\n",
    "In the code, `.dep_`stands for syntactic dependency, *i.e.* the relation between tokens."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "processed_text.ents[30].root.dep_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Hint](# \"ent.label_, ent.root.head.lemma_\") "
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T17:09:34.144121Z",
     "start_time": "2021-03-28T17:09:34.132840Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Find characters that are 'talking', 'saying', 'doing' the most. Find the relationship between \n",
    "# entities and corresponding root verbs.\n",
    "\n",
    "character_verb_counter = Counter()\n",
    "\n",
    "\n",
    "for ent in processed_text.ents:\n",
    "    if # your code here:\n",
    "        character_verb_counter[ent.text] += 1\n",
    "\n",
    "print(character_verb_counter.most_common(10)) \n",
    "\n",
    "# do the same for talking and doing\n",
    "\n",
    "print(character_verb_counter.most_common(10)) \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Hint](# \"ent.label_, ent.root.head.pos_\") "
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T17:10:42.811139Z",
     "start_time": "2021-03-28T17:10:42.804815Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Find 20 most used verbs\n",
    "verb_counter = Counter()\n",
    "\n",
    "# your code here\n",
    "\n",
    "print(verb_counter.most_common(20))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a dataframe with the most used verb and how many time a character used the verb\n",
    "\n",
    "import pandas as pd\n",
    "verb_characters = {}\n",
    "verb_list = [verb[0] for verb in verb_counter.most_common(20)]\n",
    "for ent in processed_text.ents:\n",
    "    if ent.label_ == 'PERSON' and ent.root.head.lemma_ in verb_list:\n",
    "        # complete the code\n",
    "        pass\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.DataFrame(verb_characters).transpose().fillna(0)\n",
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# drop the less meaningful columns\n",
    "df = df[df.columns[df.sum()>=10]].sort_index()\n",
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.heatmap(df, annot=True, cmap='Blues')\n",
    "df.style.background_gradient(cmap='Blues')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}