{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# NLP Lecture @ Strive School - 21st July 2021\n",
    "# NER update\n",
    "\n",
    "'''\n",
    "Since today we are exploring the world of natural language processing, weâ€™ll deepen in the Named Entity Recognition technique:\n",
    "this is just one of the mechanisms that NLP embodies. The recognition of named entities as the process of automatic\n",
    "identification of the entities present in a text and consequent classification into predefined categories such as \"person\",\n",
    "\"organization\", \"position\" is a quite common activity and expect for English, trained models with spaCy offer few labels that\n",
    "could be improved through training.\n",
    "\n",
    "Following the case study of this morning, try to emulate it in order to label all the brands present in the provided datasets,\n",
    "choosing the one you prefer OR trying to label all them and to train the model to recognize new different entities.\n",
    "The result should be twofold: the final model should be able to recognize brands that it has already seen, but already new ones.\n",
    "The brands proposed in the dataset concern fashion, cars and food.\n",
    "In order to test the accuracy of the model, test it with sentences and brands the model has never seen.\n",
    "\n",
    "Sample of the dataset\n",
    "---------------------\n",
    "- Cate Blanchett in Armani PrivÃ©. Rating: 8. Concludes as a rare butterfly, or from Rorschach's Test, or from computerized\n",
    "axial tomography.\n",
    "- I liked everything, recommend it! Another quality Xiaomi product...\n",
    "- What is the price of that Fiat 500XL?\n",
    "\n",
    "Info:\n",
    "- Feel free to change or arrange a new dataset\n",
    "- Try experimenting and tuning with the hyperparameters\n",
    "- Feel free to use or change the code you've seen during the morning session\n",
    "- TBD = To be done (from you!) :)\n",
    "\n",
    "'''"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nSince today we are exploring the world of natural language processing, weâ€™ll deepen in the Named Entity Recognition technique:\\nthis is just one of the mechanisms that NLP embodies. The recognition of named entities as the process of automatic\\nidentification of the entities present in a text and consequent classification into predefined categories such as \"person\",\\n\"organization\", \"position\" is a quite common activity and expect for English, trained models with spaCy offer few labels that\\ncould be improved through training.\\n\\nFollowing the case study of this morning, try to emulate it in order to label all the brands present in the provided datasets,\\nchoosing the one you prefer OR trying to label all them and to train the model to recognize new different entities.\\nThe result should be twofold: the final model should be able to recognize brands that it has already seen, but already new ones.\\nThe brands proposed in the dataset concern fashion, cars and food.\\nIn order to test the accuracy of the model, test it with sentences and brands the model has never seen.\\n\\nSample of the dataset\\n---------------------\\n- Cate Blanchett in Armani PrivÃ©. Rating: 8. Concludes as a rare butterfly, or from Rorschach\\'s Test, or from computerized\\naxial tomography.\\n- I liked everything, recommend it! Another quality Xiaomi product...\\n- What is the price of that Fiat 500XL?\\n\\nInfo:\\n- Feel free to change or arrange a new dataset\\n- Try experimenting and tuning with the hyperparameters\\n- Feel free to use or change the code you\\'ve seen during the morning session\\n- TBD = To be done (from you!) :)\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# STEP 0 - PRE REQUISITES\n",
    "\n",
    "# python -m spacy download en_core_web_lg\n",
    "\n",
    "# TBD: Import libraries\n",
    "import spacy\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "from spacy.training import Example\n",
    "\n",
    "# TBD: Load preferred model\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# TBD: Load the dataset and test it as-is\n",
    "\n",
    "with open(\"electronics.txt\") as file:\n",
    "    dataset = file.read()\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "doc = nlp(dataset)\n",
    "print(\"Entities:\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I am being forced to purchase a new device as all US networks are apparently no longer supporting Huawei devices in the very near future.\n",
      "Samsung S20 is The best Phone that money can buy\n",
      "I'm a Samsung fan, design and productivity is amazing and perfect, BUT it have a no-go for me: it poses a risk for phone owners.\n",
      "The hardware is absolutetly stellar, which is no surprise for Samsung in the past years.\n",
      "Unfortunately, same goes for app bloatware, which is also no surprise for Samsung.\n",
      " The phone feels amazing to the touch. Haven't messed with the camera much but from what I have I can say it's not half bad. I bought a micro sdxc card from Samsung to put all my movies and music on and use VLC to watch/listen and it's great.\n",
      "Last time I checked samsung had there high end devices free to unlock there bootloader. At least from the s7 days .\n",
      "Techniques used in Huawei is great, and even awesome.\n",
      "huawei really did an amazing job.\n",
      "Huawei phones are excellent. I have used them for ever, unfortunately they are ban by USA. This is the last phone I am purchasing because the next generations will not work in the ðŸ‡ºðŸ‡¸.\n",
      "I ordered a new huawei p30 pro for $ 614 and what I received was crazy, the volume buttons werenâ€™t working and the power button hardly works, the battery drains fast and it was a used phone.\n",
      "I bought the Huawei P30 Pro in July, which to replace my Iphone. I have been using it every day since then. It works great for both AT&T and Tmobile network in the USA. It is a shame to see the political battle and people can not easily buy a great phone, which has nothing to do with national security. Otherwise, the US should ban Samsung, then all other countries should ban Apple etc. So stupid.\n",
      "For the money, this phone represents a real bargain. I have been an iphone user for the last ten years, have shown loyalty to the brand and have bought three sim free units during this time. Without question, the Huawei wipes the floor with what I am used to - easily navigated set up and subsequent user menus in real English, superbly constructed, lightening fast loading of websites/data, no irratating and obtrusive update and running out of icloud data prompts ever 5 minutes and an amazing camera.\n",
      "Incredible phone. My second from Huawei and hoping they stop this nonsense to block apps in their phones as they are perfect. Good value, beautiful device, fast, easy to use, outstanding camera, etc.\n",
      "Everything is fine with huawei phones I think I've been wasting my time and money with iPhone. Huawei gives you more options and more services with less money so my recommendation is don't buy iPhone. I phone is finished long time ago.\n",
      "For me Huawei are delivering great products at proper prices and are really getting it right. Anybody like me who is worried to leave apple jail, break out it's really good outside!!\n",
      "Thank you for huawei !\n",
      "I really love Xiaomi and Redmi phones. This is my third one and I've usually had a good experience with them.\n",
      "I've been contemplating on buying a Xiaomi smartphone for quite some time and had tried the Redmi Go on an impulse purchase, saw the Redmi 8 and decided to sit it out, then came the Redmi 9 and so did reviews. I watched a few video reviews and tutorials on how to maximize your experience before purchasing. Here are my thoughts.\n",
      "This is where I'm highly mixed with Xiaomi phones.\n",
      "If you are using Xiaomi smartphones you are dealing with ads and a bunch of bloatware you aren't immediately able to uninstall without special tools.\n",
      "Great cell phone, fast, good photos, battery lasts a long time. Super worth it, it's my second xiaomi and I don't want another brand anymore.\n",
      "It's my second Xiaomi and I intend to stay in it for now. Best cost benefit.\n",
      "Battery lasts for days, great camera, second time I buy a Xiaomi phone and I am super satisfied.\n",
      "Very good product, xiaomi and another level, very attentive seller ball show...\n",
      "Xiaomi great for photos, lots of memory to store everyday photos and documents. I recommend it!!\n",
      "Buying original XIAOMI is pure tranquility. Quality product guarantee and good price.\n",
      "It arrived in perfect condition, the phone could come more the fault of xiaomi still great device!\n",
      "Excellent device Xiaomi does not disappoint quality and performance like few, an excellent cost benefit\n",
      "Wonderful device as it was expected to be a xiaomi, you can buy without regrets\n",
      "battery lasts well, I love xiaomi phones, for me there's no better\n",
      "Best cost benefit, xiaomi making me lose the prejudice of MediaTek\n",
      "I liked everything, recommend it! Another quality Xiaomi product...\n",
      "I loved it very good, and my first xiaomi. Battery lasts all day excellent.\n",
      "Xiaomi speaks for itself! Excellent cost for money!\n",
      "First time using Xiaomi and well worth it\n",
      "This is my second Xiaomi so far and very pleased\n",
      "I definitely do not like it like my Xiaomi Mi 9t pro, I hate the proximity sensor, it wasn't new but refurbished or it seamed like refurbished, the screen had clearly signs of use. Do not recommend it.\n",
      "Great mobile, an iPhone with Xiaomi flag and Android operating system, great cost benefit I'm 200% satisfied.\n",
      "After a couple of months from my purchase I tell you a bit of Xiaomi mi10t.\n",
      "Xiaomi is loosely with other manufacturers. No useless apps or pre-installed games you want. I'm sure that was not the last phone from Xiaomi. The battery delivers what it promises. Long endurance and fast loading.\n",
      "The new Oppo has fully satisfied me.\n",
      "How I miss my Nokia 3310!\n",
      "If I had to spend some money to buy myself a new phone, I would definitely buy the latest iPhone model.\n",
      "Do you remember the Motorola Razr? It was so small and compact!\n",
      "This is my second Oneplus smartphone as Iâ€™m moving from the 6 to 8 and Iâ€™ve found a home with OnePlus.\n",
      "I finally switched from Samsung and Motorola phones to a Google Pixel.\n",
      "Having owned the TCL TV for few years, I decided to buy the TCL phone and I have been using this phone for a week now and I like it.\n",
      "This LG K31 smartphone is just a little larger but works just fine for my smartphone uses.\n",
      "Entities: [('US', 'GPE'), ('Huawei', 'ORG'), ('Samsung', 'ORG'), ('Samsung', 'ORG'), ('Samsung', 'ORG'), ('the past years', 'DATE'), ('Samsung', 'ORG'), ('Samsung', 'ORG'), ('VLC', 'ORG'), ('samsung', 'ORG'), ('Huawei', 'ORG'), ('Huawei', 'ORG'), ('USA', 'GPE'), ('p30', 'PRODUCT'), ('614', 'MONEY'), ('Huawei P30 Pro', 'ORG'), ('July', 'DATE'), ('AT&T', 'ORG'), ('Tmobile', 'ORG'), ('USA', 'GPE'), ('US', 'GPE'), ('Samsung', 'ORG'), ('Apple', 'ORG'), ('the last ten years', 'DATE'), ('three', 'CARDINAL'), ('Huawei', 'ORG'), ('English', 'LANGUAGE'), ('5 minutes', 'TIME'), ('second', 'ORDINAL'), ('Huawei', 'ORG'), ('iPhone', 'ORG'), ('Huawei', 'ORG'), ('iPhone', 'ORG'), ('Huawei', 'ORG'), ('Redmi', 'ORG'), ('third', 'ORDINAL'), ('Xiaomi', 'PRODUCT'), ('the Redmi 8', 'ORG'), ('the Redmi 9', 'ORG'), ('Xiaomi', 'PRODUCT'), ('second', 'ORDINAL'), ('second', 'ORDINAL'), ('second', 'ORDINAL'), ('XIAOMI', 'ORG'), ('MediaTek', 'ORG'), ('first', 'ORDINAL'), ('First', 'ORDINAL'), ('Xiaomi', 'PRODUCT'), ('second', 'ORDINAL'), ('Xiaomi Mi', 'PERSON'), ('9', 'CARDINAL'), ('Xiaomi', 'PRODUCT'), ('Android', 'ORG'), ('200%', 'PERCENT'), ('a couple of months', 'DATE'), ('Xiaomi mi10t.', 'FAC'), ('Oppo', 'ORG'), ('Nokia 3310', 'ORG'), ('iPhone', 'PRODUCT'), ('second', 'ORDINAL'), ('the 6 to 8', 'DATE'), ('OnePlus', 'PRODUCT'), ('Samsung', 'ORG'), ('Motorola', 'ORG'), ('few years', 'DATE'), ('TCL', 'ORG'), ('a week', 'DATE'), ('LG', 'ORG')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# STEP 1 - TRAIN DATA\n",
    "\n",
    "# Prepare training data\n",
    "\n",
    "# TBD: define all the entities by extracting the words and their indexes from the dataset\n",
    "# expected format is the following:  (\"sentence\", {\"entities\": [0,10, \"FOOD\"]})\n",
    "\n",
    "words = ['xiaomi', 'samsung', 'nokia', 'apple', 'huawei', 'at&t', 'redmi', 'mediatk', 'oppo', 'motorola', 'oneplus', 'google pixel',\n",
    "        'tcl', 'lg'\n",
    "]\n",
    "\n",
    "train_data = []\n",
    "\n",
    "with open(\"electronics.txt\") as file:\n",
    "    dataset = file.readlines()\n",
    "    for sentence in dataset:\n",
    "        print(\"######\")\n",
    "        print(\"sentence: \", sentence)\n",
    "        print(\"######\")\n",
    "        sentence = sentence.lower()\n",
    "        entities = []\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            if word in sentence:\n",
    "                start_index = sentence.index(word)\n",
    "                end_index = len(word) + start_index\n",
    "                print(\"word: \", word)\n",
    "                print(\"----------------\")\n",
    "                print(\"start index:\", start_index)\n",
    "                print(\"end index:\", end_index)\n",
    "                pos = (start_index, end_index, \"ORG\")\n",
    "                entities.append(pos)\n",
    "        element = (sentence.rstrip('\\n'), {\"entities\": entities})\n",
    "\n",
    "        train_data.append(element)\n",
    "        print('----------------')\n",
    "        print(\"element:\", element)\n",
    "\n",
    "# STEP 2 - UPDATE MODEL\n",
    "\n",
    "# TBD: load the needed pipeline\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# TBD: define the annotations\n",
    "for _, annotations in train_data:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "# TBD: train the model\n",
    "\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "\n",
    "# TBD: define the number of iterations, the batch size and the drop according to your experience or using an empirical value\n",
    "# Train model\n",
    "\n",
    "iter = 500\n",
    "drop_out = 0.4\n",
    "\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "    for iteration in range(iter):\n",
    "        print(\"Iteration #\" + str(iteration))\n",
    "\n",
    "        # Data shuffle for each iteration\n",
    "        random.shuffle(train_data)\n",
    "        losses = {}\n",
    "        batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            for text, annotations in batch:\n",
    "                # Create an Example object\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                # Update the model\n",
    "                nlp.update([example], losses=losses, drop=drop_out)\n",
    "        print(\"Losses:\", losses)\n",
    "\n",
    "# Save the model\n",
    "# TBD:\n",
    "\n",
    "output_dir = Path(\"./ner/\")\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Saved correctly!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "######\n",
      "sentence:  I am being forced to purchase a new device as all US networks are apparently no longer supporting Huawei devices in the very near future.\n",
      "\n",
      "######\n",
      "word:  huawei\n",
      "----------------\n",
      "start index: 98\n",
      "end index: 104\n",
      "----------------\n",
      "element: ('i am being forced to purchase a new device as all us networks are apparently no longer supporting huawei devices in the very near future.', {'entities': [(98, 104, 'ORG')]})\n",
      "######\n",
      "sentence:  Samsung S20 is The best Phone that money can buy\n",
      "\n",
      "######\n",
      "word:  samsung\n",
      "----------------\n",
      "start index: 0\n",
      "end index: 7\n",
      "----------------\n",
      "element: ('samsung s20 is the best phone that money can buy', {'entities': [(0, 7, 'ORG')]})\n",
      "######\n",
      "sentence:  I'm a Samsung fan, design and productivity is amazing and perfect, BUT it have a no-go for me: it poses a risk for phone owners.\n",
      "\n",
      "######\n",
      "word:  samsung\n",
      "----------------\n",
      "start index: 6\n",
      "end index: 13\n",
      "----------------\n",
      "element: (\"i'm a samsung fan, design and productivity is amazing and perfect, but it have a no-go for me: it poses a risk for phone owners.\", {'entities': [(6, 13, 'ORG')]})\n",
      "######\n",
      "sentence:  The hardware is absolutetly stellar, which is no surprise for Samsung in the past years.\n",
      "\n",
      "######\n",
      "word:  samsung\n",
      "----------------\n",
      "start index: 62\n",
      "end index: 69\n",
      "----------------\n",
      "element: ('the hardware is absolutetly stellar, which is no surprise for samsung in the past years.', {'entities': [(62, 69, 'ORG')]})\n",
      "######\n",
      "sentence:  Unfortunately, same goes for app bloatware, which is also no surprise for Samsung.\n",
      "\n",
      "######\n",
      "word:  samsung\n",
      "----------------\n",
      "start index: 74\n",
      "end index: 81\n",
      "----------------\n",
      "element: ('unfortunately, same goes for app bloatware, which is also no surprise for samsung.', {'entities': [(74, 81, 'ORG')]})\n",
      "######\n",
      "sentence:   The phone feels amazing to the touch. Haven't messed with the camera much but from what I have I can say it's not half bad. I bought a micro sdxc card from Samsung to put all my movies and music on and use VLC to watch/listen and it's great.\n",
      "\n",
      "######\n",
      "word:  samsung\n",
      "----------------\n",
      "start index: 157\n",
      "end index: 164\n",
      "----------------\n",
      "element: (\" the phone feels amazing to the touch. haven't messed with the camera much but from what i have i can say it's not half bad. i bought a micro sdxc card from samsung to put all my movies and music on and use vlc to watch/listen and it's great.\", {'entities': [(157, 164, 'ORG')]})\n",
      "######\n",
      "sentence:  Last time I checked samsung had there high end devices free to unlock there bootloader. At least from the s7 days .\n",
      "\n",
      "######\n",
      "word:  samsung\n",
      "----------------\n",
      "start index: 20\n",
      "end index: 27\n",
      "----------------\n",
      "element: ('last time i checked samsung had there high end devices free to unlock there bootloader. at least from the s7 days .', {'entities': [(20, 27, 'ORG')]})\n",
      "######\n",
      "sentence:  Techniques used in Huawei is great, and even awesome.\n",
      "\n",
      "######\n",
      "word:  huawei\n",
      "----------------\n",
      "start index: 19\n",
      "end index: 25\n",
      "----------------\n",
      "element: ('techniques used in huawei is great, and even awesome.', {'entities': [(19, 25, 'ORG')]})\n",
      "######\n",
      "sentence:  huawei really did an amazing job.\n",
      "\n",
      "######\n",
      "word:  huawei\n",
      "----------------\n",
      "start index: 0\n",
      "end index: 6\n",
      "----------------\n",
      "element: ('huawei really did an amazing job.', {'entities': [(0, 6, 'ORG')]})\n",
      "######\n",
      "sentence:  Huawei phones are excellent. I have used them for ever, unfortunately they are ban by USA. This is the last phone I am purchasing because the next generations will not work in the ðŸ‡ºðŸ‡¸.\n",
      "\n",
      "######\n",
      "word:  huawei\n",
      "----------------\n",
      "start index: 0\n",
      "end index: 6\n",
      "----------------\n",
      "element: ('huawei phones are excellent. i have used them for ever, unfortunately they are ban by usa. this is the last phone i am purchasing because the next generations will not work in the ðŸ‡ºðŸ‡¸.', {'entities': [(0, 6, 'ORG')]})\n",
      "######\n",
      "sentence:  I ordered a new huawei p30 pro for $ 614 and what I received was crazy, the volume buttons werenâ€™t working and the power button hardly works, the battery drains fast and it was a used phone.\n",
      "\n",
      "######\n",
      "word:  huawei\n",
      "----------------\n",
      "start index: 16\n",
      "end index: 22\n",
      "----------------\n",
      "element: ('i ordered a new huawei p30 pro for $ 614 and what i received was crazy, the volume buttons werenâ€™t working and the power button hardly works, the battery drains fast and it was a used phone.', {'entities': [(16, 22, 'ORG')]})\n",
      "######\n",
      "sentence:  I bought the Huawei P30 Pro in July, which to replace my Iphone. I have been using it every day since then. It works great for both AT&T and Tmobile network in the USA. It is a shame to see the political battle and people can not easily buy a great phone, which has nothing to do with national security. Otherwise, the US should ban Samsung, then all other countries should ban Apple etc. So stupid.\n",
      "\n",
      "######\n",
      "word:  samsung\n",
      "----------------\n",
      "start index: 333\n",
      "end index: 340\n",
      "word:  apple\n",
      "----------------\n",
      "start index: 378\n",
      "end index: 383\n",
      "word:  huawei\n",
      "----------------\n",
      "start index: 13\n",
      "end index: 19\n",
      "word:  at&t\n",
      "----------------\n",
      "start index: 132\n",
      "end index: 136\n",
      "----------------\n",
      "element: ('i bought the huawei p30 pro in july, which to replace my iphone. i have been using it every day since then. it works great for both at&t and tmobile network in the usa. it is a shame to see the political battle and people can not easily buy a great phone, which has nothing to do with national security. otherwise, the us should ban samsung, then all other countries should ban apple etc. so stupid.', {'entities': [(333, 340, 'ORG'), (378, 383, 'ORG'), (13, 19, 'ORG'), (132, 136, 'ORG')]})\n",
      "######\n",
      "sentence:  For the money, this phone represents a real bargain. I have been an iphone user for the last ten years, have shown loyalty to the brand and have bought three sim free units during this time. Without question, the Huawei wipes the floor with what I am used to - easily navigated set up and subsequent user menus in real English, superbly constructed, lightening fast loading of websites/data, no irratating and obtrusive update and running out of icloud data prompts ever 5 minutes and an amazing camera.\n",
      "\n",
      "######\n",
      "word:  huawei\n",
      "----------------\n",
      "start index: 213\n",
      "end index: 219\n",
      "----------------\n",
      "element: ('for the money, this phone represents a real bargain. i have been an iphone user for the last ten years, have shown loyalty to the brand and have bought three sim free units during this time. without question, the huawei wipes the floor with what i am used to - easily navigated set up and subsequent user menus in real english, superbly constructed, lightening fast loading of websites/data, no irratating and obtrusive update and running out of icloud data prompts ever 5 minutes and an amazing camera.', {'entities': [(213, 219, 'ORG')]})\n",
      "######\n",
      "sentence:  Incredible phone. My second from Huawei and hoping they stop this nonsense to block apps in their phones as they are perfect. Good value, beautiful device, fast, easy to use, outstanding camera, etc.\n",
      "\n",
      "######\n",
      "word:  huawei\n",
      "----------------\n",
      "start index: 33\n",
      "end index: 39\n",
      "----------------\n",
      "element: ('incredible phone. my second from huawei and hoping they stop this nonsense to block apps in their phones as they are perfect. good value, beautiful device, fast, easy to use, outstanding camera, etc.', {'entities': [(33, 39, 'ORG')]})\n",
      "######\n",
      "sentence:  Everything is fine with huawei phones I think I've been wasting my time and money with iPhone. Huawei gives you more options and more services with less money so my recommendation is don't buy iPhone. I phone is finished long time ago.\n",
      "\n",
      "######\n",
      "word:  huawei\n",
      "----------------\n",
      "start index: 24\n",
      "end index: 30\n",
      "----------------\n",
      "element: (\"everything is fine with huawei phones i think i've been wasting my time and money with iphone. huawei gives you more options and more services with less money so my recommendation is don't buy iphone. i phone is finished long time ago.\", {'entities': [(24, 30, 'ORG')]})\n",
      "######\n",
      "sentence:  For me Huawei are delivering great products at proper prices and are really getting it right. Anybody like me who is worried to leave apple jail, break out it's really good outside!!\n",
      "\n",
      "######\n",
      "word:  apple\n",
      "----------------\n",
      "start index: 134\n",
      "end index: 139\n",
      "word:  huawei\n",
      "----------------\n",
      "start index: 7\n",
      "end index: 13\n",
      "----------------\n",
      "element: (\"for me huawei are delivering great products at proper prices and are really getting it right. anybody like me who is worried to leave apple jail, break out it's really good outside!!\", {'entities': [(134, 139, 'ORG'), (7, 13, 'ORG')]})\n",
      "######\n",
      "sentence:  Thank you for huawei !\n",
      "\n",
      "######\n",
      "word:  huawei\n",
      "----------------\n",
      "start index: 14\n",
      "end index: 20\n",
      "----------------\n",
      "element: ('thank you for huawei !', {'entities': [(14, 20, 'ORG')]})\n",
      "######\n",
      "sentence:  I really love Xiaomi and Redmi phones. This is my third one and I've usually had a good experience with them.\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 14\n",
      "end index: 20\n",
      "word:  redmi\n",
      "----------------\n",
      "start index: 25\n",
      "end index: 30\n",
      "----------------\n",
      "element: (\"i really love xiaomi and redmi phones. this is my third one and i've usually had a good experience with them.\", {'entities': [(14, 20, 'ORG'), (25, 30, 'ORG')]})\n",
      "######\n",
      "sentence:  I've been contemplating on buying a Xiaomi smartphone for quite some time and had tried the Redmi Go on an impulse purchase, saw the Redmi 8 and decided to sit it out, then came the Redmi 9 and so did reviews. I watched a few video reviews and tutorials on how to maximize your experience before purchasing. Here are my thoughts.\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 36\n",
      "end index: 42\n",
      "word:  redmi\n",
      "----------------\n",
      "start index: 92\n",
      "end index: 97\n",
      "----------------\n",
      "element: (\"i've been contemplating on buying a xiaomi smartphone for quite some time and had tried the redmi go on an impulse purchase, saw the redmi 8 and decided to sit it out, then came the redmi 9 and so did reviews. i watched a few video reviews and tutorials on how to maximize your experience before purchasing. here are my thoughts.\", {'entities': [(36, 42, 'ORG'), (92, 97, 'ORG')]})\n",
      "######\n",
      "sentence:  This is where I'm highly mixed with Xiaomi phones.\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 36\n",
      "end index: 42\n",
      "----------------\n",
      "element: (\"this is where i'm highly mixed with xiaomi phones.\", {'entities': [(36, 42, 'ORG')]})\n",
      "######\n",
      "sentence:  If you are using Xiaomi smartphones you are dealing with ads and a bunch of bloatware you aren't immediately able to uninstall without special tools.\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 17\n",
      "end index: 23\n",
      "----------------\n",
      "element: (\"if you are using xiaomi smartphones you are dealing with ads and a bunch of bloatware you aren't immediately able to uninstall without special tools.\", {'entities': [(17, 23, 'ORG')]})\n",
      "######\n",
      "sentence:  Great cell phone, fast, good photos, battery lasts a long time. Super worth it, it's my second xiaomi and I don't want another brand anymore.\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 95\n",
      "end index: 101\n",
      "----------------\n",
      "element: (\"great cell phone, fast, good photos, battery lasts a long time. super worth it, it's my second xiaomi and i don't want another brand anymore.\", {'entities': [(95, 101, 'ORG')]})\n",
      "######\n",
      "sentence:  It's my second Xiaomi and I intend to stay in it for now. Best cost benefit.\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 15\n",
      "end index: 21\n",
      "----------------\n",
      "element: (\"it's my second xiaomi and i intend to stay in it for now. best cost benefit.\", {'entities': [(15, 21, 'ORG')]})\n",
      "######\n",
      "sentence:  Battery lasts for days, great camera, second time I buy a Xiaomi phone and I am super satisfied.\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 58\n",
      "end index: 64\n",
      "----------------\n",
      "element: ('battery lasts for days, great camera, second time i buy a xiaomi phone and i am super satisfied.', {'entities': [(58, 64, 'ORG')]})\n",
      "######\n",
      "sentence:  Very good product, xiaomi and another level, very attentive seller ball show...\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 19\n",
      "end index: 25\n",
      "----------------\n",
      "element: ('very good product, xiaomi and another level, very attentive seller ball show...', {'entities': [(19, 25, 'ORG')]})\n",
      "######\n",
      "sentence:  Xiaomi great for photos, lots of memory to store everyday photos and documents. I recommend it!!\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 0\n",
      "end index: 6\n",
      "----------------\n",
      "element: ('xiaomi great for photos, lots of memory to store everyday photos and documents. i recommend it!!', {'entities': [(0, 6, 'ORG')]})\n",
      "######\n",
      "sentence:  Buying original XIAOMI is pure tranquility. Quality product guarantee and good price.\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 16\n",
      "end index: 22\n",
      "----------------\n",
      "element: ('buying original xiaomi is pure tranquility. quality product guarantee and good price.', {'entities': [(16, 22, 'ORG')]})\n",
      "######\n",
      "sentence:  It arrived in perfect condition, the phone could come more the fault of xiaomi still great device!\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 72\n",
      "end index: 78\n",
      "----------------\n",
      "element: ('it arrived in perfect condition, the phone could come more the fault of xiaomi still great device!', {'entities': [(72, 78, 'ORG')]})\n",
      "######\n",
      "sentence:  Excellent device Xiaomi does not disappoint quality and performance like few, an excellent cost benefit\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 17\n",
      "end index: 23\n",
      "----------------\n",
      "element: ('excellent device xiaomi does not disappoint quality and performance like few, an excellent cost benefit', {'entities': [(17, 23, 'ORG')]})\n",
      "######\n",
      "sentence:  Wonderful device as it was expected to be a xiaomi, you can buy without regrets\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 44\n",
      "end index: 50\n",
      "----------------\n",
      "element: ('wonderful device as it was expected to be a xiaomi, you can buy without regrets', {'entities': [(44, 50, 'ORG')]})\n",
      "######\n",
      "sentence:  battery lasts well, I love xiaomi phones, for me there's no better\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 27\n",
      "end index: 33\n",
      "----------------\n",
      "element: (\"battery lasts well, i love xiaomi phones, for me there's no better\", {'entities': [(27, 33, 'ORG')]})\n",
      "######\n",
      "sentence:  Best cost benefit, xiaomi making me lose the prejudice of MediaTek\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 19\n",
      "end index: 25\n",
      "----------------\n",
      "element: ('best cost benefit, xiaomi making me lose the prejudice of mediatek', {'entities': [(19, 25, 'ORG')]})\n",
      "######\n",
      "sentence:  I liked everything, recommend it! Another quality Xiaomi product...\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 50\n",
      "end index: 56\n",
      "----------------\n",
      "element: ('i liked everything, recommend it! another quality xiaomi product...', {'entities': [(50, 56, 'ORG')]})\n",
      "######\n",
      "sentence:  I loved it very good, and my first xiaomi. Battery lasts all day excellent.\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 35\n",
      "end index: 41\n",
      "----------------\n",
      "element: ('i loved it very good, and my first xiaomi. battery lasts all day excellent.', {'entities': [(35, 41, 'ORG')]})\n",
      "######\n",
      "sentence:  Xiaomi speaks for itself! Excellent cost for money!\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 0\n",
      "end index: 6\n",
      "----------------\n",
      "element: ('xiaomi speaks for itself! excellent cost for money!', {'entities': [(0, 6, 'ORG')]})\n",
      "######\n",
      "sentence:  First time using Xiaomi and well worth it\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 17\n",
      "end index: 23\n",
      "----------------\n",
      "element: ('first time using xiaomi and well worth it', {'entities': [(17, 23, 'ORG')]})\n",
      "######\n",
      "sentence:  This is my second Xiaomi so far and very pleased\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 18\n",
      "end index: 24\n",
      "----------------\n",
      "element: ('this is my second xiaomi so far and very pleased', {'entities': [(18, 24, 'ORG')]})\n",
      "######\n",
      "sentence:  I definitely do not like it like my Xiaomi Mi 9t pro, I hate the proximity sensor, it wasn't new but refurbished or it seamed like refurbished, the screen had clearly signs of use. Do not recommend it.\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 36\n",
      "end index: 42\n",
      "----------------\n",
      "element: (\"i definitely do not like it like my xiaomi mi 9t pro, i hate the proximity sensor, it wasn't new but refurbished or it seamed like refurbished, the screen had clearly signs of use. do not recommend it.\", {'entities': [(36, 42, 'ORG')]})\n",
      "######\n",
      "sentence:  Great mobile, an iPhone with Xiaomi flag and Android operating system, great cost benefit I'm 200% satisfied.\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 29\n",
      "end index: 35\n",
      "----------------\n",
      "element: (\"great mobile, an iphone with xiaomi flag and android operating system, great cost benefit i'm 200% satisfied.\", {'entities': [(29, 35, 'ORG')]})\n",
      "######\n",
      "sentence:  After a couple of months from my purchase I tell you a bit of Xiaomi mi10t.\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 62\n",
      "end index: 68\n",
      "----------------\n",
      "element: ('after a couple of months from my purchase i tell you a bit of xiaomi mi10t.', {'entities': [(62, 68, 'ORG')]})\n",
      "######\n",
      "sentence:  Xiaomi is loosely with other manufacturers. No useless apps or pre-installed games you want. I'm sure that was not the last phone from Xiaomi. The battery delivers what it promises. Long endurance and fast loading.\n",
      "\n",
      "######\n",
      "word:  xiaomi\n",
      "----------------\n",
      "start index: 0\n",
      "end index: 6\n",
      "----------------\n",
      "element: (\"xiaomi is loosely with other manufacturers. no useless apps or pre-installed games you want. i'm sure that was not the last phone from xiaomi. the battery delivers what it promises. long endurance and fast loading.\", {'entities': [(0, 6, 'ORG')]})\n",
      "######\n",
      "sentence:  The new Oppo has fully satisfied me.\n",
      "\n",
      "######\n",
      "word:  oppo\n",
      "----------------\n",
      "start index: 8\n",
      "end index: 12\n",
      "----------------\n",
      "element: ('the new oppo has fully satisfied me.', {'entities': [(8, 12, 'ORG')]})\n",
      "######\n",
      "sentence:  How I miss my Nokia 3310!\n",
      "\n",
      "######\n",
      "word:  nokia\n",
      "----------------\n",
      "start index: 14\n",
      "end index: 19\n",
      "----------------\n",
      "element: ('how i miss my nokia 3310!', {'entities': [(14, 19, 'ORG')]})\n",
      "######\n",
      "sentence:  If I had to spend some money to buy myself a new phone, I would definitely buy the latest iPhone model.\n",
      "\n",
      "######\n",
      "----------------\n",
      "element: ('if i had to spend some money to buy myself a new phone, i would definitely buy the latest iphone model.', {'entities': []})\n",
      "######\n",
      "sentence:  Do you remember the Motorola Razr? It was so small and compact!\n",
      "\n",
      "######\n",
      "word:  motorola\n",
      "----------------\n",
      "start index: 20\n",
      "end index: 28\n",
      "----------------\n",
      "element: ('do you remember the motorola razr? it was so small and compact!', {'entities': [(20, 28, 'ORG')]})\n",
      "######\n",
      "sentence:  This is my second Oneplus smartphone as Iâ€™m moving from the 6 to 8 and Iâ€™ve found a home with OnePlus.\n",
      "\n",
      "######\n",
      "word:  oneplus\n",
      "----------------\n",
      "start index: 18\n",
      "end index: 25\n",
      "----------------\n",
      "element: ('this is my second oneplus smartphone as iâ€™m moving from the 6 to 8 and iâ€™ve found a home with oneplus.', {'entities': [(18, 25, 'ORG')]})\n",
      "######\n",
      "sentence:  I finally switched from Samsung and Motorola phones to a Google Pixel.\n",
      "\n",
      "######\n",
      "word:  samsung\n",
      "----------------\n",
      "start index: 24\n",
      "end index: 31\n",
      "word:  motorola\n",
      "----------------\n",
      "start index: 36\n",
      "end index: 44\n",
      "word:  google pixel\n",
      "----------------\n",
      "start index: 57\n",
      "end index: 69\n",
      "----------------\n",
      "element: ('i finally switched from samsung and motorola phones to a google pixel.', {'entities': [(24, 31, 'ORG'), (36, 44, 'ORG'), (57, 69, 'ORG')]})\n",
      "######\n",
      "sentence:  Having owned the TCL TV for few years, I decided to buy the TCL phone and I have been using this phone for a week now and I like it.\n",
      "\n",
      "######\n",
      "word:  tcl\n",
      "----------------\n",
      "start index: 17\n",
      "end index: 20\n",
      "----------------\n",
      "element: ('having owned the tcl tv for few years, i decided to buy the tcl phone and i have been using this phone for a week now and i like it.', {'entities': [(17, 20, 'ORG')]})\n",
      "######\n",
      "sentence:  This LG K31 smartphone is just a little larger but works just fine for my smartphone uses.\n",
      "######\n",
      "word:  lg\n",
      "----------------\n",
      "start index: 5\n",
      "end index: 7\n",
      "----------------\n",
      "element: ('this lg k31 smartphone is just a little larger but works just fine for my smartphone uses.', {'entities': [(5, 7, 'ORG')]})\n",
      "Iteration #0\n",
      "Losses: {'ner': 60.325116688012336}\n",
      "Iteration #1\n",
      "Losses: {'ner': 23.91330388862161}\n",
      "Iteration #2\n",
      "Losses: {'ner': 22.24670874409919}\n",
      "Iteration #3\n",
      "Losses: {'ner': 19.79952009576744}\n",
      "Iteration #4\n",
      "Losses: {'ner': 10.015455346443554}\n",
      "Iteration #5\n",
      "Losses: {'ner': 9.502066332116886}\n",
      "Iteration #6\n",
      "Losses: {'ner': 10.622361581320355}\n",
      "Iteration #7\n",
      "Losses: {'ner': 2.0959273427582916}\n",
      "Iteration #8\n",
      "Losses: {'ner': 4.277679720291136}\n",
      "Iteration #9\n",
      "Losses: {'ner': 2.7309453102736807}\n",
      "Iteration #10\n",
      "Losses: {'ner': 2.549766251726251}\n",
      "Iteration #11\n",
      "Losses: {'ner': 5.203076380654858}\n",
      "Iteration #12\n",
      "Losses: {'ner': 1.4931349870998303}\n",
      "Iteration #13\n",
      "Losses: {'ner': 6.103550089647421}\n",
      "Iteration #14\n",
      "Losses: {'ner': 2.9524112560869615}\n",
      "Iteration #15\n",
      "Losses: {'ner': 2.0212952743348858}\n",
      "Iteration #16\n",
      "Losses: {'ner': 3.9918573287549286}\n",
      "Iteration #17\n",
      "Losses: {'ner': 2.588473489001634}\n",
      "Iteration #18\n",
      "Losses: {'ner': 1.928476410800193}\n",
      "Iteration #19\n",
      "Losses: {'ner': 1.9752882730604456e-05}\n",
      "Iteration #20\n",
      "Losses: {'ner': 3.7807589012900693}\n",
      "Iteration #21\n",
      "Losses: {'ner': 0.005967622353036505}\n",
      "Iteration #22\n",
      "Losses: {'ner': 2.877552453682419}\n",
      "Iteration #23\n",
      "Losses: {'ner': 0.9244060312594401}\n",
      "Iteration #24\n",
      "Losses: {'ner': 0.09762134136581743}\n",
      "Iteration #25\n",
      "Losses: {'ner': 0.007551673390441226}\n",
      "Iteration #26\n",
      "Losses: {'ner': 3.200028856261951}\n",
      "Iteration #27\n",
      "Losses: {'ner': 7.651291792540515e-06}\n",
      "Iteration #28\n",
      "Losses: {'ner': 0.23797988332551842}\n",
      "Iteration #29\n",
      "Losses: {'ner': 1.0580409726382539e-05}\n",
      "Iteration #30\n",
      "Losses: {'ner': 2.687283702293323e-05}\n",
      "Iteration #31\n",
      "Losses: {'ner': 1.3745490946805678e-05}\n",
      "Iteration #32\n",
      "Losses: {'ner': 0.002432994665682282}\n",
      "Iteration #33\n",
      "Losses: {'ner': 3.7629767146612316}\n",
      "Iteration #34\n",
      "Losses: {'ner': 0.0018999949824925863}\n",
      "Iteration #35\n",
      "Losses: {'ner': 0.07959707441174321}\n",
      "Iteration #36\n",
      "Losses: {'ner': 0.9689132069397446}\n",
      "Iteration #37\n",
      "Losses: {'ner': 3.927693576267536}\n",
      "Iteration #38\n",
      "Losses: {'ner': 6.057588235074077e-07}\n",
      "Iteration #39\n",
      "Losses: {'ner': 8.546497892696812e-09}\n",
      "Iteration #40\n",
      "Losses: {'ner': 2.503065391056199}\n",
      "Iteration #41\n",
      "Losses: {'ner': 3.999642980087118}\n",
      "Iteration #42\n",
      "Losses: {'ner': 1.9318863858182171}\n",
      "Iteration #43\n",
      "Losses: {'ner': 1.2503517507240443}\n",
      "Iteration #44\n",
      "Losses: {'ner': 2.511556199829583e-05}\n",
      "Iteration #45\n",
      "Losses: {'ner': 0.0020825272695840216}\n",
      "Iteration #46\n",
      "Losses: {'ner': 3.9882662155284208}\n",
      "Iteration #47\n",
      "Losses: {'ner': 4.02995925507378}\n",
      "Iteration #48\n",
      "Losses: {'ner': 0.11383426337673559}\n",
      "Iteration #49\n",
      "Losses: {'ner': 1.9900263564810494}\n",
      "Iteration #50\n",
      "Losses: {'ner': 1.9824802185298214}\n",
      "Iteration #51\n",
      "Losses: {'ner': 0.001956055486648486}\n",
      "Iteration #52\n",
      "Losses: {'ner': 0.13180291035906735}\n",
      "Iteration #53\n",
      "Losses: {'ner': 0.0012016252600685305}\n",
      "Iteration #54\n",
      "Losses: {'ner': 1.4170802000893312}\n",
      "Iteration #55\n",
      "Losses: {'ner': 0.008619087921525308}\n",
      "Iteration #56\n",
      "Losses: {'ner': 4.971234571966699e-05}\n",
      "Iteration #57\n",
      "Losses: {'ner': 2.701972818637744e-06}\n",
      "Iteration #58\n",
      "Losses: {'ner': 1.82374465516294}\n",
      "Iteration #59\n",
      "Losses: {'ner': 3.4886308963915286e-08}\n",
      "Iteration #60\n",
      "Losses: {'ner': 1.604836442212692}\n",
      "Iteration #61\n",
      "Losses: {'ner': 8.472876355396418e-05}\n",
      "Iteration #62\n",
      "Losses: {'ner': 1.2312355622949548e-09}\n",
      "Iteration #63\n",
      "Losses: {'ner': 1.3137346146543951}\n",
      "Iteration #64\n",
      "Losses: {'ner': 3.9417858701088733}\n",
      "Iteration #65\n",
      "Losses: {'ner': 1.609492690386029}\n",
      "Iteration #66\n",
      "Losses: {'ner': 0.03668670648843309}\n",
      "Iteration #67\n",
      "Losses: {'ner': 0.00017232120898220713}\n",
      "Iteration #68\n",
      "Losses: {'ner': 1.527139870397585e-05}\n",
      "Iteration #69\n",
      "Losses: {'ner': 1.9033398773069325}\n",
      "Iteration #70\n",
      "Losses: {'ner': 0.01728872815240662}\n",
      "Iteration #71\n",
      "Losses: {'ner': 7.670921258285747e-08}\n",
      "Iteration #72\n",
      "Losses: {'ner': 1.2996251880647386e-06}\n",
      "Iteration #73\n",
      "Losses: {'ner': 0.0024547197574178105}\n",
      "Iteration #74\n",
      "Losses: {'ner': 1.9998068820426402}\n",
      "Iteration #75\n",
      "Losses: {'ner': 9.857510793341737e-05}\n",
      "Iteration #76\n",
      "Losses: {'ner': 1.6046104425138836e-05}\n",
      "Iteration #77\n",
      "Losses: {'ner': 3.3179499315475327e-06}\n",
      "Iteration #78\n",
      "Losses: {'ner': 6.438865319376649e-06}\n",
      "Iteration #79\n",
      "Losses: {'ner': 1.9974612822917754}\n",
      "Iteration #80\n",
      "Losses: {'ner': 0.015701598491636028}\n",
      "Iteration #81\n",
      "Losses: {'ner': 1.9860344116186344}\n",
      "Iteration #82\n",
      "Losses: {'ner': 3.9545037159018785}\n",
      "Iteration #83\n",
      "Losses: {'ner': 1.7708515468307362}\n",
      "Iteration #84\n",
      "Losses: {'ner': 1.9998368646156472}\n",
      "Iteration #85\n",
      "Losses: {'ner': 1.2989980818095349e-05}\n",
      "Iteration #86\n",
      "Losses: {'ner': 2.0602820409880027}\n",
      "Iteration #87\n",
      "Losses: {'ner': 0.013832304050969914}\n",
      "Iteration #88\n",
      "Losses: {'ner': 0.5270047551555983}\n",
      "Iteration #89\n",
      "Losses: {'ner': 0.0029712829547088493}\n",
      "Iteration #90\n",
      "Losses: {'ner': 3.789752876474177}\n",
      "Iteration #91\n",
      "Losses: {'ner': 1.9999889337350716}\n",
      "Iteration #92\n",
      "Losses: {'ner': 2.6425995983066337e-05}\n",
      "Iteration #93\n",
      "Losses: {'ner': 0.2962768478820968}\n",
      "Iteration #94\n",
      "Losses: {'ner': 3.889510382115968}\n",
      "Iteration #95\n",
      "Losses: {'ner': 8.486123417726722e-05}\n",
      "Iteration #96\n",
      "Losses: {'ner': 3.888751696176628e-06}\n",
      "Iteration #97\n",
      "Losses: {'ner': 1.9998526671394623}\n",
      "Iteration #98\n",
      "Losses: {'ner': 1.9848270116416926}\n",
      "Iteration #99\n",
      "Losses: {'ner': 0.8680251617673812}\n",
      "Iteration #100\n",
      "Losses: {'ner': 1.102033376747466}\n",
      "Iteration #101\n",
      "Losses: {'ner': 0.15388614882223162}\n",
      "Iteration #102\n",
      "Losses: {'ner': 9.485548242266471e-11}\n",
      "Iteration #103\n",
      "Losses: {'ner': 1.9882106798694428}\n",
      "Iteration #104\n",
      "Losses: {'ner': 5.8177261303262385e-08}\n",
      "Iteration #105\n",
      "Losses: {'ner': 2.2756861255742403e-08}\n",
      "Iteration #106\n",
      "Losses: {'ner': 2.2432418586751965e-05}\n",
      "Iteration #107\n",
      "Losses: {'ner': 0.460329311926089}\n",
      "Iteration #108\n",
      "Losses: {'ner': 6.094443642286173e-11}\n",
      "Iteration #109\n",
      "Losses: {'ner': 5.907703618247746e-05}\n",
      "Iteration #110\n",
      "Losses: {'ner': 0.03138374374924276}\n",
      "Iteration #111\n",
      "Losses: {'ner': 6.268226456086584e-08}\n",
      "Iteration #112\n",
      "Losses: {'ner': 1.9999969044202712}\n",
      "Iteration #113\n",
      "Losses: {'ner': 5.2212962779522516e-08}\n",
      "Iteration #114\n",
      "Losses: {'ner': 0.011258327686036398}\n",
      "Iteration #115\n",
      "Losses: {'ner': 0.49066042598990495}\n",
      "Iteration #116\n",
      "Losses: {'ner': 0.9989046180531607}\n",
      "Iteration #117\n",
      "Losses: {'ner': 3.073709803495071e-05}\n",
      "Iteration #118\n",
      "Losses: {'ner': 1.9408959788426223e-11}\n",
      "Iteration #119\n",
      "Losses: {'ner': 2.1476116427509737e-12}\n",
      "Iteration #120\n",
      "Losses: {'ner': 3.57211130178687e-10}\n",
      "Iteration #121\n",
      "Losses: {'ner': 5.537838602058534e-10}\n",
      "Iteration #122\n",
      "Losses: {'ner': 1.1189455429561597e-08}\n",
      "Iteration #123\n",
      "Losses: {'ner': 3.9999399938636913}\n",
      "Iteration #124\n",
      "Losses: {'ner': 1.4648435155774393}\n",
      "Iteration #125\n",
      "Losses: {'ner': 1.4582133462452302}\n",
      "Iteration #126\n",
      "Losses: {'ner': 1.9999868880797425}\n",
      "Iteration #127\n",
      "Losses: {'ner': 2.2519615798527146e-07}\n",
      "Iteration #128\n",
      "Losses: {'ner': 2.1231225955853296e-09}\n",
      "Iteration #129\n",
      "Losses: {'ner': 2.0645084679140338}\n",
      "Iteration #130\n",
      "Losses: {'ner': 2.2747356151701788e-07}\n",
      "Iteration #131\n",
      "Losses: {'ner': 3.135618607594777e-10}\n",
      "Iteration #132\n",
      "Losses: {'ner': 2.8563034559598764e-11}\n",
      "Iteration #133\n",
      "Losses: {'ner': 4.316924317694155e-09}\n",
      "Iteration #134\n",
      "Losses: {'ner': 1.091810281465893e-06}\n",
      "Iteration #135\n",
      "Losses: {'ner': 8.629511721779841e-09}\n",
      "Iteration #136\n",
      "Losses: {'ner': 7.173824656076816e-10}\n",
      "Iteration #137\n",
      "Losses: {'ner': 4.853680881248584e-11}\n",
      "Iteration #138\n",
      "Losses: {'ner': 3.5642781719194787e-09}\n",
      "Iteration #139\n",
      "Losses: {'ner': 1.4594750223860343e-05}\n",
      "Iteration #140\n",
      "Losses: {'ner': 3.934051634290883}\n",
      "Iteration #141\n",
      "Losses: {'ner': 0.014946579390273046}\n",
      "Iteration #142\n",
      "Losses: {'ner': 0.0013672080325135456}\n",
      "Iteration #143\n",
      "Losses: {'ner': 2.4400525669981603e-08}\n",
      "Iteration #144\n",
      "Losses: {'ner': 3.3991205580912955e-08}\n",
      "Iteration #145\n",
      "Losses: {'ner': 1.0038254410431404}\n",
      "Iteration #146\n",
      "Losses: {'ner': 2.057146561355598}\n",
      "Iteration #147\n",
      "Losses: {'ner': 1.898230139775342}\n",
      "Iteration #148\n",
      "Losses: {'ner': 0.08792411604338163}\n",
      "Iteration #149\n",
      "Losses: {'ner': 1.9683697806013858}\n",
      "Iteration #150\n",
      "Losses: {'ner': 3.81815713206713}\n",
      "Iteration #151\n",
      "Losses: {'ner': 0.6014688854634254}\n",
      "Iteration #152\n",
      "Losses: {'ner': 2.200598621210957e-05}\n",
      "Iteration #153\n",
      "Losses: {'ner': 1.4710070841318564e-10}\n",
      "Iteration #154\n",
      "Losses: {'ner': 1.109009413985602}\n",
      "Iteration #155\n",
      "Losses: {'ner': 1.0265742183228442e-09}\n",
      "Iteration #156\n",
      "Losses: {'ner': 2.00383771288295}\n",
      "Iteration #157\n",
      "Losses: {'ner': 2.9399961531539546e-07}\n",
      "Iteration #158\n",
      "Losses: {'ner': 0.0003429617082016607}\n",
      "Iteration #159\n",
      "Losses: {'ner': 1.9520368063141418}\n",
      "Iteration #160\n",
      "Losses: {'ner': 0.00349150505010326}\n",
      "Iteration #161\n",
      "Losses: {'ner': 4.1444256062405486e-17}\n",
      "Iteration #162\n",
      "Losses: {'ner': 2.418188672090698e-09}\n",
      "Iteration #163\n",
      "Losses: {'ner': 1.9031187601738923e-08}\n",
      "Iteration #164\n",
      "Losses: {'ner': 4.367443729478823e-19}\n",
      "Iteration #165\n",
      "Losses: {'ner': 8.782059442881606e-22}\n",
      "Iteration #166\n",
      "Losses: {'ner': 4.621137101553624e-16}\n",
      "Iteration #167\n",
      "Losses: {'ner': 8.277270788499205e-19}\n",
      "Iteration #168\n",
      "Losses: {'ner': 8.729173747123946e-11}\n",
      "Iteration #169\n",
      "Losses: {'ner': 1.0817001503529843e-23}\n",
      "Iteration #170\n",
      "Losses: {'ner': 3.793687378818895e-12}\n",
      "Iteration #171\n",
      "Losses: {'ner': 4.495760844465525e-15}\n",
      "Iteration #172\n",
      "Losses: {'ner': 1.1774194119819558e-10}\n",
      "Iteration #173\n",
      "Losses: {'ner': 1.0612088471879416e-15}\n",
      "Iteration #174\n",
      "Losses: {'ner': 2.6932394473439934e-18}\n",
      "Iteration #175\n",
      "Losses: {'ner': 1.8558930786155155e-07}\n",
      "Iteration #176\n",
      "Losses: {'ner': 5.1115112237328605e-14}\n",
      "Iteration #177\n",
      "Losses: {'ner': 0.0014110244810581207}\n",
      "Iteration #178\n",
      "Losses: {'ner': 2.0000189954629475}\n",
      "Iteration #179\n",
      "Losses: {'ner': 1.8013108652929464e-07}\n",
      "Iteration #180\n",
      "Losses: {'ner': 3.9930726738613376}\n",
      "Iteration #181\n",
      "Losses: {'ner': 0.00023649058463204165}\n",
      "Iteration #182\n",
      "Losses: {'ner': 6.849639287149215e-16}\n",
      "Iteration #183\n",
      "Losses: {'ner': 1.090659976157975e-11}\n",
      "Iteration #184\n",
      "Losses: {'ner': 7.559350634576495e-10}\n",
      "Iteration #185\n",
      "Losses: {'ner': 7.600383343185821e-10}\n",
      "Iteration #186\n",
      "Losses: {'ner': 3.1693508068435866e-13}\n",
      "Iteration #187\n",
      "Losses: {'ner': 2.5977454102450266e-12}\n",
      "Iteration #188\n",
      "Losses: {'ner': 7.827251478313295e-10}\n",
      "Iteration #189\n",
      "Losses: {'ner': 4.749301464903822e-09}\n",
      "Iteration #190\n",
      "Losses: {'ner': 8.844274657521788e-13}\n",
      "Iteration #191\n",
      "Losses: {'ner': 1.9775155018100623e-05}\n",
      "Iteration #192\n",
      "Losses: {'ner': 1.2698346678920145e-12}\n",
      "Iteration #193\n",
      "Losses: {'ner': 5.716873252130698e-07}\n",
      "Iteration #194\n",
      "Losses: {'ner': 4.657365518323036e-10}\n",
      "Iteration #195\n",
      "Losses: {'ner': 2.520828395899054e-12}\n",
      "Iteration #196\n",
      "Losses: {'ner': 5.808753557731398e-10}\n",
      "Iteration #197\n",
      "Losses: {'ner': 6.765487779422991e-09}\n",
      "Iteration #198\n",
      "Losses: {'ner': 1.654249805863747e-07}\n",
      "Iteration #199\n",
      "Losses: {'ner': 4.037363950309148e-09}\n",
      "Iteration #200\n",
      "Losses: {'ner': 0.08095575595400319}\n",
      "Iteration #201\n",
      "Losses: {'ner': 0.009576831913078216}\n",
      "Iteration #202\n",
      "Losses: {'ner': 4.327699249761216e-15}\n",
      "Iteration #203\n",
      "Losses: {'ner': 0.17279496363095714}\n",
      "Iteration #204\n",
      "Losses: {'ner': 3.413507161208671}\n",
      "Iteration #205\n",
      "Losses: {'ner': 2.075156443438923}\n",
      "Iteration #206\n",
      "Losses: {'ner': 6.384167374276278e-07}\n",
      "Iteration #207\n",
      "Losses: {'ner': 0.027769838625809545}\n",
      "Iteration #208\n",
      "Losses: {'ner': 3.316170913791702e-19}\n",
      "Iteration #209\n",
      "Losses: {'ner': 3.0127368921812377e-19}\n",
      "Iteration #210\n",
      "Losses: {'ner': 6.363282848875221e-15}\n",
      "Iteration #211\n",
      "Losses: {'ner': 3.4161577942299215}\n",
      "Iteration #212\n",
      "Losses: {'ner': 1.9999162422956702}\n",
      "Iteration #213\n",
      "Losses: {'ner': 0.0011245583539375812}\n",
      "Iteration #214\n",
      "Losses: {'ner': 6.965446466751955e-08}\n",
      "Iteration #215\n",
      "Losses: {'ner': 1.4222440719604492}\n",
      "Iteration #216\n",
      "Losses: {'ner': 0.7420787759908409}\n",
      "Iteration #217\n",
      "Losses: {'ner': 3.5504116103655616e-09}\n",
      "Iteration #218\n",
      "Losses: {'ner': 0.0023455850590723944}\n",
      "Iteration #219\n",
      "Losses: {'ner': 8.465191112667148e-19}\n",
      "Iteration #220\n",
      "Losses: {'ner': 0.0013773093232885007}\n",
      "Iteration #221\n",
      "Losses: {'ner': 1.9999902248382568}\n",
      "Iteration #222\n",
      "Losses: {'ner': 0.23869197072370796}\n",
      "Iteration #223\n",
      "Losses: {'ner': 2.3712748349506757e-13}\n",
      "Iteration #224\n",
      "Losses: {'ner': 3.5951940417292954}\n",
      "Iteration #225\n",
      "Losses: {'ner': 8.354994468811546e-13}\n",
      "Iteration #226\n",
      "Losses: {'ner': 1.3182643981537579e-15}\n",
      "Iteration #227\n",
      "Losses: {'ner': 2.6884528285172312e-14}\n",
      "Iteration #228\n",
      "Losses: {'ner': 5.565574268755474e-12}\n",
      "Iteration #229\n",
      "Losses: {'ner': 5.0622204646946624e-11}\n",
      "Iteration #230\n",
      "Losses: {'ner': 1.68910980769495}\n",
      "Iteration #231\n",
      "Losses: {'ner': 0.00024953064520777065}\n",
      "Iteration #232\n",
      "Losses: {'ner': 1.995581099808231}\n",
      "Iteration #233\n",
      "Losses: {'ner': 1.007339028936229e-12}\n",
      "Iteration #234\n",
      "Losses: {'ner': 2.000000025436791}\n",
      "Iteration #235\n",
      "Losses: {'ner': 8.808639768486752e-11}\n",
      "Iteration #236\n",
      "Losses: {'ner': 7.027481810196163e-08}\n",
      "Iteration #237\n",
      "Losses: {'ner': 2.7046736282252264e-13}\n",
      "Iteration #238\n",
      "Losses: {'ner': 7.523726727521841e-14}\n",
      "Iteration #239\n",
      "Losses: {'ner': 0.6614816190337539}\n",
      "Iteration #240\n",
      "Losses: {'ner': 0.00016239238898952297}\n",
      "Iteration #241\n",
      "Losses: {'ner': 1.2631798262960333e-08}\n",
      "Iteration #242\n",
      "Losses: {'ner': 1.0977969525788736e-13}\n",
      "Iteration #243\n",
      "Losses: {'ner': 2.143507441453056e-08}\n",
      "Iteration #244\n",
      "Losses: {'ner': 0.05257374970573978}\n",
      "Iteration #245\n",
      "Losses: {'ner': 1.4625097556804689e-15}\n",
      "Iteration #246\n",
      "Losses: {'ner': 1.9709556102752825}\n",
      "Iteration #247\n",
      "Losses: {'ner': 1.4349806308875928}\n",
      "Iteration #248\n",
      "Losses: {'ner': 6.271722468612974e-07}\n",
      "Iteration #249\n",
      "Losses: {'ner': 2.0942869754072175e-10}\n",
      "Iteration #250\n",
      "Losses: {'ner': 1.8359463221784398}\n",
      "Iteration #251\n",
      "Losses: {'ner': 1.4608220905072113}\n",
      "Iteration #252\n",
      "Losses: {'ner': 2.2386843426651456e-11}\n",
      "Iteration #253\n",
      "Losses: {'ner': 0.004788392374087526}\n",
      "Iteration #254\n",
      "Losses: {'ner': 3.999979972891077}\n",
      "Iteration #255\n",
      "Losses: {'ner': 1.9968746222700142}\n",
      "Iteration #256\n",
      "Losses: {'ner': 0.0022373203037371835}\n",
      "Iteration #257\n",
      "Losses: {'ner': 1.165154191300837e-10}\n",
      "Iteration #258\n",
      "Losses: {'ner': 2.0410245094609513e-13}\n",
      "Iteration #259\n",
      "Losses: {'ner': 3.2935467764696713e-13}\n",
      "Iteration #260\n",
      "Losses: {'ner': 3.7113876679722917e-09}\n",
      "Iteration #261\n",
      "Losses: {'ner': 0.014379586181332393}\n",
      "Iteration #262\n",
      "Losses: {'ner': 2.0000000000001124}\n",
      "Iteration #263\n",
      "Losses: {'ner': 2.52298701572635}\n",
      "Iteration #264\n",
      "Losses: {'ner': 1.9999984347000554}\n",
      "Iteration #265\n",
      "Losses: {'ner': 5.72422321449225e-06}\n",
      "Iteration #266\n",
      "Losses: {'ner': 1.1932980034789818e-07}\n",
      "Iteration #267\n",
      "Losses: {'ner': 1.0932495134500645e-06}\n",
      "Iteration #268\n",
      "Losses: {'ner': 1.2232962654026133e-06}\n",
      "Iteration #269\n",
      "Losses: {'ner': 1.0728327722304202e-05}\n",
      "Iteration #270\n",
      "Losses: {'ner': 2.8336158026332455e-08}\n",
      "Iteration #271\n",
      "Losses: {'ner': 1.5138832635228537e-11}\n",
      "Iteration #272\n",
      "Losses: {'ner': 4.457991339328866e-10}\n",
      "Iteration #273\n",
      "Losses: {'ner': 2.463025859482211e-08}\n",
      "Iteration #274\n",
      "Losses: {'ner': 0.0011525707900768296}\n",
      "Iteration #275\n",
      "Losses: {'ner': 2.4532279202724777e-08}\n",
      "Iteration #276\n",
      "Losses: {'ner': 3.462044635650312e-12}\n",
      "Iteration #277\n",
      "Losses: {'ner': 0.0007630153253764607}\n",
      "Iteration #278\n",
      "Losses: {'ner': 1.4921640414777758e-16}\n",
      "Iteration #279\n",
      "Losses: {'ner': 9.426793283691325e-12}\n",
      "Iteration #280\n",
      "Losses: {'ner': 2.589053589843919e-14}\n",
      "Iteration #281\n",
      "Losses: {'ner': 1.4389881802201931e-13}\n",
      "Iteration #282\n",
      "Losses: {'ner': 6.287271290077266e-13}\n",
      "Iteration #283\n",
      "Losses: {'ner': 2.107481069102302e-12}\n",
      "Iteration #284\n",
      "Losses: {'ner': 4.0125648171270364e-14}\n",
      "Iteration #285\n",
      "Losses: {'ner': 6.258227790303586e-17}\n",
      "Iteration #286\n",
      "Losses: {'ner': 1.3259777782812141e-13}\n",
      "Iteration #287\n",
      "Losses: {'ner': 1.2744592817260933e-13}\n",
      "Iteration #288\n",
      "Losses: {'ner': 7.70789136107321e-09}\n",
      "Iteration #289\n",
      "Losses: {'ner': 4.37318421606033e-13}\n",
      "Iteration #290\n",
      "Losses: {'ner': 6.293849991984244e-11}\n",
      "Iteration #291\n",
      "Losses: {'ner': 0.010870666861398396}\n",
      "Iteration #292\n",
      "Losses: {'ner': 7.089315974851543e-09}\n",
      "Iteration #293\n",
      "Losses: {'ner': 4.789777365943125e-13}\n",
      "Iteration #294\n",
      "Losses: {'ner': 0.03801007292088762}\n",
      "Iteration #295\n",
      "Losses: {'ner': 0.8164492848742735}\n",
      "Iteration #296\n",
      "Losses: {'ner': 3.746142279676744e-15}\n",
      "Iteration #297\n",
      "Losses: {'ner': 7.145203299390739e-12}\n",
      "Iteration #298\n",
      "Losses: {'ner': 1.3162688226771698e-18}\n",
      "Iteration #299\n",
      "Losses: {'ner': 5.72686845464743e-24}\n",
      "Iteration #300\n",
      "Losses: {'ner': 8.571095740571084e-23}\n",
      "Iteration #301\n",
      "Losses: {'ner': 7.607111562147406e-20}\n",
      "Iteration #302\n",
      "Losses: {'ner': 4.635817778171331e-12}\n",
      "Iteration #303\n",
      "Losses: {'ner': 1.174288224303854e-20}\n",
      "Iteration #304\n",
      "Losses: {'ner': 1.4911630957803185e-12}\n",
      "Iteration #305\n",
      "Losses: {'ner': 4.1600129879771187e-20}\n",
      "Iteration #306\n",
      "Losses: {'ner': 8.965700232474934e-20}\n",
      "Iteration #307\n",
      "Losses: {'ner': 9.858480040518479e-21}\n",
      "Iteration #308\n",
      "Losses: {'ner': 6.754498470795089e-19}\n",
      "Iteration #309\n",
      "Losses: {'ner': 1.1592984118948444e-24}\n",
      "Iteration #310\n",
      "Losses: {'ner': 5.187246019689306e-19}\n",
      "Iteration #311\n",
      "Losses: {'ner': 6.770324547039104e-13}\n",
      "Iteration #312\n",
      "Losses: {'ner': 5.391534551087699e-21}\n",
      "Iteration #313\n",
      "Losses: {'ner': 1.4558201435831357e-16}\n",
      "Iteration #314\n",
      "Losses: {'ner': 4.019837140031395e-23}\n",
      "Iteration #315\n",
      "Losses: {'ner': 1.4174035872110147e-18}\n",
      "Iteration #316\n",
      "Losses: {'ner': 3.165906655175531e-14}\n",
      "Iteration #317\n",
      "Losses: {'ner': 1.868257527348781e-06}\n",
      "Iteration #318\n",
      "Losses: {'ner': 4.664191712445436e-16}\n",
      "Iteration #319\n",
      "Losses: {'ner': 4.0131138180513656e-16}\n",
      "Iteration #320\n",
      "Losses: {'ner': 2.270556500300407e-20}\n",
      "Iteration #321\n",
      "Losses: {'ner': 3.778941208301033e-19}\n",
      "Iteration #322\n",
      "Losses: {'ner': 1.143421386797238e-20}\n",
      "Iteration #323\n",
      "Losses: {'ner': 1.4863789434814014e-13}\n",
      "Iteration #324\n",
      "Losses: {'ner': 1.1952005252169384e-06}\n",
      "Iteration #325\n",
      "Losses: {'ner': 2.6062457657849136e-20}\n",
      "Iteration #326\n",
      "Losses: {'ner': 1.3639930961111538e-09}\n",
      "Iteration #327\n",
      "Losses: {'ner': 6.132425034614706e-12}\n",
      "Iteration #328\n",
      "Losses: {'ner': 1.5881634766998898e-16}\n",
      "Iteration #329\n",
      "Losses: {'ner': 1.2019988144818773e-19}\n",
      "Iteration #330\n",
      "Losses: {'ner': 1.590988520774335e-17}\n",
      "Iteration #331\n",
      "Losses: {'ner': 2.903959881528749e-19}\n",
      "Iteration #332\n",
      "Losses: {'ner': 5.408319708401515e-19}\n",
      "Iteration #333\n",
      "Losses: {'ner': 2.2028735685252982e-12}\n",
      "Iteration #334\n",
      "Losses: {'ner': 1.7970514477557287e-16}\n",
      "Iteration #335\n",
      "Losses: {'ner': 8.494753165006477e-17}\n",
      "Iteration #336\n",
      "Losses: {'ner': 7.308052444768462e-16}\n",
      "Iteration #337\n",
      "Losses: {'ner': 6.223153514500171e-13}\n",
      "Iteration #338\n",
      "Losses: {'ner': 5.7909170350390605e-18}\n",
      "Iteration #339\n",
      "Losses: {'ner': 2.7470170582724326e-10}\n",
      "Iteration #340\n",
      "Losses: {'ner': 6.83290641562487e-21}\n",
      "Iteration #341\n",
      "Losses: {'ner': 3.222371677556495e-18}\n",
      "Iteration #342\n",
      "Losses: {'ner': 3.9681676497126206e-19}\n",
      "Iteration #343\n",
      "Losses: {'ner': 5.628977702680201e-22}\n",
      "Iteration #344\n",
      "Losses: {'ner': 2.131711776011764e-15}\n",
      "Iteration #345\n",
      "Losses: {'ner': 1.4705012497330782e-17}\n",
      "Iteration #346\n",
      "Losses: {'ner': 7.440608142846704e-18}\n",
      "Iteration #347\n",
      "Losses: {'ner': 3.668616276625388e-20}\n",
      "Iteration #348\n",
      "Losses: {'ner': 1.151938782472757e-13}\n",
      "Iteration #349\n",
      "Losses: {'ner': 3.220297628646024e-08}\n",
      "Iteration #350\n",
      "Losses: {'ner': 1.4714070389693374e-13}\n",
      "Iteration #351\n",
      "Losses: {'ner': 2.319299139319053e-23}\n",
      "Iteration #352\n",
      "Losses: {'ner': 5.877017338662963e-16}\n",
      "Iteration #353\n",
      "Losses: {'ner': 1.2764837812409635e-17}\n",
      "Iteration #354\n",
      "Losses: {'ner': 2.5779297531681786e-09}\n",
      "Iteration #355\n",
      "Losses: {'ner': 2.119914938173788e-15}\n",
      "Iteration #356\n",
      "Losses: {'ner': 2.7814540881703145e-19}\n",
      "Iteration #357\n",
      "Losses: {'ner': 2.393218373485492e-16}\n",
      "Iteration #358\n",
      "Losses: {'ner': 8.139030871203238e-18}\n",
      "Iteration #359\n",
      "Losses: {'ner': 3.5235529701751885e-19}\n",
      "Iteration #360\n",
      "Losses: {'ner': 5.941035324448742e-15}\n",
      "Iteration #361\n",
      "Losses: {'ner': 5.821963888645194e-21}\n",
      "Iteration #362\n",
      "Losses: {'ner': 1.974224104292831e-19}\n",
      "Iteration #363\n",
      "Losses: {'ner': 5.71603602605638}\n",
      "Iteration #364\n",
      "Losses: {'ner': 0.01694892109888621}\n",
      "Iteration #365\n",
      "Losses: {'ner': 2.003113254971428}\n",
      "Iteration #366\n",
      "Losses: {'ner': 7.321450309293196e-10}\n",
      "Iteration #367\n",
      "Losses: {'ner': 4.0149092669582715e-11}\n",
      "Iteration #368\n",
      "Losses: {'ner': 4.4235020212062444e-05}\n",
      "Iteration #369\n",
      "Losses: {'ner': 0.0014027877478165703}\n",
      "Iteration #370\n",
      "Losses: {'ner': 1.5285606152237812e-11}\n",
      "Iteration #371\n",
      "Losses: {'ner': 1.2327603826636222e-08}\n",
      "Iteration #372\n",
      "Losses: {'ner': 1.361464615758368e-26}\n",
      "Iteration #373\n",
      "Losses: {'ner': 1.3999914527871626e-15}\n",
      "Iteration #374\n",
      "Losses: {'ner': 6.9199362165461e-22}\n",
      "Iteration #375\n",
      "Losses: {'ner': 9.605536868242087e-12}\n",
      "Iteration #376\n",
      "Losses: {'ner': 2.1809441520416515e-09}\n",
      "Iteration #377\n",
      "Losses: {'ner': 4.316964021998606e-10}\n",
      "Iteration #378\n",
      "Losses: {'ner': 3.998026132602317}\n",
      "Iteration #379\n",
      "Losses: {'ner': 2.9540489546700913e-13}\n",
      "Iteration #380\n",
      "Losses: {'ner': 3.6633967779219006e-13}\n",
      "Iteration #381\n",
      "Losses: {'ner': 3.820903039461504e-10}\n",
      "Iteration #382\n",
      "Losses: {'ner': 3.998703718185425}\n",
      "Iteration #383\n",
      "Losses: {'ner': 8.271900630355749}\n",
      "Iteration #384\n",
      "Losses: {'ner': 0.00015340918273761876}\n",
      "Iteration #385\n",
      "Losses: {'ner': 4.016753774343559e-06}\n",
      "Iteration #386\n",
      "Losses: {'ner': 3.1347513936396228e-09}\n",
      "Iteration #387\n",
      "Losses: {'ner': 0.00011266132818238655}\n",
      "Iteration #388\n",
      "Losses: {'ner': 7.022952513451294e-07}\n",
      "Iteration #389\n",
      "Losses: {'ner': 2.3910034077430747e-12}\n",
      "Iteration #390\n",
      "Losses: {'ner': 7.876499722637299e-10}\n",
      "Iteration #391\n",
      "Losses: {'ner': 1.727132297702964e-10}\n",
      "Iteration #392\n",
      "Losses: {'ner': 3.515351986974614e-10}\n",
      "Iteration #393\n",
      "Losses: {'ner': 3.1415822520544454e-09}\n",
      "Iteration #394\n",
      "Losses: {'ner': 1.5724578415807163e-10}\n",
      "Iteration #395\n",
      "Losses: {'ner': 1.6142029295352215e-10}\n",
      "Iteration #396\n",
      "Losses: {'ner': 0.03508754236448256}\n",
      "Iteration #397\n",
      "Losses: {'ner': 0.8659096315571347}\n",
      "Iteration #398\n",
      "Losses: {'ner': 1.9998588562011719}\n",
      "Iteration #399\n",
      "Losses: {'ner': 0.08710196279342608}\n",
      "Iteration #400\n",
      "Losses: {'ner': 1.8244834791403725e-05}\n",
      "Iteration #401\n",
      "Losses: {'ner': 9.680167974640633e-10}\n",
      "Iteration #402\n",
      "Losses: {'ner': 1.993941068649292}\n",
      "Iteration #403\n",
      "Losses: {'ner': 1.5757808330582854e-13}\n",
      "Iteration #404\n",
      "Losses: {'ner': 2.7518203164179e-15}\n",
      "Iteration #405\n",
      "Losses: {'ner': 2.1484456817028615e-19}\n",
      "Iteration #406\n",
      "Losses: {'ner': 7.378302020276742e-05}\n",
      "Iteration #407\n",
      "Losses: {'ner': 5.122255970526889e-07}\n",
      "Iteration #408\n",
      "Losses: {'ner': 2.000010702493455}\n",
      "Iteration #409\n",
      "Losses: {'ner': 0.00027646106900652595}\n",
      "Iteration #410\n",
      "Losses: {'ner': 4.118772409774561e-12}\n",
      "Iteration #411\n",
      "Losses: {'ner': 1.9786205291748047}\n",
      "Iteration #412\n",
      "Losses: {'ner': 3.678281184639008}\n",
      "Iteration #413\n",
      "Losses: {'ner': 0.01432990375906229}\n",
      "Iteration #414\n",
      "Losses: {'ner': 1.3758163948869456e-06}\n",
      "Iteration #415\n",
      "Losses: {'ner': 8.330513310286627e-07}\n",
      "Iteration #416\n",
      "Losses: {'ner': 6.863043619496691e-19}\n",
      "Iteration #417\n",
      "Losses: {'ner': 2.1184994492909374e-20}\n",
      "Iteration #418\n",
      "Losses: {'ner': 1.7082227089587382e-20}\n",
      "Iteration #419\n",
      "Losses: {'ner': 1.9215006748273325e-09}\n",
      "Iteration #420\n",
      "Losses: {'ner': 3.9265209436416626}\n",
      "Iteration #421\n",
      "Losses: {'ner': 1.9984490877847736}\n",
      "Iteration #422\n",
      "Losses: {'ner': 1.999985694885277}\n",
      "Iteration #423\n",
      "Losses: {'ner': 1.9975087642798648}\n",
      "Iteration #424\n",
      "Losses: {'ner': 4.5381097968236045e-14}\n",
      "Iteration #425\n",
      "Losses: {'ner': 1.4396090985968625e-09}\n",
      "Iteration #426\n",
      "Losses: {'ner': 2.669501403819301e-07}\n",
      "Iteration #427\n",
      "Losses: {'ner': 1.1076187265059132e-11}\n",
      "Iteration #428\n",
      "Losses: {'ner': 0.00389911684551969}\n",
      "Iteration #429\n",
      "Losses: {'ner': 9.272090202832566e-14}\n",
      "Iteration #430\n",
      "Losses: {'ner': 8.16745782117323e-09}\n",
      "Iteration #431\n",
      "Losses: {'ner': 2.000000000000022}\n",
      "Iteration #432\n",
      "Losses: {'ner': 1.999994345475356}\n",
      "Iteration #433\n",
      "Losses: {'ner': 1.6507004637093647}\n",
      "Iteration #434\n",
      "Losses: {'ner': 0.09495882689952852}\n",
      "Iteration #435\n",
      "Losses: {'ner': 3.68687283992797}\n",
      "Iteration #436\n",
      "Losses: {'ner': 3.847444187476648e-16}\n",
      "Iteration #437\n",
      "Losses: {'ner': 1.6295589739709746e-06}\n",
      "Iteration #438\n",
      "Losses: {'ner': 0.00012637615237215356}\n",
      "Iteration #439\n",
      "Losses: {'ner': 4.023295525865272e-14}\n",
      "Iteration #440\n",
      "Losses: {'ner': 1.1973078366007044e-07}\n",
      "Iteration #441\n",
      "Losses: {'ner': 5.713758457119896e-13}\n",
      "Iteration #442\n",
      "Losses: {'ner': 0.000546246767045569}\n",
      "Iteration #443\n",
      "Losses: {'ner': 1.9794369935989404}\n",
      "Iteration #444\n",
      "Losses: {'ner': 6.745420528543523e-09}\n",
      "Iteration #445\n",
      "Losses: {'ner': 8.687498509294355e-07}\n",
      "Iteration #446\n",
      "Losses: {'ner': 0.0020348490215838376}\n",
      "Iteration #447\n",
      "Losses: {'ner': 4.1811831052800805e-11}\n",
      "Iteration #448\n",
      "Losses: {'ner': 5.808441093822372e-20}\n",
      "Iteration #449\n",
      "Losses: {'ner': 1.2186841059370677e-17}\n",
      "Iteration #450\n",
      "Losses: {'ner': 2.0000118488576937}\n",
      "Iteration #451\n",
      "Losses: {'ner': 1.3739094734192743}\n",
      "Iteration #452\n",
      "Losses: {'ner': 8.950871652246903e-15}\n",
      "Iteration #453\n",
      "Losses: {'ner': 2.021590699726042e-14}\n",
      "Iteration #454\n",
      "Losses: {'ner': 1.4454874992395021}\n",
      "Iteration #455\n",
      "Losses: {'ner': 3.7472743656119425}\n",
      "Iteration #456\n",
      "Losses: {'ner': 7.492939218942382e-06}\n",
      "Iteration #457\n",
      "Losses: {'ner': 1.1545866587796952e-09}\n",
      "Iteration #458\n",
      "Losses: {'ner': 3.678797998468511e-11}\n",
      "Iteration #459\n",
      "Losses: {'ner': 0.06535291063962023}\n",
      "Iteration #460\n",
      "Losses: {'ner': 0.001727017224766314}\n",
      "Iteration #461\n",
      "Losses: {'ner': 4.614848026604746e-14}\n",
      "Iteration #462\n",
      "Losses: {'ner': 4.4244457059424304e-08}\n",
      "Iteration #463\n",
      "Losses: {'ner': 1.3398296440448896e-17}\n",
      "Iteration #464\n",
      "Losses: {'ner': 5.633203854488872e-07}\n",
      "Iteration #465\n",
      "Losses: {'ner': 1.9759845429398615e-20}\n",
      "Iteration #466\n",
      "Losses: {'ner': 8.832534661287063e-21}\n",
      "Iteration #467\n",
      "Losses: {'ner': 9.475074012273626e-15}\n",
      "Iteration #468\n",
      "Losses: {'ner': 3.6844619444309834e-07}\n",
      "Iteration #469\n",
      "Losses: {'ner': 1.4453519978088854e-11}\n",
      "Iteration #470\n",
      "Losses: {'ner': 1.0459724801660928e-15}\n",
      "Iteration #471\n",
      "Losses: {'ner': 1.972772479057312}\n",
      "Iteration #472\n",
      "Losses: {'ner': 0.008469105532948369}\n",
      "Iteration #473\n",
      "Losses: {'ner': 6.712712502360159e-19}\n",
      "Iteration #474\n",
      "Losses: {'ner': 4.633638395227821e-23}\n",
      "Iteration #475\n",
      "Losses: {'ner': 3.8307856666143446e-17}\n",
      "Iteration #476\n",
      "Losses: {'ner': 1.348836459192437e-10}\n",
      "Iteration #477\n",
      "Losses: {'ner': 3.666970917052911e-17}\n",
      "Iteration #478\n",
      "Losses: {'ner': 3.091956557600733e-08}\n",
      "Iteration #479\n",
      "Losses: {'ner': 1.5376535159523897e-11}\n",
      "Iteration #480\n",
      "Losses: {'ner': 6.009645905196681e-16}\n",
      "Iteration #481\n",
      "Losses: {'ner': 3.9127687499657725e-14}\n",
      "Iteration #482\n",
      "Losses: {'ner': 6.334275993589719e-17}\n",
      "Iteration #483\n",
      "Losses: {'ner': 9.357776408745905e-20}\n",
      "Iteration #484\n",
      "Losses: {'ner': 2.28325106535788e-20}\n",
      "Iteration #485\n",
      "Losses: {'ner': 4.348603479531549e-14}\n",
      "Iteration #486\n",
      "Losses: {'ner': 1.1175159496635351e-24}\n",
      "Iteration #487\n",
      "Losses: {'ner': 5.118461061163483e-19}\n",
      "Iteration #488\n",
      "Losses: {'ner': 2.0000163898501713}\n",
      "Iteration #489\n",
      "Losses: {'ner': 0.30207867056288823}\n",
      "Iteration #490\n",
      "Losses: {'ner': 2.5643585674742383e-17}\n",
      "Iteration #491\n",
      "Losses: {'ner': 1.7334231507078208e-18}\n",
      "Iteration #492\n",
      "Losses: {'ner': 6.704408606637546e-16}\n",
      "Iteration #493\n",
      "Losses: {'ner': 2.002458216428946e-20}\n",
      "Iteration #494\n",
      "Losses: {'ner': 7.286349696496439e-12}\n",
      "Iteration #495\n",
      "Losses: {'ner': 7.662907632431554e-11}\n",
      "Iteration #496\n",
      "Losses: {'ner': 9.041235145754484e-18}\n",
      "Iteration #497\n",
      "Losses: {'ner': 8.77552302300114e-05}\n",
      "Iteration #498\n",
      "Losses: {'ner': 3.602110092233718e-16}\n",
      "Iteration #499\n",
      "Losses: {'ner': 2.256411754608245e-21}\n",
      "Saved correctly!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# STEP 3 - TEST THE UPDATED MODEL\n",
    "\n",
    "# Load updated model\n",
    "print(\"Loading model...\")\n",
    "nlp_updated = spacy.load(output_dir)\n",
    "\n",
    "# TBD: test with a old sentence\n",
    "doc = nlp_updated('After a couple of months from my purchase I tell you a bit of Xiaomi mi10t.')\n",
    "print(\"entities:\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "# TBD: test with a new sentence and an old brand\n",
    "doc = nlp_updated('I wll buy the new Apple thing')\n",
    "print(\"entities:\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "# TBD: test with a new sentence and a new brand\n",
    "doc = nlp_updated('I find the new Doogee really good')\n",
    "print(\"entities:\", [(ent.text, ent.label_) for ent in doc.ents])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading model...\n",
      "entities: [('Xiaomi', 'ORG')]\n",
      "entities: [('Apple', 'ORG')]\n",
      "entities: [('Doogee', 'ORG')]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('deep_learning': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "5d8eb55396b26e444e25830983e23d02f9d742a022e83389ffb69c4e4a8d7f54"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}