{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"train-and-generate-gpt2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3.8.11 64-bit ('hungging_face': conda)"},"language_info":{"name":"python","version":"3.8.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5393e577ceed4a1abcb8ff0f945d7966":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cba6b3f2ee19428cb376867925cf8c39","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7455bccc661c4efeac7f13524b9f95dc","IPY_MODEL_43ae6ff7f7e14dc49f494e6e9886ff78","IPY_MODEL_ea7375dc5ea74e04b887b3a77b364ce9"]}},"cba6b3f2ee19428cb376867925cf8c39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7455bccc661c4efeac7f13524b9f95dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a1ce592d9d3541c8b49c6f3cad7bc06a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dba2c2b8bab6464d868a820516fa2f67"}},"43ae6ff7f7e14dc49f494e6e9886ff78":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2fba591fb3b64e0f81ac3d655ef264aa","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa551c48b48543218750a31b9667b98b"}},"ea7375dc5ea74e04b887b3a77b364ce9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7a7fb71142b54144bd04a4edc5227670","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 15/? [00:01&lt;00:00, 15.35 tables/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_70cb47a69c3744f8a86928fa14638fb8"}},"a1ce592d9d3541c8b49c6f3cad7bc06a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dba2c2b8bab6464d868a820516fa2f67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2fba591fb3b64e0f81ac3d655ef264aa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"aa551c48b48543218750a31b9667b98b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7a7fb71142b54144bd04a4edc5227670":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"70cb47a69c3744f8a86928fa14638fb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f96a18d99b274fdc99096e2e47eb817a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2fd4ad9c9c6745878dafc0575ddf0d9b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bf34b7713f494be9b9652781b9ff3db2","IPY_MODEL_1c7983a3eb1b41ca9f0c0555ed59a439","IPY_MODEL_092ba6d41c7c414a9946ca8d47c13640"]}},"2fd4ad9c9c6745878dafc0575ddf0d9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bf34b7713f494be9b9652781b9ff3db2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9d23722f56ec4e9e8211d6b9d8602088","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4dd9f3e51dba4cd798eaaef86f488a54"}},"1c7983a3eb1b41ca9f0c0555ed59a439":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_743fbfcbb9774d4c91529544863fb040","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a21695c3840541fb9c91f095a503989b"}},"092ba6d41c7c414a9946ca8d47c13640":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f468b71b7c6e429989fdc0af6af802b0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/? [00:00&lt;00:00,  8.11 tables/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f5074d43382c459291b8cc5aca794fc9"}},"9d23722f56ec4e9e8211d6b9d8602088":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4dd9f3e51dba4cd798eaaef86f488a54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"743fbfcbb9774d4c91529544863fb040":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a21695c3840541fb9c91f095a503989b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f468b71b7c6e429989fdc0af6af802b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f5074d43382c459291b8cc5aca794fc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"99b4477050494fe08b499fb6e96eb910":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3d3f87782bcf4bbe959ae75636187e50","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a4690a963e12439a842e755a88ffe346","IPY_MODEL_1a56e51c6c344c3fb04cea93dc257931","IPY_MODEL_66da0d322e6c40948dfb7527f5889c95"]}},"3d3f87782bcf4bbe959ae75636187e50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4690a963e12439a842e755a88ffe346":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d118d71ec2674023a334cde32069aa51","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_26bbf4afbb824f14acb05e4c45852c16"}},"1a56e51c6c344c3fb04cea93dc257931":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b4004a49ff7b4c1b85e7639e8cbe822c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":665,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":665,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_319d2af566a84ebe9e0ccf763f2c7b4e"}},"66da0d322e6c40948dfb7527f5889c95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_14dec2fae7d6485180dea71e8ec1681e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 665/665 [00:00&lt;00:00, 23.6kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d7a8f4d45aef4c9f82b388279eda891e"}},"d118d71ec2674023a334cde32069aa51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"26bbf4afbb824f14acb05e4c45852c16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4004a49ff7b4c1b85e7639e8cbe822c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"319d2af566a84ebe9e0ccf763f2c7b4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14dec2fae7d6485180dea71e8ec1681e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d7a8f4d45aef4c9f82b388279eda891e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"33186f64703241d281ed58c72e7da526":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8eccc81dcbb14bf197fad71b9691492a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_93df06e32bb84838af7795dafee31ef6","IPY_MODEL_f60e8f9110284861ab147d9f9d004ca3","IPY_MODEL_fb067ff3573540b1ac1f9412610cfa20"]}},"8eccc81dcbb14bf197fad71b9691492a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"93df06e32bb84838af7795dafee31ef6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bddfcdde9b964a03bc97c4a20b5fc0dc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0a5e6d0897204131968bbe6186c2591e"}},"f60e8f9110284861ab147d9f9d004ca3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_07deb02c97f6484987fa235ecda38129","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1042301,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1042301,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_47451c25d1804707bfa4344f69e9a7fe"}},"fb067ff3573540b1ac1f9412610cfa20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_80cf8e8a836b462898f4c314ffb85bbd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.04M/1.04M [00:00&lt;00:00, 4.64MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ef0c646dff7e44c598f9cc0147d888fc"}},"bddfcdde9b964a03bc97c4a20b5fc0dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0a5e6d0897204131968bbe6186c2591e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"07deb02c97f6484987fa235ecda38129":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"47451c25d1804707bfa4344f69e9a7fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"80cf8e8a836b462898f4c314ffb85bbd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ef0c646dff7e44c598f9cc0147d888fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d2c821d602bd4b0eb38d59a80c4fe2cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d05abe646cc74b5498aa8793c5ff6173","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_db6ad1115f0547809ba78660da3659e6","IPY_MODEL_23949bce110d41c094db820587cb70d5","IPY_MODEL_ef338f0cfc1a4416a16d819e3a04b733"]}},"d05abe646cc74b5498aa8793c5ff6173":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db6ad1115f0547809ba78660da3659e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_72b5d59257634b37be375f99b3373857","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f1970f07fe534643b78a215fd03277f3"}},"23949bce110d41c094db820587cb70d5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1347c154e0794552bad14db1133121ee","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d75de577ee4449995268fff6fd331d7"}},"ef338f0cfc1a4416a16d819e3a04b733":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bcfce46e09b44b6a842669f9f2c2a13e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 1.68MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_296d8cd3aae24a22bf148a5f21a7a271"}},"72b5d59257634b37be375f99b3373857":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f1970f07fe534643b78a215fd03277f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1347c154e0794552bad14db1133121ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5d75de577ee4449995268fff6fd331d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bcfce46e09b44b6a842669f9f2c2a13e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"296d8cd3aae24a22bf148a5f21a7a271":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e290033bed9245628e3c339584a49336":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e47e0ede475e4ffd9c30509c86983903","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_572bfd63ff9b4039a84bff51280be716","IPY_MODEL_3e93a783b4384ede88ebe3a9c20e61d7","IPY_MODEL_807a2a5a279c415c902db3622e2642fb"]}},"e47e0ede475e4ffd9c30509c86983903":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"572bfd63ff9b4039a84bff51280be716":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5ec2f7a261c941f2b492c33ec80d0718","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_13c30e3f27144203b537ddcf2091fb9e"}},"3e93a783b4384ede88ebe3a9c20e61d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7de60d3b54fb42d9bbff5b6fa1e3503b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1355256,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355256,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2179b5e1d61e4ff091ea4919ab1866e0"}},"807a2a5a279c415c902db3622e2642fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_78d7ecfe92834386bcc64877a5d4386f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:00&lt;00:00, 5.39MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_80fb7ed8a21c44b48583a408ae6837bf"}},"5ec2f7a261c941f2b492c33ec80d0718":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"13c30e3f27144203b537ddcf2091fb9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7de60d3b54fb42d9bbff5b6fa1e3503b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2179b5e1d61e4ff091ea4919ab1866e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78d7ecfe92834386bcc64877a5d4386f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"80fb7ed8a21c44b48583a408ae6837bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a72afce05fe46adbdcb2cac0233fded":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f832aac4530d4f40a16569dc2baeb387","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b32054974e7b49f6bf7e554d78d5969e","IPY_MODEL_f33c045f2afd41e6b33afe02ec17e6ae","IPY_MODEL_a10c5e42356c431d9d64be66d503cb92"]}},"f832aac4530d4f40a16569dc2baeb387":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b32054974e7b49f6bf7e554d78d5969e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7b46a09d3a8a46ac932230135dbfde9f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Tokenizing train and test splits: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a728107d125c41aa910e497087259e81"}},"f33c045f2afd41e6b33afe02ec17e6ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_23b064f24aca4e99bb9becca52b8b87a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":113,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":113,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_46d65deaf4a6406e83061d0cb8928935"}},"a10c5e42356c431d9d64be66d503cb92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a8577afd96de4d28bc00f406ac56f23e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 113/113 [00:59&lt;00:00,  2.54ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_69ae5ff511b04c86a5948d70a04303c6"}},"7b46a09d3a8a46ac932230135dbfde9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a728107d125c41aa910e497087259e81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"23b064f24aca4e99bb9becca52b8b87a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"46d65deaf4a6406e83061d0cb8928935":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a8577afd96de4d28bc00f406ac56f23e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"69ae5ff511b04c86a5948d70a04303c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5a384129784d4a79bc300300f539b458":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a54ae66e6624456e90f42d3c010ba6d3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_16b9784a2e1b455aae2a697da012fb04","IPY_MODEL_32a96ef83287440c8a02f5e9cbd99226","IPY_MODEL_95aeb8ee0cd840f0b97c56b73de8b793"]}},"a54ae66e6624456e90f42d3c010ba6d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"16b9784a2e1b455aae2a697da012fb04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fad03fbb6da04bbca31d95ebba85eecb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Tokenizing train and test splits: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5ffb1209cf4941d29a6b0bf1753520e8"}},"32a96ef83287440c8a02f5e9cbd99226":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6ebdaaec550846a1bad29d5b0fc6caf5","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":13,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":13,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fc9dd33d8c4340629cfa85a9e3803b99"}},"95aeb8ee0cd840f0b97c56b73de8b793":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4d40b640cccb4b72922edd7ea0d3df15","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 13/13 [00:06&lt;00:00,  2.33ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_14430e56ad3940a999a3487950264c49"}},"fad03fbb6da04bbca31d95ebba85eecb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5ffb1209cf4941d29a6b0bf1753520e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6ebdaaec550846a1bad29d5b0fc6caf5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fc9dd33d8c4340629cfa85a9e3803b99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4d40b640cccb4b72922edd7ea0d3df15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"14430e56ad3940a999a3487950264c49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7a958ff38b224edca3a052f19e736adc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_34e4dc966ce94a198c74e581ddacedd2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f890f2aebeb44cc8826b07c4defe5ee4","IPY_MODEL_058b2beb11704f149181bbc152363f24","IPY_MODEL_b78a3b2735f5418da06a7f98c982b508"]}},"34e4dc966ce94a198c74e581ddacedd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f890f2aebeb44cc8826b07c4defe5ee4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_296c7fc0518c4ea19d10db363d1f3fd7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Group sentences in blocks of equal size (512): 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a682fd30c8714e748213221a5d0c89a5"}},"058b2beb11704f149181bbc152363f24":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_84bc841d41c046bbbbea5d2180d7bc7e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":113,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":113,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_444833162a8146cfaaa116b70b489c65"}},"b78a3b2735f5418da06a7f98c982b508":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6264f012e5fd48a9a99383aaf3cb3be7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 113/113 [05:10&lt;00:00,  1.90s/ba]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d817e774763546d98239c24ff26b4ca3"}},"296c7fc0518c4ea19d10db363d1f3fd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a682fd30c8714e748213221a5d0c89a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"84bc841d41c046bbbbea5d2180d7bc7e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"444833162a8146cfaaa116b70b489c65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6264f012e5fd48a9a99383aaf3cb3be7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d817e774763546d98239c24ff26b4ca3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1817db18784942d1adb5282348330d59":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a38df38bfe144e7ab1fb9faf82a9f67e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_61836f219eee4449bedbd36d8fd1e894","IPY_MODEL_03c49047be4145f58e47601ddaf46ebe","IPY_MODEL_7b029410cca7442c8b19d40a243342e6"]}},"a38df38bfe144e7ab1fb9faf82a9f67e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61836f219eee4449bedbd36d8fd1e894":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9b3206f001924a13a9b1d167ab24a72f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Group sentences in blocks of equal size (512): 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_729e954f08b04ecfba16a522c4551fe3"}},"03c49047be4145f58e47601ddaf46ebe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_211ce56336544cb1a50b1d9da21c4294","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":13,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":13,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e3ed550346d6411585d2b04709e6227d"}},"7b029410cca7442c8b19d40a243342e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0d1046d2201d4f02a1093ba42de1a5be","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 13/13 [00:35&lt;00:00,  2.31s/ba]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6dd4a1be196b431bbfeb7f33fd51e665"}},"9b3206f001924a13a9b1d167ab24a72f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"729e954f08b04ecfba16a522c4551fe3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"211ce56336544cb1a50b1d9da21c4294":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e3ed550346d6411585d2b04709e6227d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d1046d2201d4f02a1093ba42de1a5be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6dd4a1be196b431bbfeb7f33fd51e665":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"44964208925b47028cfbf3cf32d319af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_885eb74648744647ad00091790e88d06","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bd293aeda2d946b99a78ff4fd903310a","IPY_MODEL_d796ba376e49469592f3b44b6275eee1","IPY_MODEL_d72b7268ff05482cadb41a88ae70b59c"]}},"885eb74648744647ad00091790e88d06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bd293aeda2d946b99a78ff4fd903310a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4dfd61f2fe684309945e9e73f972e369","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Add labels to create data for language model training: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ed9042e6033b44a6b9a3b86701890d18"}},"d796ba376e49469592f3b44b6275eee1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ec1e22b8b5b74ab59d57410e81af3137","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":72,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":72,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9098567a7dac4f9392898a208ad65bc5"}},"d72b7268ff05482cadb41a88ae70b59c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8c9c985cf0274eb485d17e6c03c197c2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 72/72 [00:30&lt;00:00,  2.42ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0478c95ec4c745509db6493b57a28f06"}},"4dfd61f2fe684309945e9e73f972e369":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ed9042e6033b44a6b9a3b86701890d18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ec1e22b8b5b74ab59d57410e81af3137":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9098567a7dac4f9392898a208ad65bc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8c9c985cf0274eb485d17e6c03c197c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0478c95ec4c745509db6493b57a28f06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3110b86eef4c4aafa9f496bb6d2172e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_02d483364a1b490eb4430a8669db01d3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_94a6866f54bb4a3690afca689d30bb86","IPY_MODEL_e52fa6b7dd3e4873b80775d637bb4f29","IPY_MODEL_1f4eefe27d46493e9ef93c681b7bdb7f"]}},"02d483364a1b490eb4430a8669db01d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"94a6866f54bb4a3690afca689d30bb86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_57f6d6e17a864a93b75af2b3a351312e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Add labels to create data for language model training: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d92215eee31a4e4b8b41515f2c073f30"}},"e52fa6b7dd3e4873b80775d637bb4f29":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1a19fa2ab13c4713b64bd73c9055f1ad","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":8,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":8,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6115be1f9336417ab1f9b070d9b62ae1"}},"1f4eefe27d46493e9ef93c681b7bdb7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6937428e68be46048690279fc68770d6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 8/8 [00:03&lt;00:00,  2.38ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_599f7985f31742a3b756bd4368a8e2f2"}},"57f6d6e17a864a93b75af2b3a351312e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d92215eee31a4e4b8b41515f2c073f30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1a19fa2ab13c4713b64bd73c9055f1ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6115be1f9336417ab1f9b070d9b62ae1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6937428e68be46048690279fc68770d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"599f7985f31742a3b756bd4368a8e2f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8c886c9bbdb54277b751b0b8b5fddc67":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_162ce843a4f6475086048534e913da86","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8e81eb2d2a56419fb9df5e2d253d1703","IPY_MODEL_080119e2dde7452e9f42b959b0960896","IPY_MODEL_e0f7cb4613a44bbb9fa27827d4455d8d"]}},"162ce843a4f6475086048534e913da86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8e81eb2d2a56419fb9df5e2d253d1703":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f6673e0767a44182aaeada811b5c40ca","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Skipping the first batches: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7df86e2d364b4215aad7b606f2629c71"}},"080119e2dde7452e9f42b959b0960896":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1dfec5ab317e4684bb41658cbf49e2df","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e630a72a0bc646ab8a43e99325894cd8"}},"e0f7cb4613a44bbb9fa27827d4455d8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2b6f766d33aa4bfe894bdbb151a42bf8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/0 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3d66b0f5e5b04c0b9b6d31ce63a17237"}},"f6673e0767a44182aaeada811b5c40ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7df86e2d364b4215aad7b606f2629c71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1dfec5ab317e4684bb41658cbf49e2df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e630a72a0bc646ab8a43e99325894cd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b6f766d33aa4bfe894bdbb151a42bf8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3d66b0f5e5b04c0b9b6d31ce63a17237":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"interpreter":{"hash":"04af386be12a483b8bebb33ddec4b27a643f28aaa5911a48e2a8bf07254a5fb8"}},"cells":[{"cell_type":"code","execution_count":1,"source":["import pandas as pd\n","import json\n","\n","path = 'booksummaries/'\n","\n","summaries = pd.read_csv(path + 'booksummaries.txt', delimiter = \"\\t\", header=None)\n","\n","to_drop = [0, 1, 4, 5]\n","\n","summaries.drop(to_drop, axis=1, inplace=True)\n","\n","summaries\n"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                       2                   3  \\\n","0                                            Animal Farm       George Orwell   \n","1                                     A Clockwork Orange     Anthony Burgess   \n","2                                             The Plague        Albert Camus   \n","3              An Enquiry Concerning Human Understanding          David Hume   \n","4                                   A Fire Upon the Deep        Vernor Vinge   \n","...                                                  ...                 ...   \n","16554                                     Under Wildwood         Colin Meloy   \n","16555                                  Transfer of Power         Vince Flynn   \n","16556                                            Decoded               Jay-Z   \n","16557  America Again: Re-becoming The Greatness We Ne...     Stephen Colbert   \n","16558                                          Poor Folk  Fyodor Dostoyevsky   \n","\n","                                                       6  \n","0       Old Major, the old boar on the Manor Farm, ca...  \n","1       Alex, a teenager living in near-future Englan...  \n","2       The text of The Plague is divided into five p...  \n","3       The argument of the Enquiry proceeds by a ser...  \n","4       The novel posits that space around the Milky ...  \n","...                                                  ...  \n","16554   Prue McKeel, having rescued her brother from ...  \n","16555   The reader first meets Rapp while he is doing...  \n","16556   The book follows very rough chronological ord...  \n","16557   Colbert addresses topics including Wall Stree...  \n","16558   Makar Devushkin and Varvara Dobroselova are s...  \n","\n","[16559 rows x 3 columns]"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Animal Farm</td>\n","      <td>George Orwell</td>\n","      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A Clockwork Orange</td>\n","      <td>Anthony Burgess</td>\n","      <td>Alex, a teenager living in near-future Englan...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The Plague</td>\n","      <td>Albert Camus</td>\n","      <td>The text of The Plague is divided into five p...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>An Enquiry Concerning Human Understanding</td>\n","      <td>David Hume</td>\n","      <td>The argument of the Enquiry proceeds by a ser...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A Fire Upon the Deep</td>\n","      <td>Vernor Vinge</td>\n","      <td>The novel posits that space around the Milky ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>16554</th>\n","      <td>Under Wildwood</td>\n","      <td>Colin Meloy</td>\n","      <td>Prue McKeel, having rescued her brother from ...</td>\n","    </tr>\n","    <tr>\n","      <th>16555</th>\n","      <td>Transfer of Power</td>\n","      <td>Vince Flynn</td>\n","      <td>The reader first meets Rapp while he is doing...</td>\n","    </tr>\n","    <tr>\n","      <th>16556</th>\n","      <td>Decoded</td>\n","      <td>Jay-Z</td>\n","      <td>The book follows very rough chronological ord...</td>\n","    </tr>\n","    <tr>\n","      <th>16557</th>\n","      <td>America Again: Re-becoming The Greatness We Ne...</td>\n","      <td>Stephen Colbert</td>\n","      <td>Colbert addresses topics including Wall Stree...</td>\n","    </tr>\n","    <tr>\n","      <th>16558</th>\n","      <td>Poor Folk</td>\n","      <td>Fyodor Dostoyevsky</td>\n","      <td>Makar Devushkin and Varvara Dobroselova are s...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>16559 rows × 3 columns</p>\n","</div>"]},"metadata":{},"execution_count":1}],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["\n","sentences = []\n","for i in range(summaries.shape[0]):\n","    sentence = f\"{summaries.loc[i].values.tolist()[0]}, {summaries.loc[i].values.tolist()[1]}, {summaries.loc[i].values.tolist()[2]}\"\n","    sentences.append(sentence)\n","\n","sentences[:2]"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Animal Farm, George Orwell,  Old Major, the old boar on the Manor Farm, calls the animals on the farm for a meeting, where he compares the humans to parasites and teaches the animals a revolutionary song, \\'Beasts of England\\'. When Major dies, two young pigs, Snowball and Napoleon, assume command and turn his dream into a philosophy. The animals revolt and drive the drunken and irresponsible Mr Jones from the farm, renaming it \"Animal Farm\". They adopt Seven Commandments of Animal-ism, the most important of which is, \"All animals are equal\". Snowball attempts to teach the animals reading and writing; food is plentiful, and the farm runs smoothly. The pigs elevate themselves to positions of leadership and set aside special food items, ostensibly for their personal health. Napoleon takes the pups from the farm dogs and trains them privately. Napoleon and Snowball struggle for leadership. When Snowball announces his plans to build a windmill, Napoleon has his dogs chase Snowball away and declares himself leader. Napoleon enacts changes to the governance structure of the farm, replacing meetings with a committee of pigs, who will run the farm. Using a young pig named Squealer as a \"mouthpiece\", Napoleon claims credit for the windmill idea. The animals work harder with the promise of easier lives with the windmill. After a violent storm, the animals find the windmill annihilated. Napoleon and Squealer convince the animals that Snowball destroyed it, although the scorn of the neighbouring farmers suggests that its walls were too thin. Once Snowball becomes a scapegoat, Napoleon begins purging the farm with his dogs, killing animals he accuses of consorting with his old rival. He and the pigs abuse their power, imposing more control while reserving privileges for themselves and rewriting history, villainising Snowball and glorifying Napoleon. Squealer justifies every statement Napoleon makes, even the pigs\\' alteration of the Seven Commandments of Animalism to benefit themselves. \\'Beasts of England\\' is replaced by an anthem glorifying Napoleon, who appears to be adopting the lifestyle of a man. The animals remain convinced that they are better off than they were when under Mr Jones. Squealer abuses the animals\\' poor memories and invents numbers to show their improvement. Mr Frederick, one of the neighbouring farmers, attacks the farm, using blasting powder to blow up the restored windmill. Though the animals win the battle, they do so at great cost, as many, including Boxer the workhorse, are wounded. Despite his injuries, Boxer continues working harder and harder, until he collapses while working on the windmill. Napoleon sends for a van to take Boxer to the veterinary surgeon\\'s, explaining that better care can be given there. Benjamin, the cynical donkey, who \"could read as well as any pig\", notices that the van belongs to a knacker, and attempts to mount a rescue; but the animals\\' attempts are futile. Squealer reports that the van was purchased by the hospital and the writing from the previous owner had not been repainted. He recounts a tale of Boxer\\'s death in the hands of the best medical care. Years pass, and the pigs learn to walk upright, carry whips and wear clothes. The Seven Commandments are reduced to a single phrase: \"All animals are equal, but some animals are more equal than others\". Napoleon holds a dinner party for the pigs and the humans of the area, who congratulate Napoleon on having the hardest-working but least fed animals in the country. Napoleon announces an alliance with the humans, against the labouring classes of both \"worlds\". He abolishes practices and traditions related to the Revolution, and changes the name of the farm to \"The Manor Farm\". The animals, overhearing the conversation, notice that the faces of the pigs have begun changing. During a poker match, an argument breaks out between Napoleon and Mr Pilkington, and the animals realise that the faces of the pigs look like the faces of humans, and no one can tell the difference between them. The pigs Snowball, Napoleon, and Squealer adapt Old Major\\'s ideas into an actual philosophy, which they formally name Animalism. Soon after, Napoleon and Squealer indulge in the vices of humans (drinking alcohol, sleeping in beds, trading). Squealer is employed to alter the Seven Commandments to account for this humanisation, an allusion to the Soviet government\\'s revising of history in order to exercise control of the people\\'s beliefs about themselves and their society. The original commandments are: # Whatever goes upon two legs is an enemy. # Whatever goes upon four legs, or has wings, is a friend. # No animal shall wear clothes. # No animal shall sleep in a bed. # No animal shall drink alcohol. # No animal shall kill any other animal. # All animals are equal. Later, Napoleon and his pigs secretly revise some commandments to clear them of accusations of law-breaking (such as \"No animal shall drink alcohol\" having \"to excess\" appended to it and \"No animal shall sleep in a bed\" with \"with sheets\" added to it). The changed commandments are as follows, with the changes bolded: * 4 No animal shall sleep in a bed with sheets. * 5 No animal shall drink alcohol to excess. * 6 No animal shall kill any other animal without cause. Eventually these are replaced with the maxims, \"All animals are equal, but some animals are more equal than others\", and \"Four legs good, two legs better!\" as the pigs become more human. This is an ironic twist to the original purpose of the Seven Commandments, which were supposed to keep order within Animal Farm by uniting the animals together against the humans, and prevent animals from following the humans\\' evil habits. Through the revision of the commandments, Orwell demonstrates how simply political dogma can be turned into malleable propaganda.',\n"," 'A Clockwork Orange, Anthony Burgess,  Alex, a teenager living in near-future England, leads his gang on nightly orgies of opportunistic, random \"ultra-violence.\" Alex\\'s friends (\"droogs\" in the novel\\'s Anglo-Russian slang, Nadsat) are: Dim, a slow-witted bruiser who is the gang\\'s muscle; Georgie, an ambitious second-in-command; and Pete, who mostly plays along as the droogs indulge their taste for ultra-violence. Characterized as a sociopath and a hardened juvenile delinquent, Alex is also intelligent and quick-witted, with sophisticated taste in music, being particularly fond of Beethoven, or \"Lovely Ludwig Van.\" The novel begins with the droogs sitting in their favorite hangout (the Korova Milkbar), drinking milk-drug cocktails, called \"milk-plus\", to hype themselves for the night\\'s mayhem. They assault a scholar walking home from the public library, rob a store leaving the owner and his wife bloodied and unconscious, stomp a panhandling derelict, then scuffle with a rival gang. Joyriding through the countryside in a stolen car, they break into an isolated cottage and maul the young couple living there, beating the husband and raping his wife. In a metafictional touch, the husband is a writer working on a manuscript called \"A Clockwork Orange,\" and Alex contemptuously reads out a paragraph that states the novel\\'s main theme before shredding the manuscript. Back at the milk bar, Alex punishes Dim for some crude behaviour, and strains within the gang become apparent. At home in his dreary flat, Alex plays classical music at top volume while fantasizing of even more orgiastic violence. Alex skips school the next day. Following an unexpected visit from P.R. Deltoid, his \"post-corrective advisor,\" Alex meets a pair of ten-year-old girls and takes them back to his parents\\' flat, where he administers hard drugs and then rapes them. That evening, Alex finds his droogs in a mutinous mood. Georgie challenges Alex for leadership of the gang, demanding that they pull a \"man-sized\" job. Alex quells the rebellion by slashing Dim\\'s hand and fighting with Georgie, then in a show of generosity takes them to a bar, where Alex insists on following through on Georgie\\'s idea to burgle the home of a wealthy old woman. The break-in starts as farce and ends in tragic pathos, as Alex\\'s attack kills the elderly woman. His escape is blocked by Dim, who attacks Alex, leaving him incapacitated on the front step as the police arrive. Sentenced to prison for murder, Alex gets a job at the Wing chapel playing religious music on the stereo before and after services as well as during the singing of hymns. The prison chaplain mistakes Alex\\'s Bible studies for stirrings of faith (Alex is actually reading Scripture for the violent passages). After Alex\\'s fellow cellmates blame him for beating a troublesome cellmate to death, he agrees to undergo an experimental behaviour-modification treatment called the Ludovico Technique. The technique is a form of aversion therapy in which Alex receives an injection that makes him feel sick while watching graphically violent films, eventually conditioning him to suffer crippling bouts of nausea at the mere thought of violence. As an unintended consequence, the soundtrack to one of the films—Beethoven\\'s Fifth Symphony—renders Alex unable to listen to his beloved classical music. The effectiveness of the technique is demonstrated to a group of VIPs, who watch as Alex collapses before a walloping bully, and abases himself before a scantily-clad young woman whose presence has aroused his predatory sexual inclinations. Though the prison chaplain accuses the state of stripping Alex of free will, the government officials on the scene are pleased with the results and Alex is released into society. Since his parents are now renting his room to a lodger, Alex wanders the streets and enters a public library where he hopes to learn a painless way to commit suicide. There, he accidentally encounters the old scholar he assaulted earlier in the book, who, keen on revenge, beats Alex with the help of his friends. The policemen who come to Alex\\'s rescue turn out to be none other than Dim and former gang rival Billyboy. The two policemen take Alex outside of town and beat him up. Dazed and bloodied, Alex collapses at the door of an isolated cottage, realizing too late that it is the house he and his droogs invaded in the first half of the story. Because the gang wore masks during the assault, the writer does not recognize Alex. The writer, whose name is revealed as F. Alexander, shelters Alex and questions him about the conditioning. During this sequence, it is revealed that Mrs. Alexander died from the injuries inflicted during the gang-rape, and her husband has decided to continue living \"where her fragrant memory persists\" despite the horrid memories. Alexander, a critic of the government, hopes to use Alex as a symbol of state brutality and thereby prevent the incumbent government from being re-elected. Eventually, he begins to realize Alex\\'s role in the happenings of the night two years ago. One of Alexander\\'s radical associates manages to extract a confession from Alex after removing him from F. Alexander\\'s home and then locks him in a flatblock near his former home. Alex is then subjected to a relentless barrage of classical music, prompting him to attempt suicide by leaping from a high window. Alex wakes up in hospital, where he is courted by government officials anxious to counter the bad publicity created by his suicide attempt. With Alexander safely packed off to a mental institution, Alex is offered a well-paying job if he agrees to side with the government. As photographers snap pictures, Alex daydreams of orgiastic violence and realizes the Ludovico conditioning has been reversed: \"I was cured all right.\" In the final chapter, Alex has a new trio of droogs, but he finds he is beginning to outgrow his taste for violence. A chance encounter with Pete, now married and settled down, inspires Alex to seek a wife and family of his own. He contemplates the likelihood of his future son being a delinquent as he was, a prospect Alex views fatalistically.']"]},"metadata":{},"execution_count":2}],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["# import json\n","# from pathlib import Path\n","\n","# # collect sentences\n","# with open(\"dataset/recipes_raw_nosource_ar.json\") as fn:\n","#   recipes = json.load(fn)\n","\n","# # TODO: wrap the data collection into a function\n","# dataset_path = Path('dataset')\n","# sentences = []\n","# for file in dataset_path.iterdir():\n","#   if file.suffix == '.json':\n","#      with open(file) as fn:\n","#        recipes = json.load(fn)\n","#      for id in recipes.keys():\n","#          try:\n","#              title = recipes[id]['title']\n","#              ingredients = ', '.join([ing for ing in recipes[id]['ingredients']])\n","#              instructions = recipes[id]['instructions']\n","#              sentence = f\"{title}, {ingredients}, {instructions}\"\n","#              if sentence != '':\n","#                  sentences.append(sentence)\n","#          except KeyError:\n","#              continue\n","\n","# # clean sentences\n","# # TODO: add further cleaning steps\n","# def clean(sentence):\n","#     sentence = sentence.replace('ADVERTISEMENT', '')  # replace repetetive words\n","#     sentence = sentence.replace('\\n', ' ')  # replace new line chars\n","#     sentence = sentence.strip()  # strip leading and trailing white-spaces\n","#     return sentence\n","\n","# sentences = list(map(clean, sentences))  # map method.\n","# # sentences = [clean(sentence) for sentence in sentences]  # list comprehension method"],"outputs":[],"metadata":{"id":"zb6nsd1WTouu"}},{"cell_type":"code","execution_count":4,"source":["from sklearn.model_selection import train_test_split\n","\n","# split into train/dev\n","# TODO: alternatively, we could use the `datasets.Dataset.train_test_split()` method \n","SEED = 10  # set seed var for reproducibility\n","train_sentences, test_sentences = train_test_split(sentences, \n","                                                   test_size=0.3, \n","                                                   # change the train_size for rapid testing (for example, use 0.1)\n","                                                   # train_size=0.8,  \n","                                                   random_state=SEED)\n","\n","# write into files\n","for split, sents in zip(['train', 'test'], [train_sentences, test_sentences]):\n","    with open(f\"{split}.txt\", 'w') as fn:\n","        fn.write('\\n'.join(sents))\n"],"outputs":[],"metadata":{"id":"a32Wh1P_l36H"}},{"cell_type":"code","execution_count":5,"source":["# create the datasets.Dataset object\n","from datasets import load_dataset\n","\n","dataset = load_dataset('text', data_files={'train': 'train.txt', 'test': 'test.txt'})"],"outputs":[{"output_type":"stream","name":"stderr","text":["Using custom data configuration default-9b81215ed4537d9e\n"]},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset text/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/alessio/.cache/huggingface/datasets/text/default-9b81215ed4537d9e/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n"]},{"output_type":"stream","name":"stderr","text":["                            "]},{"output_type":"stream","name":"stdout","text":["Dataset text downloaded and prepared to /home/alessio/.cache/huggingface/datasets/text/default-9b81215ed4537d9e/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n"]},{"output_type":"stream","name":"stderr","text":[]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":94,"referenced_widgets":["5393e577ceed4a1abcb8ff0f945d7966","cba6b3f2ee19428cb376867925cf8c39","7455bccc661c4efeac7f13524b9f95dc","43ae6ff7f7e14dc49f494e6e9886ff78","ea7375dc5ea74e04b887b3a77b364ce9","a1ce592d9d3541c8b49c6f3cad7bc06a","dba2c2b8bab6464d868a820516fa2f67","2fba591fb3b64e0f81ac3d655ef264aa","aa551c48b48543218750a31b9667b98b","7a7fb71142b54144bd04a4edc5227670","70cb47a69c3744f8a86928fa14638fb8","f96a18d99b274fdc99096e2e47eb817a","2fd4ad9c9c6745878dafc0575ddf0d9b","bf34b7713f494be9b9652781b9ff3db2","1c7983a3eb1b41ca9f0c0555ed59a439","092ba6d41c7c414a9946ca8d47c13640","9d23722f56ec4e9e8211d6b9d8602088","4dd9f3e51dba4cd798eaaef86f488a54","743fbfcbb9774d4c91529544863fb040","a21695c3840541fb9c91f095a503989b","f468b71b7c6e429989fdc0af6af802b0","f5074d43382c459291b8cc5aca794fc9"]},"id":"1mn1HVpRDkzi","executionInfo":{"status":"ok","timestamp":1628414514009,"user_tz":-120,"elapsed":1772,"user":{"displayName":"Casimiro Carrino","photoUrl":"","userId":"06687796779757067652"}},"outputId":"12f2dbca-d4b8-497a-b21e-bfd8e924ccfb"}},{"cell_type":"code","execution_count":6,"source":["# Instantiate tokenizer\n","from transformers import AutoTokenizer\n","pretrained_model = 'gpt2'\n","tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=pretrained_model)\n","\n","# Define a function to tokenize the dataset and return the text indices. \n","# We also add trailing <|endoftext|> special token\n","def tokenize_sentence(dataset):\n","    # As we can see, there is no padding since the PAD token is not originally used by GPT-2. \n","    # We could perform padding by adding the PAD token to the vocabulary with the method `add_special_tokens()`\n","    return tokenizer([f\"{sentence} {tokenizer.eos_token}\" for sentence in dataset['text']])\n","\n","# apply to dataset object\n","dataset_features = dataset.map(tokenize_sentence,\n","                               batched=True,\n","                               remove_columns=['text'],\n","                               desc='Tokenizing train and test splits')"],"outputs":[{"output_type":"stream","name":"stderr","text":["Tokenizing train and test splits:   0%|          | 0/12 [00:00<?, ?ba/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1944 > 1024). Running this sequence through the model will result in indexing errors\n","Tokenizing train and test splits: 100%|██████████| 12/12 [00:03<00:00,  3.63ba/s]\n","Tokenizing train and test splits: 100%|██████████| 5/5 [00:01<00:00,  3.61ba/s]\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248,"referenced_widgets":["99b4477050494fe08b499fb6e96eb910","3d3f87782bcf4bbe959ae75636187e50","a4690a963e12439a842e755a88ffe346","1a56e51c6c344c3fb04cea93dc257931","66da0d322e6c40948dfb7527f5889c95","d118d71ec2674023a334cde32069aa51","26bbf4afbb824f14acb05e4c45852c16","b4004a49ff7b4c1b85e7639e8cbe822c","319d2af566a84ebe9e0ccf763f2c7b4e","14dec2fae7d6485180dea71e8ec1681e","d7a8f4d45aef4c9f82b388279eda891e","33186f64703241d281ed58c72e7da526","8eccc81dcbb14bf197fad71b9691492a","93df06e32bb84838af7795dafee31ef6","f60e8f9110284861ab147d9f9d004ca3","fb067ff3573540b1ac1f9412610cfa20","bddfcdde9b964a03bc97c4a20b5fc0dc","0a5e6d0897204131968bbe6186c2591e","07deb02c97f6484987fa235ecda38129","47451c25d1804707bfa4344f69e9a7fe","80cf8e8a836b462898f4c314ffb85bbd","ef0c646dff7e44c598f9cc0147d888fc","d2c821d602bd4b0eb38d59a80c4fe2cf","d05abe646cc74b5498aa8793c5ff6173","db6ad1115f0547809ba78660da3659e6","23949bce110d41c094db820587cb70d5","ef338f0cfc1a4416a16d819e3a04b733","72b5d59257634b37be375f99b3373857","f1970f07fe534643b78a215fd03277f3","1347c154e0794552bad14db1133121ee","5d75de577ee4449995268fff6fd331d7","bcfce46e09b44b6a842669f9f2c2a13e","296d8cd3aae24a22bf148a5f21a7a271","e290033bed9245628e3c339584a49336","e47e0ede475e4ffd9c30509c86983903","572bfd63ff9b4039a84bff51280be716","3e93a783b4384ede88ebe3a9c20e61d7","807a2a5a279c415c902db3622e2642fb","5ec2f7a261c941f2b492c33ec80d0718","13c30e3f27144203b537ddcf2091fb9e","7de60d3b54fb42d9bbff5b6fa1e3503b","2179b5e1d61e4ff091ea4919ab1866e0","78d7ecfe92834386bcc64877a5d4386f","80fb7ed8a21c44b48583a408ae6837bf","4a72afce05fe46adbdcb2cac0233fded","f832aac4530d4f40a16569dc2baeb387","b32054974e7b49f6bf7e554d78d5969e","f33c045f2afd41e6b33afe02ec17e6ae","a10c5e42356c431d9d64be66d503cb92","7b46a09d3a8a46ac932230135dbfde9f","a728107d125c41aa910e497087259e81","23b064f24aca4e99bb9becca52b8b87a","46d65deaf4a6406e83061d0cb8928935","a8577afd96de4d28bc00f406ac56f23e","69ae5ff511b04c86a5948d70a04303c6","5a384129784d4a79bc300300f539b458","a54ae66e6624456e90f42d3c010ba6d3","16b9784a2e1b455aae2a697da012fb04","32a96ef83287440c8a02f5e9cbd99226","95aeb8ee0cd840f0b97c56b73de8b793","fad03fbb6da04bbca31d95ebba85eecb","5ffb1209cf4941d29a6b0bf1753520e8","6ebdaaec550846a1bad29d5b0fc6caf5","fc9dd33d8c4340629cfa85a9e3803b99","4d40b640cccb4b72922edd7ea0d3df15","14430e56ad3940a999a3487950264c49"]},"id":"GJ-If2dyKtyc","executionInfo":{"status":"ok","timestamp":1628414598282,"user_tz":-120,"elapsed":76581,"user":{"displayName":"Casimiro Carrino","photoUrl":"","userId":"06687796779757067652"}},"outputId":"161f31a2-3504-458e-d9d8-21977c6a2a51"}},{"cell_type":"code","execution_count":7,"source":["# group sentences in batches of equal size (standard GPT-2 approach)\n","# We use an adaptation of the `group_text` function for that purpose\n","def group_texts(examples):\n","    # Concatenate all texts.\n","    block_size = 512  # set the \"blocks\" to half of the maximum GPT-2 model length (1024) for memory issues\n","    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n","    total_length = len(concatenated_examples[list(examples.keys())[0]])\n","    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n","    # customize this part to your needs.\n","    if total_length >= block_size:\n","        total_length = (total_length // block_size) * block_size\n","    # Split by chunks of max_len.\n","    result = {\n","        k: [t[i: i + block_size] for i in range(0, total_length, block_size)]\n","        for k, t in concatenated_examples.items()\n","    }\n","\n","    # # Add labels to the dataset_features\n","    # # Since the task is language modelling, the labels to predict are actually the input indices \"shifted\"\n","\n","    # result[\"labels\"] = result[\"input_ids\"].copy()\n","    return result\n","\n","# apply the group function to the dataset\n","\n","dataset_grouped = dataset_features.map(group_texts,\n","                                       batched=True,\n","                                       desc='Group sentences in blocks of equal size (512)')\n"],"outputs":[{"output_type":"stream","name":"stderr","text":["Group sentences in blocks of equal size (512): 100%|██████████| 12/12 [00:32<00:00,  2.72s/ba]\n","Group sentences in blocks of equal size (512): 100%|██████████| 5/5 [00:12<00:00,  2.58s/ba]\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["7a958ff38b224edca3a052f19e736adc","34e4dc966ce94a198c74e581ddacedd2","f890f2aebeb44cc8826b07c4defe5ee4","058b2beb11704f149181bbc152363f24","b78a3b2735f5418da06a7f98c982b508","296c7fc0518c4ea19d10db363d1f3fd7","a682fd30c8714e748213221a5d0c89a5","84bc841d41c046bbbbea5d2180d7bc7e","444833162a8146cfaaa116b70b489c65","6264f012e5fd48a9a99383aaf3cb3be7","d817e774763546d98239c24ff26b4ca3","1817db18784942d1adb5282348330d59","a38df38bfe144e7ab1fb9faf82a9f67e","61836f219eee4449bedbd36d8fd1e894","03c49047be4145f58e47601ddaf46ebe","7b029410cca7442c8b19d40a243342e6","9b3206f001924a13a9b1d167ab24a72f","729e954f08b04ecfba16a522c4551fe3","211ce56336544cb1a50b1d9da21c4294","e3ed550346d6411585d2b04709e6227d","0d1046d2201d4f02a1093ba42de1a5be","6dd4a1be196b431bbfeb7f33fd51e665"]},"id":"138rsIPbve3w","executionInfo":{"status":"ok","timestamp":1628414944701,"user_tz":-120,"elapsed":346449,"user":{"displayName":"Casimiro Carrino","photoUrl":"","userId":"06687796779757067652"}},"outputId":"94742469-ce3a-4fa5-9ac9-38c143c9e042"}},{"cell_type":"code","execution_count":8,"source":["# Add \"labels\" column to the dataset_features. \n","# To modify the dataset structure, we use the `dataset.map()` method\n","def add_labels(dataset):\n","    # Since the task is language modelling, the labels to predict are actually \n","    # the input indices shifted forward by one element (token)\n","    dataset['labels'] = dataset['input_ids'].copy()\n","    return dataset\n","\n","dataset_for_lm = dataset_grouped.map(add_labels,\n","                                     batched=True,\n","                                     desc='Add labels to create data for language model training')\n"," "],"outputs":[{"output_type":"stream","name":"stderr","text":["Add labels to create data for language model training: 100%|██████████| 13/13 [00:03<00:00,  3.34ba/s]\n","Add labels to create data for language model training: 100%|██████████| 6/6 [00:01<00:00,  3.68ba/s]\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["44964208925b47028cfbf3cf32d319af","885eb74648744647ad00091790e88d06","bd293aeda2d946b99a78ff4fd903310a","d796ba376e49469592f3b44b6275eee1","d72b7268ff05482cadb41a88ae70b59c","4dfd61f2fe684309945e9e73f972e369","ed9042e6033b44a6b9a3b86701890d18","ec1e22b8b5b74ab59d57410e81af3137","9098567a7dac4f9392898a208ad65bc5","8c9c985cf0274eb485d17e6c03c197c2","0478c95ec4c745509db6493b57a28f06","3110b86eef4c4aafa9f496bb6d2172e3","02d483364a1b490eb4430a8669db01d3","94a6866f54bb4a3690afca689d30bb86","e52fa6b7dd3e4873b80775d637bb4f29","1f4eefe27d46493e9ef93c681b7bdb7f","57f6d6e17a864a93b75af2b3a351312e","d92215eee31a4e4b8b41515f2c073f30","1a19fa2ab13c4713b64bd73c9055f1ad","6115be1f9336417ab1f9b070d9b62ae1","6937428e68be46048690279fc68770d6","599f7985f31742a3b756bd4368a8e2f2"]},"id":"wwQojoh3gHk9","executionInfo":{"status":"ok","timestamp":1628414978015,"user_tz":-120,"elapsed":33343,"user":{"displayName":"Casimiro Carrino","photoUrl":"","userId":"06687796779757067652"}},"outputId":"a76c83d3-7736-4200-e9d5-d379e164ce86"}},{"cell_type":"markdown","source":["### 3) Train the model\n","#### Usage of the `Trainer` API\n","It provides a complete **training loop** under the hood, simplifying a lot the training. It also set some useful training and evaluation strategies."],"metadata":{"id":"2MmJ5vcdKuc3"}},{"cell_type":"code","execution_count":9,"source":["# Instantiate the model class\n","from transformers import (\n","    AutoConfig, \n","    AutoModelForCausalLM, \n","    Trainer, \n","    TrainingArguments,\n","    default_data_collator,\n",")\n","import torch\n","\n","\n","# TODO: experiment with different model configuration and batch sizes until \n","# the models fits into GPU memory (otherwise it generated CUDA-out-of-memory error)\n","# The model is instantiated from the pretrained GPT-2 model\n","# Here, I reduced the number of attention head and layers, \n","# to significantly reduce the model size and make sure it fits in the GPU memory\n","config = AutoConfig.from_pretrained(pretrained_model,\n","                                    n_head=8,  # reduce the size of the model for memory issues\n","                                    n_layer=8)\n","\n","pretrained_model = 'gpt2'\n","model = AutoModelForCausalLM.from_pretrained(pretrained_model, \n","                                             config=config)\n","\n","# Again, we simulate a batch size of 8 by setting the `gradient_accumulation_steps` parameters\n","no_cuda = not bool(torch.cuda.is_available())\n","\n","if no_cuda:\n","  print(f\"Training on CPUs\")\n","else:\n","  print(f\"Training on GPU\")\n","\n","training_args = TrainingArguments(no_cuda=no_cuda,\n","                                  per_device_train_batch_size=3,\n","                                  per_device_eval_batch_size=3,\n","                                  gradient_accumulation_steps=8, # virtually increment the batch_size\n","                                  evaluation_strategy='epoch',\n","                                  save_strategy='epoch',\n","                                  logging_steps=100,\n","                                  logging_dir='gpt2-sum/tb',  # where to store the tensorboard\n","                                  num_train_epochs=5,\n","                                  output_dir='gpt2-sum')\n","\n","# Start the training!\n","# Initialize our Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset_for_lm['train'],\n","    eval_dataset=dataset_for_lm['test'], # we use the test set as validation set\n","    tokenizer=tokenizer,\n","    # Data collator is used to create batches from data. \n","    # When a tokenizer is passed the default to DataCollatorWithPadding is used.\n","    # So we change it since our model do not use PAD tokens\n","    data_collator=default_data_collator,\n",")"],"outputs":[{"output_type":"error","ename":"ValueError","evalue":"`embed_dim` must be divisible by num_heads (got `embed_dim`: 768 and `num_heads`: 10).","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-a74259cc27fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mpretrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gpt2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(pretrained_model, \n\u001b[0m\u001b[1;32m     23\u001b[0m                                              config=config)\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/hungging_face/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         raise ValueError(\n\u001b[1;32m    397\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/hungging_face/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mno_init_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_enable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fast_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/hungging_face/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_embd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/hungging_face/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membd_pdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGPT2Block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/hungging_face/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membd_pdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGPT2Block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/hungging_face/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/hungging_face/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, is_cross_attention)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0;34mf\"`embed_dim` must be divisible by num_heads (got `embed_dim`: {self.embed_dim} and `num_heads`: {self.num_heads}).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: `embed_dim` must be divisible by num_heads (got `embed_dim`: 768 and `num_heads`: 10)."]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rwO6jmz0rNFK","executionInfo":{"status":"ok","timestamp":1628416588507,"user_tz":-120,"elapsed":2806,"user":{"displayName":"Casimiro Carrino","photoUrl":"","userId":"06687796779757067652"}},"outputId":"e26ac14f-4c92-4a7c-ba10-052e8d150817"}},{"cell_type":"code","execution_count":null,"source":["# Use tensorboard to monitor the training\n","# Load the TensorBoard notebook extension\n","%reload_ext tensorboard  \n","\n"," # read data from tensorboard dir\n","%tensorboard --logdir gpt2-sum/tb "],"outputs":[],"metadata":{"id":"SNKMV0Y_AASL"}},{"cell_type":"code","execution_count":null,"source":["# Finally: let's start the training!\n","train_results = trainer.train()"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415,"referenced_widgets":["8c886c9bbdb54277b751b0b8b5fddc67","162ce843a4f6475086048534e913da86","8e81eb2d2a56419fb9df5e2d253d1703","080119e2dde7452e9f42b959b0960896","e0f7cb4613a44bbb9fa27827d4455d8d","f6673e0767a44182aaeada811b5c40ca","7df86e2d364b4215aad7b606f2629c71","1dfec5ab317e4684bb41658cbf49e2df","e630a72a0bc646ab8a43e99325894cd8","2b6f766d33aa4bfe894bdbb151a42bf8","3d66b0f5e5b04c0b9b6d31ce63a17237"]},"id":"ZsVd4BY3AqBs","outputId":"b2ad9b61-beb9-4660-bdc1-2d64627977db"}},{"cell_type":"code","execution_count":null,"source":["# Save model and tokenizer\n","trainer.save_model('gpt2-sum')\n","\n","# Save the metrics obtained (loss)\n","metrics_train = train_results.metrics\n","trainer.log_metrics('train', metrics_train)\n","trainer.save_metrics('train', metrics_train)\n","\n","# save trainer state Saves the Trainer state, since Trainer.save_model \n","# saves only the tokenizer with the model\n","trainer.save_state()"],"outputs":[],"metadata":{"id":"_wyyzGuAm70Z"}},{"cell_type":"markdown","source":["### 4) Evaluate the model\n","The model is evaluated, in our case, on the test set. We use the loss along with the _perplexity_ as evaluation metrics. Shortly, the _perplexity_ is a measure of how a probability model (our trained model) predict a sample (from the test set). A low perplexity indicates the probability distribution is good at predicting the sample. \n","\n","More info here: https://en.wikipedia.org/wiki/Perplexity"],"metadata":{"id":"3iLCm6laovBi"}},{"cell_type":"code","execution_count":null,"source":["metrics_eval = trainer.evaluate()"],"outputs":[],"metadata":{"id":"ja5Gp4uEpnle"}},{"cell_type":"code","execution_count":null,"source":["import math\n","\n","# compute perplexity as the exponential of the loss (cross-entropy)\n","perplexity = math.exp(metrics_eval['eval_loss'])\n","metrics_eval['perplexity'] = perplexity\n","\n","# save evaluation metrics\n","trainer.log_metrics('eval', metrics_eval)\n","trainer.save_metrics('eval', metrics_eval)"],"outputs":[],"metadata":{"id":"88rYZXPbpyfv"}},{"cell_type":"code","execution_count":null,"source":["# # Finally, mount yout Google Drive folder in the runtime to permanently saved the trained model\n","# from google.colab import drive\n","# drive.mount('/content/drive')  # mount the drive folder in the Colab env\n","# ! cp -r 'gpt2-recipes-ep-2/' '/content/drive/MyDrive/Colab Notebooks/strive-school-nlp-aug-2021/natural-text-generation'  # copy the model to drive"],"outputs":[],"metadata":{"id":"Qx3P5tWIJSKV"}},{"cell_type":"markdown","source":["## Generation\n","### Introduction\n","Let's generate some text now.  Text generation involves a different _decoding algorithms_ that rely on trained language models. It can be controlled by several parameters that significantly affects the performances and the generated sequences. There are several _decoding methods_ to generate text from a pretrained language model, such as _greedy search_ versus _beam search_. The HF Transformers library implements various methods as parameters of the `model.generate()` method you can controll. Changing some of them can significantly impact on the performance of the generated text. In general, some decoding algorithms can be complex to understand, that is why we use the most basic methods here.\n","\n","To understand and explore complex decoding methods, I recommend this blog from the HF community https://huggingface.co/blog/how-to-generate\n"],"metadata":{"id":"ieJPoQc_GYdh"}},{"cell_type":"markdown","source":["Let's use our model to generate some recipe! Keep in mind that, depending on how the model has been trained (number of epochs, amount of data, size of the model itself) the results can be far from realistic and often very creative 😃."],"metadata":{"id":"JNe4UyUmZ-ND"}},{"cell_type":"code","execution_count":1,"source":["# Easy Way\n","\n","# Use the `transfomers.pipeline` classes\n","from transformers import TextGenerationPipeline, AutoModelForCausalLM, AutoTokenizer\n","\n","checkpoint = 'gpt2-sum'\n","model_checkpoint = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=checkpoint)\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","\n","pipeline_generate = TextGenerationPipeline(model_checkpoint,\n","                                           tokenizer=tokenizer)\n","\n","while True:\n","    prompt = input('\\n\\nInsert prompt\\n')\n","    max_length = int(input('\\nInsert max generation length\\n'))\n","    top_p = float(input('\\nInsert top_p\\n'))\n","    top_k = int(input('\\nInsert top_k\\n'))\n","    num_return_sequences = int(input('\\nInsert num_return_sequences\\n'))\n","    \n","    generated_sentence = pipeline_generate(prompt,    \n","                                           max_length=max_length,\n","                                           do_sample=True,\n","                                           top_k=top_k,\n","                                           top_p=top_p,\n","                                           num_return_sequences=num_return_sequences,\n","                                           early_stopping=False)\n","    \n","    \n","    for gen in generated_sentence:\n","        print(gen['generated_text'])\n","\n","# generated_sentence = pipeline_generate('Spicy curry chicken',    \n","#                                        max_length=max_length)\n","# for gen in generated_sentence:\n","#     print(gen['generated_text'])\n"],"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["the knight came from the north and found his way back to town. \n","the knight came from the north, and was very much at heart for all the wicked people and many of the others. While they still have a new wife and husband, a wealthy woman with whom she has already married the family and daughter, she can still carry it back to her own country. Her parents are very grateful to her and to find her as he recovers. His family includes her husband and son; his wife, whom he grew up with for the first time, whom he and his wife had affection for, who had been married to a man named Vardice. Dredell is told by his mother that he has died because of his being \"in love with the woman of God.\" Dredell is reunited with his father and goes to court at the fair but the court's council does not decide it will be decided by the court if she and Vardice are sent down to the castle. Dredell then visits Vardice and gives his father the king's crown (the prince had been a successful and successful woman with whom Vardice had befriended, although he did not really possess any of the throne). During this time, Vardice gives Vardice a new wife and a son who is a widow to Vardice and is not her son. Dredell finds out that Vardice has gone with Vardice in the forest to avenge his father, but the elder brother does not have an affair with Vardice; Dredell has been in love with Vardice. Vardice also decides to marry Vardice, so she sets out to meet Vardice. Vardice, once again, is sent to the city, where Vardice is a beautiful maiden, and her brother's grandfather and heir. Vardice's mother gives Vardice to her son, and Vardice takes Vardice in as part of her family's plan to overthrow Vardice. Vardice then becomes an armyguard, and both Vardice and Vardice share an affair, which Vardice wins. Vardice is then sent to the town where Vardice is allowed to travel. Vardice uses Vardice in the night to find Vardice as Vardice, but Vardice becomes a soldier. Vardice, Vardice, and Vardice meet on the bridge, and Vardice, along with Vardice, meet with Vardice and Vardice's two friends,\n","the knight came from the north and fled with him. When his lord, Tarkle, in charge of the two men, took the knights into the house of the Lord of Lords, Sir John Henry, Lord of Lords. He's been killed in the battle, and Sir John Henry has a son, Prince William, who appears to be a servant from the royal army. Sir John Henry has two sons, Prince William and Landon, to whom he has taken many young men in the service of King Richard. This is all of great danger, and Sir John is able to persuade Sir John to travel to the castle and be carried back to the castle. Sir John is now a half-brother of Sir John's and not the king's favorite, he is also a strong king and also the prince. The knight himself makes his way to England on the last part of the journey to his mistress the Lady Jane (which she later reveals to be a woman of great fame), who gives him a young priestess to accompany Sir John to the country for the last time, with the other half of his men. Sir John learns that he will be pursued by a servant named Sir John, and they agree to sail to England in charge of the land, where Sir John and Sir John remain until Sir John is dead. Sir John has to be slain and Sir John's mother, Lord Henry, are not in the kingdom. Sir John is the descendant of Lord Edward, which Sir John does not believe is a better, man. Sir John, with the aid of Lady Jane and Sir John, is an excellent tutor in her household, but Sir John is able to bring the prince back. Sir John and Sir John must flee England to the castle and discover the King's great folly. Sir John also discovers that Sir John has no real love for Sir John as he may have been an un-friended, and that Sir John's father had an affair with Sir John's widow, Miss Elizabeth (which George did not consider worthy of such as Sir John's.) Sir John also discovers the King's secret and is convinced that Sir John is the daughter of Sir John. Sir John's only son, Sir John's brother, is the son of Sir John who has already committed suicide. Sir John's son is sent to Sir John's lodgings, in which Sir John's men are in charge. Sir John gives Sir John his advice to Sir John, and the King, Sir John, Lord Lord Henry, then takes Sir John for England and Sir\n"]},{"output_type":"error","ename":"ValueError","evalue":"invalid literal for int() with base 10: ''","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-ff6e490160bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\nInsert prompt\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nInsert max generation length\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mtop_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nInsert top_p\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtop_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nInsert top_k\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"]}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM\n","checkpoint = 'gpt2-sum'\n","config = AutoConfig.from_pretrained(pretrained_model_name_or_path=checkpoint)\n","model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=checkpoint,\n","                                             config=config)\n","tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=checkpoint)\n","\n","# 2) CREATE A PROMPT, TOKENIZE IT AND CREATE TENSORS\n","while True:\n","    prompt = input('\\n\\nInsert prompt\\n')\n","    max_length = int(input('\\nInsert max generation length\\n'))\n","\n","\n","    # Tokenize the prompt and return tensors needed by the `model.generate()` method\n","    tokenized_prompt = tokenizer(prompt, return_tensors='pt')  \n","    \n","    # 3) RUN CONDITIONAL GENERATION\n","    print(f\"Run conditional generation with prompt: <{prompt}>\")\n","    output_sentence = model.generate(input_ids=tokenized_prompt['input_ids'],\n","                                     max_length=max_length)\n","\n","    output_sentence.squeeze_()  # remove batch dimension\n","    generated_text = tokenizer.decode(output_sentence)\n","    # TODO: add postprocessing to clean the generated text (e.g, cut the text at stop words such as periods)\n","    print(f\"Generated recipe:\\n {generated_text}\")"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"y-wg-TLjGg2T","outputId":"945b7a2e-0b03-4e91-d957-928b5d239bc1"}},{"cell_type":"markdown","source":["# Assignment 1:\n","\n","Fine-tune the GPT-2 model with data from different domains. For example, you could use a collection of song lyrics, poetry or even news articles. \n","\n","Keep in mind a few things:\n","\n","- On the recipes datasets with 71k training examples, the model took about 3 hours to end one epoch. So, it's definitively possible to train it on Colab. You could also perform more epochs to improve the model performance.\n","\n","- Since the data format is just _plain sentences_ you could also scrape from the web whatever content you like. There are a lot of python libraries for scraping out there!\n","\n","- If you experience _CUDA Out of memory_ errors, try to decrease some of the followings hyperparameters: \n","  - batch size\n","  - number of layers\n","  - number of heads\n","\n"],"metadata":{"id":"gp0j7mdrMnpR"}},{"cell_type":"markdown","source":["# Assignment 2\n","\n","Experimentally try out different decoding methods and report the one that performs \"best\". For example, try to discover if some sentences are easy to generate. We will comment on the results during the debrief session.\n","\n"],"metadata":{"id":"vYyloxRdPOiG"}},{"cell_type":"markdown","source":["# Assignment 3 (optional)\n","**Optional**: _measure_ how good the generated text is, compared to the expected one, using the BLEU score. It basically takes as input a _reference sentence_ and a _generated sentences_ and computes the n-gram overlap between them to define a score of similarity. This library helps you compute the BLEU easily: https://pypi.org/project/bleu/"],"metadata":{"id":"j-8s7tOlQ6wS"}}]}